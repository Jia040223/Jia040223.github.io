

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Serendipity">
  <meta name="keywords" content="">
  
    <meta name="description" content="优化问题通常可以表示为： \[\theta^* \in \arg\min_{\theta \in \Theta} L(\theta)\] 其中，\(\theta^*\)是优化得到的参数，\(\Theta\)是参数空间，可以是任意维度的实数集合，而\(L(\theta)\)是目标函数或损失函数，它衡量了参数与某种目标之间的距离。 凸优化问题的局部最优解即是全局最优解，而非凸问题可能有多个局部">
<meta property="og:type" content="article">
<meta property="og:title" content="[Probabilistic Machine Learning]: Fundamentals-Optimization">
<meta property="og:url" content="https://jia040223.github.io/2024/10/29/Fundamentals-Optimization/index.html">
<meta property="og:site_name" content="Serendipity&#39;s Blog">
<meta property="og:description" content="优化问题通常可以表示为： \[\theta^* \in \arg\min_{\theta \in \Theta} L(\theta)\] 其中，\(\theta^*\)是优化得到的参数，\(\Theta\)是参数空间，可以是任意维度的实数集合，而\(L(\theta)\)是目标函数或损失函数，它衡量了参数与某种目标之间的距离。 凸优化问题的局部最优解即是全局最优解，而非凸问题可能有多个局部">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jia040223.github.io/images/Fundamentals-Probability/0.png">
<meta property="article:published_time" content="2024-10-29T01:41:24.000Z">
<meta property="article:modified_time" content="2024-10-29T03:19:32.122Z">
<meta property="article:author" content="Serendipity">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="概率论与数理统计">
<meta property="article:tag" content="优化方法">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://jia040223.github.io/images/Fundamentals-Probability/0.png">
  
  
  
  <title>[Probabilistic Machine Learning]: Fundamentals-Optimization - Serendipity&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"jia040223.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Serendipity's Blog" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Serendipity&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="[Probabilistic Machine Learning]: Fundamentals-Optimization"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-10-29 09:41" pubdate>
          2024年10月29日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          16k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          131 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">[Probabilistic Machine Learning]: Fundamentals-Optimization</h1>
            
            
              <div class="markdown-body">
                
                <p>优化问题通常可以表示为：</p>
<p><span class="math display">\[\theta^* \in \arg\min_{\theta \in
\Theta} L(\theta)\]</span></p>
<p>其中，<span class="math inline">\(\theta^*\)</span>是优化得到的参数，<span class="math inline">\(\Theta\)</span>是参数空间，可以是任意维度的实数集合，而<span class="math inline">\(L(\theta)\)</span>是目标函数或损失函数，它衡量了参数与某种目标之间的距离。</p>
<p>凸优化问题的局部最优解即是全局最优解，而非凸问题可能有多个局部最优解。</p>
<h2 id="一自动微分automatic-differentiation">一、自动微分（Automatic
Differentiation）</h2>
<p><strong>自动微分（AD）</strong>是计算复杂函数的导数的有效方法，尤其是在深度学习和优化中具有重要应用。AD与数值微分和符号微分不同，它通过跟踪计算图来有效计算导数。</p>
<h3 id="函数微分的基础知识">1. 函数微分的基础知识</h3>
<p>在介绍自动微分之前，首先需要了解导数的数学基础。</p>
<ul>
<li><strong>符号表示</strong></li>
</ul>
<p>给定函数<span class="math inline">\(f : \mathbb{R}^2 \rightarrow
\mathbb{R}\)</span>，我们可以写其关于第一个参数的偏导数为<span class="math inline">\(\frac{\partial f}{\partial
x_1}\bigg|_{x=a}\)</span>或者<span class="math inline">\(\frac{\partial}{\partial a_1} f(a_1,
a_2)\)</span></p>
<p>这种命名变量表示法在函数嵌套较多时会变得复杂，因此可以考虑采用函数操作符的表示法。</p>
<ul>
<li><strong>线性和多线性函数：</strong></li>
</ul>
<p>定义线性函数<span class="math inline">\(F : \mathbb{R}^n
\overset{\ell}{\rightarrow}
\mathbb{R}^m\)</span>。每个线性映射对应一个矩阵，其列由<span class="math inline">\(F[e_1], \ldots,
F[e_n]\)</span>组成（具体线性代数课已经证明并详细学习了）。</p>
<p>多线性映射定义为：</p>
<p><span class="math display">\[T : \mathbb{R}^n \times \cdots \times
\mathbb{R}^n \rightarrow \mathbb{R}^m \ \]</span></p>
<p>它对应于<span class="math inline">\(\mathbb{R}^{m \times n \times
\cdots \times n}\)</span>中的一个张量。用<span class="math inline">\(T[x_1, \ldots, x_k] \in
\mathbb{R}^m\)</span>表示这样的<span class="math inline">\(k\)</span>-线性映射对向量<span class="math inline">\(x_1, \ldots, x_k \in
\mathbb{R}^n\)</span>的作用。</p>
<ul>
<li><strong>导数算子</strong></li>
</ul>
<p>对可微分函数<span class="math inline">\(f : U \rightarrow
\mathbb{R}^m\)</span>，其导数可以表示为：</p>
<p><span class="math display">\[\partial f : U \rightarrow (\mathbb{R}^n
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p>或者等价地：</p>
<p><span class="math display">\[\partial f : U \rightarrow \mathbb{R}^{m
\times n}\]</span></p>
<p><strong>雅可比矩阵</strong>表示为所有偏导数组成的矩阵，给定<span class="math inline">\(x \in U\)</span>，可以表示为：</p>
<p><span class="math display">\[J(x) = \partial f(x)\]</span></p>
<p><strong>雅可比-向量积 (JVP)</strong>定义为：</p>
<p><span class="math display">\[(x, v) \mapsto \partial
f(x)[v]\]</span></p>
<p>它表示在点<span class="math inline">\(x\)</span>处，输入扰动<span class="math inline">\(v\)</span>对输出的影响。</p>
<p><strong>向量-雅可比积 (VJP)</strong>定义为：</p>
<p><span class="math display">\[(x, u) \mapsto \partial
f(x)^T[u]\]</span></p>
<p>它表示在点<span class="math inline">\(x\)</span>处，输出扰动<span class="math inline">\(u\)</span>对应输入的变化。</p>
<p><img src="/images/Fundamentals-Optimization/1.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><strong>高阶导数</strong></li>
</ul>
<p>如果函数<span class="math inline">\(f\)</span>在其域<span class="math inline">\(U\)</span>内任意可微，则其二阶导数写作：</p>
<p><span class="math display">\[\partial^2 f : U \rightarrow
(\mathbb{R}^n \overset{\ell}{\rightarrow} \mathbb{R}^n
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p>对于任意高阶导数，可以表示为：</p>
<p><span class="math display">\[\partial^k f : U \rightarrow
(\mathbb{R}^n \overset{\ell}{\rightarrow} \cdots
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p><span class="math inline">\(\partial^2 f\)</span>在<span class="math inline">\(m=1\)</span>时对应于海森矩阵。</p>
<p>泰勒级数近似：</p>
<p><span class="math display">\[f(x + v) \approx f(x) + \partial f(x)[v]
+ \frac{1}{2!} \partial^2 f(x)[v, v] + \cdots + \frac{1}{k!} \partial^k
f(x)[v, \ldots, v]\]</span></p>
<ul>
<li><strong>多个输入</strong></li>
</ul>
<p>考虑一个两个参数的函数：</p>
<p><span class="math display">\[g : U \times V \rightarrow
\mathbb{R}^m\]</span></p>
<p>其中<span class="math inline">\(U \subset
\mathbb{R}^{n_1}​\)</span>和<span class="math inline">\(V \subset
\mathbb{R}^{n_2}\)</span>​。</p>
<p>导数函数可以分别表示为：</p>
<p><span class="math display">\[\partial_1 g : \mathbb{R}^{n_1} \times
\mathbb{R}^{n_2} \rightarrow (\mathbb{R}^{n_1}
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p><span class="math display">\[\partial_2 g : \mathbb{R}^{n_1} \times
\mathbb{R}^{n_2} \rightarrow (\mathbb{R}^{n_2}
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p>总导数表示为：</p>
<p><span class="math display">\[\partial g : \mathbb{R}^{n_1} \times
\mathbb{R}^{n_2} \rightarrow (\mathbb{R}^{n_1} \times \mathbb{R}^{n_2}
\overset{\ell}{\rightarrow} \mathbb{R}^m)\]</span></p>
<p>对于点<span class="math inline">\((x, y) \in U \times
V\)</span>和扰动<span class="math inline">\(\dot{x} \in
\mathbb{R}^{n_1}，\dot{y} \in \mathbb{R}^{n_2}\)</span>​，有：</p>
<p><span class="math display">\[\partial g(x, y)[\dot{x}, \dot{y}] =
\partial_1 g(x, y)[\dot{x}] + \partial_2 g(x, y)[\dot{y}]\]</span></p>
<p>或者，从矩阵的角度来看：</p>
<p><span class="math display">\[\partial g(x, y) = \begin{pmatrix}
\partial_1 g(x, y) &amp; \partial_2 g(x, y) \end{pmatrix}\]</span></p>
<p><img src="/images/Fundamentals-Optimization/2.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><strong>组合和分支</strong></li>
</ul>
<p>当我们有复合函数<span class="math inline">\(f = g \circ
h\)</span>时，链式法则表明：</p>
<p><span class="math display">\[\partial f(x) = \partial g(h(x)) \circ
\partial h(x)\]</span></p>
<p>当存在多个输入时，比如：</p>
<p><span class="math display">\[f(x) = g(a(x), b(x))\]</span></p>
<p>我们可以使用链式法则来计算：</p>
<p><span class="math display">\[\begin{align*} \partial f(x) &amp;=
\partial g(h(x)) \circ \partial h(x) \\ &amp;= \partial_1 g(a(x), b(x))
\circ \partial a(x) + \partial_2 g(a(x), b(x)) \circ \partial
b(x)  \end{align*}\]</span></p>
<p><img src="/images/Fundamentals-Optimization/3.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="链法则到计算图">2. 链法则到计算图</h3>
<p>自动微分的目标是计算任意输入函数的导数。对于给定的函数<span class="math inline">\(f: U \subset \mathbb{R}^n \to
\mathbb{R}^m\)</span>和线性化点<span class="math inline">\(x \in
U\)</span>，AD 可以计算：</p>
<ul>
<li>输入扰动<span class="math inline">\(v \in \mathbb{R}^n\)</span>的
JVP：<span class="math inline">\(\partial f(x)[v]\)</span></li>
<li>输出扰动<span class="math inline">\(u \in \mathbb{R}^m\)</span>的
VJP：<span class="math inline">\(\partial f(x)^T[u]\)</span></li>
</ul>
<p>决定使用哪些函数作为输入，以及如何表示这些函数，是AD设置中最重要的方面之一。</p>
<h4 id="链式组合和链式法则">2.1 链式组合和链式法则</h4>
<p>这里考虑的函数是基本操作的链式组合。链式组合的导数按照链式法则分解，从而提供了一种便利的函数表示形式。例如，考虑由三个操作依次组成的函数：<br>
<span class="math inline">\(f = c \circ b \circ a\)</span></p>
<p>根据链式法则，其导数为：<br>
<span class="math display">\[\partial f(x) = \partial c(b(a(x))) \circ
\partial b(a(x)) \circ \partial a(x)\]</span></p>
<p>针对输入扰动<span class="math inline">\(v \in \mathbb{R}^n\)</span>的
JVP 可以表示为：<br>
<span class="math display">\[\partial f(x)[v] = \partial c(b(a(x)))
[\partial b(a(x)) [\partial a(x)[v]]]\]</span></p>
<p>这个表达式的括号突出了从右到左的评估顺序，这对应于前向模式自动微分。为了计算这个
JVP，我们需要首先计算原始链的前缀：<br>
<span class="math display">\[x, \quad a(x), \quad b(a(x))\]</span></p>
<p>以及相应的偏导数：<br>
<span class="math display">\[\partial a(x), \quad \partial b(a(x)),
\quad \partial c(b(a(x)))\]</span></p>
<p>所以，具体的算法如下：</p>
<p><img src="/images/Fundamentals-Optimization/4.png" srcset="/img/loading.gif" lazyload></p>
<p>对于输出扰动<span class="math inline">\(u\in
\mathbb{R}^m\)</span>，VJP 的表达式为：<br>
<span class="math display">\[\partial f(x)^T[u] = \partial a(x)^T
\partial b(a(x))^T \partial c(b(a(x)))^T[u]\]</span></p>
<p>这里对应于反向模式自动微分。</p>
<p>为了进行 VJP，我们可以首先计算原始链的前缀</p>
<p><span class="math inline">\(x、a(x)、 b(a(x))\)</span></p>
<p>然后反向读取它们，具体为：<br>
<span class="math display">\[\partial c(b(a(x)))^T, \quad \partial
b(a(x))^T, \quad \partial a(x)^T\]</span></p>
<p><img src="/images/Fundamentals-Optimization/5.png" srcset="/img/loading.gif" lazyload></p>
<p>反向模式自动微分在输出为标量时（如深度学习中的损失函数）比前向模式更快。然而，反向模式在向后遍历之前存储所有链的前缀，因此它消耗的内存比前向模式多。</p>
<p>在某些特殊情况下（如每个链操作都是可逆的），可以通过一些方法减少内存需求。还可以通过丢弃某些前缀并在需要时重新计算来在内存与计算之间进行权衡。</p>
<h4 id="从链到计算图">2.2 从链到计算图</h4>
<p>当原语可以接受多个输入时，我们可以自然地将链扩展为电路（circuits）——即基于原语操作的有向无环图（DAG），也称为计算图。电路会有若干个输入节点，表示函数的参数；也有若干个原语节点，每个节点都标记为某种原语操作。输入节点没有入边（即没有其他节点指向它们），并且每个节点恰好有一条出边，同时图中只有一个汇点（输出节点）。电路的整体功能是从输入节点到汇点的操作组合，每个操作的输出作为其他操作的输入。</p>
<p>对于链的自动微分之所以有效，是因为导数沿链可以分解，这得益于著名的链式法则。当我们从链转向有向无环图时，我们是否需要某种“图法则”来沿电路结构分解计算呢？电路引入了两个新特性：入度（fan-in）和出度（fan-out）。</p>
<ul>
<li><strong>入度（fan-in）</strong>：当一个原语操作接受多个参数时，会出现入度。在第1小节中，我们知道多个参数可以视为一个参数，因此链式法则适用。</li>
<li><strong>出度（fan-out）</strong>：出度在反向模式微分中需要稍微更多的关注。</li>
</ul>
<p><img src="/images/Fundamentals-Optimization/6.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>示例说明</strong></p>
<p>考虑上图的电路。操作<span class="math inline">\(a\)</span>在拓扑上位于<span class="math inline">\(b\)</span>和<span class="math inline">\(c\)</span>之前，并且有一条出边指向它们。我们可以将<span class="math inline">\(a\)</span>从<span class="math inline">\(\{b,
c\}\)</span>中切割出来，生成两个新电路，如上图(b)所示。第一个电路对应于<span class="math inline">\(a\)</span>，第二个电路的计算为：</p>
<p><span class="math display">\[f_{\{b,c\}}(x_1, x_2) = c(x_1,
b(x_2))\]</span></p>
<p>我们可以通过一个名为<span class="math inline">\(dup\)</span>的函数来恢复完整的函数<span class="math inline">\(f\)</span>：</p>
<p><span class="math display">\[dup(x) = (x, x) \equiv \begin{pmatrix} I
\\ I \end{pmatrix} x\]</span></p>
<p>因此，函数<span class="math inline">\(f\)</span>可以写为链式组合：</p>
<p><span class="math display">\[f = f_{\{b,c\}} \circ dup \circ
a\]</span></p>
<p>电路<span class="math inline">\(f_{\{b,c\}}\)</span>不包含出度，其导数与<span class="math inline">\(b\)</span>、<span class="math inline">\(c\)</span>及其导数的关系，都是通过链式法则实现的。同时，根据链式法则：</p>
<p><span class="math display">\[\begin{align*} \partial f(x) &amp;=
\partial f_{\{b,c\}}(dup(a(x))) \circ \partial dup(a(x)) \circ \partial
a(x) \\&amp;= \partial f_{\{b,c\}}(a(x), a(x)) \circ \begin{pmatrix} I
\\ I \end{pmatrix} \circ \partial a(x) \end{align*}\]</span></p>
<p>以上表达式表明，可以通过从右到左的评估来计算<span class="math inline">\(f\)</span>的 JVP。这类似于链情况中建议的 JVP
计算，但中间有一个复制的操作<span class="math inline">\(\begin{pmatrix}
I \\ I \end{pmatrix}\)</span>，即<span class="math inline">\(dup\)</span>的雅可比矩阵。</p>
<p><img src="/images/Fundamentals-Optimization/7.png" srcset="/img/loading.gif" lazyload></p>
<p>对<span class="math inline">\(f\)</span>在<span class="math inline">\(x\)</span>处的导数进行转置：</p>
<p><span class="math display">\[\partial f(x)^T = \partial a(x)^T \circ
(I \ \  I) \circ \partial f_{\{b,c\}}(a(x), a(x))^T\]</span></p>
<p>考虑从右到左的评估，这同样类似于链情况中建议的 VJP
计算，但中间有一个求和操作<span class="math inline">\((I\ \
I)\)</span>，即<span class="math inline">\(dup\)</span>的转置雅可比矩阵。</p>
<p><img src="/images/Fundamentals-Optimization/8.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="二-随机优化">二、 随机优化</h2>
<p>这节我们主要考虑形式为<span class="math inline">\(L(\theta) =
\mathbb{E}_{q_\theta(z)} \left[ \tilde{L}(\theta, z)
\right]\)</span>的随机目标优化，其中<span class="math inline">\(\theta\)</span>是我们要优化的参数，<span class="math inline">\(z\)</span>是随机变量，例如外部噪声，采样数据或者隐变量等。</p>
<h3 id="随机梯度下降-sgd">1. 随机梯度下降 (SGD)</h3>
<p>假设我们能够计算目标函数梯度的无偏估计<span class="math inline">\(g_t\)</span>​ ，即：</p>
<p><span class="math display">\[\mathbb{E}[g_t] = \nabla_\theta
L(\theta) |_{\theta_t}\]</span></p>
<p>则我们可以在梯度下降过程中使用它：</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t - \eta_t
g_t\]</span></p>
<p>其中<span class="math inline">\(\eta_t\)</span>是学习率或步长。这被称为<strong>随机梯度下降（SGD）</strong>。SGD
收敛速度可能较慢，因为它依赖于梯度的随机估计。目前已经提出多种方法以减少每一步生成的参数估计的方差，从而加速收敛。</p>
<p>在使用 SGD
时，我们需要选择学习率来更好地收敛。我们可以使用学习率调度，而不是选择单一的常数学习率，逐步调整步长。理论上，SGD
收敛的充分条件是学习率调度满足 <strong>Robbins-Monro 条件</strong>：</p>
<p><span class="math display">\[\eta_t \to 0, \quad \sum_{t=1}^\infty
\eta_t^2 &lt; \infty, \quad \sum_{t=1}^\infty \eta_t =
\infty\]</span></p>
<p>一些常见的学习率调度示例如下：</p>
<ul>
<li><strong>分段常数</strong>：<span class="math inline">\(\eta_t =
\eta_i \quad \text{if } t_i \leq t \leq t_{i+1}\)</span></li>
<li><strong>指数衰减</strong>：<span class="math inline">\(\eta_t =
\eta_0 e^{-\lambda t}\)</span></li>
<li><strong>多项式衰减</strong>：<span class="math inline">\(\eta_t =
\eta_0 (\beta t + 1)^{-\alpha}\)</span></li>
</ul>
<p><img src="/images/Fundamentals-Optimization/9.png" srcset="/img/loading.gif" lazyload></p>
<p>在许多情况下，梯度的大小在各个维度之间可能差异很大，导致损失面在某些方向上陡峭而在其他方向上较为平坦，类似于一个山谷的底部。在这种情况下，可以用条件矩阵<span class="math inline">\(C_t\)</span>来缩放梯度向量，从而实现更快的收敛：</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t - \eta_t C_t
g_t\]</span></p>
<p>这被称为<strong>预条件 SGD</strong>。</p>
<h3 id="sgd-用于优化有限和目标">2. SGD 用于优化有限和目标</h3>
<p>在最简单的情况下，计算期望的分布<span class="math inline">\(q_\theta(z)\)</span>不依赖于正在优化的参数<span class="math inline">\(\theta\)</span>（即噪声或者数据与参数无关）。在这种情况下，我们可以将梯度推入期望算子内部，然后通过
<strong>Monte Carlo 采样</strong>来近似梯度：</p>
<p><span class="math display">\[\begin{align*} \nabla_\theta L(\theta)
&amp;= \nabla_\theta \mathbb{E}_{q(z)} \left[ \tilde{L}(\theta, z)
\right] \\ &amp;= \mathbb{E}_{q(z)} \left[ \nabla_\theta
\tilde{L}(\theta, z) \right] \\ &amp;\approx \frac{1}{S} \sum_{s=1}^{S}
\nabla_\theta \tilde{L}(\theta, z_s) \end{align*}\]</span></p>
<p>其中<span class="math inline">\(S\)</span>是采样数量。例如，考虑经验风险最小化（ERM）的问题，要求最小化：</p>
<p><span class="math display">\[L(\theta) = \frac{1}{N} \sum_{n=1}^{N}
\tilde{L}(\theta, z_n) = \frac{1}{N} \sum_{n=1}^{N} \ell(y_n, f(x_n;
\theta))\]</span></p>
<p>其中<span class="math inline">\(z_n = (x_n, y_n)\)</span>是第<span class="math inline">\(n\)</span>个标记示例，<span class="math inline">\(f\)</span>是预测函数。这种目标称为有限和目标。我们可以将其写为关于经验分布<span class="math inline">\(p_D(x, y)\)</span>的期望损失：</p>
<p><span class="math display">\[L(\theta) = \mathbb{E}_{p_D(z)} \left[
\tilde{L}(\theta, z) \right]\]</span></p>
<p>由于期望依赖于数据，而不是参数，我们可以通过在每次迭代中使用来自完整数据集<span class="math inline">\(D\)</span>的<span class="math inline">\(B =
|B|\)</span>个数据点的小批量来近似梯度：</p>
<p><span class="math display">\[g_t = \nabla L(\theta_t) = \frac{1}{B}
\sum_{n \in B} \nabla \ell(y_n, f(x_n; \theta))\]</span></p>
<p>这些带噪声的梯度可以传递给
SGD。当数据集很大时，这种方法比全批梯度下降快得多，因为它不需要在更新模型之前评估所有示例的损失
。</p>
<h3 id="sgd-用于优化分布的参数">3. SGD 用于优化分布的参数</h3>
<p>现在假设随机性依赖于我们正在优化的参数。例如，在强化学习中，<span class="math inline">\(z\)</span>可能是从随机策略<span class="math inline">\(q_\theta\)</span>​
中采样的动作，或者在随机变分推理中，<span class="math inline">\(z\)</span>可能是从推理网络<span class="math inline">\(q_\theta\)</span>​ 中采样的潜变量。</p>
<p>在这种情况下，梯度为：</p>
<p><span class="math display">\[\begin{align*} \nabla_\theta
\mathbb{E}_{q_\theta(z)}\left[\tilde{L}(\theta, z)\right] &amp;=
\nabla_\theta \int \tilde{L}(\theta, z) q_\theta(z) \, dz \\ &amp;= \int
\nabla_\theta \tilde{L}(\theta, z) q_\theta(z) \, dz \\ &amp;= \int
\left[\nabla_\theta \tilde{L}(\theta, z)\right] q_\theta(z) \, dz + \int
\tilde{L}(\theta, z) \left[\nabla_\theta q_\theta(z)\right] \, dz
\end{align*}\]</span></p>
<p>第一个项可以通过 <strong>Monte Carlo 采样</strong>近似：</p>
<p><span class="math display">\[\int \left[ \nabla_\theta
\tilde{L}(\theta, z) \right] q_\theta(z) dz \approx \frac{1}{S}
\sum_{s=1}^{S} \nabla_\theta \tilde{L}(\theta, z_s)\]</span></p>
<p>其中<span class="math inline">\(z_s \sim q_\theta\)</span>​。</p>
<p>现在考虑第二项，注意，如果<span class="math inline">\(\tilde{L}\)</span>与<span class="math inline">\(\theta\)</span>无关，则此项消失，但如果相关，则该项涉及分布本身的梯度：</p>
<p><span class="math display">\[I \equiv \int \tilde{L}(\theta, z)
[\nabla_\theta q_\theta(z)] dz\]</span></p>
<p>我们不能再使用简单的 Monte Carlo
采样来近似这个积分。然而，还有其他各种方法可以近似这个积分。将在后面简要描述两种主要方法。</p>
<h3 id="分数函数估计器reinforce">4 分数函数估计器（REINFORCE）</h3>
<p>分数函数是对数概率分布的梯度，其表达式为：<br>
<span class="math display">\[\nabla_\theta  q_\theta(z) = q_\theta(z)
\nabla_\theta \log q_\theta(z)\]</span></p>
<p>利用上述分数函数定义，可以将积分式的目标函数梯度表达式重新写为：<br>
<span class="math display">\[\begin{align*} I &amp;= \int
\tilde{L}(\theta, z) [q_\theta(z) \nabla_\theta \log q_\theta(z)] \, dz
\\ &amp;= \mathbb{E}_{q_\theta(z)}\left[\tilde{L}(\theta, z)
\nabla_\theta \log q_\theta(z)\right]  \end{align*}\]</span></p>
<p>这里，<span class="math inline">\(I\)</span>表示我们要计算的梯度期望。</p>
<p>通过蒙特卡洛方法，可以对上述积分进行近似：<br>
<span class="math display">\[I \approx \frac{1}{S} \sum_{s=1}^{S}
\tilde{L}(\theta, z_s) \nabla_\theta \log q_\theta(z_s)\]</span></p>
<p>其中<span class="math inline">\(z_s \sim q_\theta\)</span>​。</p>
<p>为了降低分数函数估计的方差，可以使用<strong>控制变量</strong>的方法，将<span class="math inline">\(\tilde{L}(\theta, z)\)</span>替换为：<br>
<span class="math display">\[\hat{\tilde{L}}(\theta, z) =
\tilde{L}(\theta, z) - c \left(b(\theta, z) - \mathbb{E}[b(\theta,
z)]\right)\]</span></p>
<p>这里，<span class="math inline">\(b(\theta, z)\)</span>是与<span class="math inline">\(\tilde{L}(\theta, z)\)</span>相关的基线函数，<span class="math inline">\(c &gt; 0\)</span>是一个系数。使用此新的估计<span class="math inline">\(\hat{\tilde{L}}\)</span>计算的梯度估计仍然是无偏的，但具有较低的方差。</p>
<p>当<span class="math inline">\(q_\theta(z)\)</span>是离散分布时，目标函数为：<br>
<span class="math display">\[L(\theta) = \sum_{z} \tilde{L}(\theta, z)
q_\theta(z)\]</span></p>
<p>梯度计算为：<br>
<span class="math display">\[\nabla_\theta L(\theta) = \sum_{z}
\tilde{L}(\theta, z) \nabla_\theta q_\theta(z)\]</span></p>
<p>如果<span class="math inline">\(z\)</span>可以取指数级多的值，直接计算可能不可行。可以将和分为两部分：一部分<span class="math inline">\(S_1\)</span>​ 是高概率值的小集合，另一部分<span class="math inline">\(S_2\)</span>​
是所有其他值的大集合。梯度的计算可以表达为：<br>
<span class="math display">\[\nabla_\theta L(\theta) = \sum_{z \in S_1}
\tilde{L}(\theta, z) \nabla_\theta q_\theta(z) +
\mathbb{E}_{q_\theta(z|z \in S_2)}\left[\tilde{L}(\theta, z)
\nabla_\theta \log q_\theta(z)\right]\]</span></p>
<p>对于第二项的计算，可以使用拒绝采样的方法，用来自<span class="math inline">\(q_\theta(z)\)</span>的样本进行近似。这种方法就是<strong>拉奥-布莱克威尔化(Rao-Blackwellization)</strong>，能够有效减少方差。</p>
<h3 id="重参数化技巧">5. 重参数化技巧</h3>
<p><strong>重参数化技巧</strong>用于降低得分函数估计器的方差，前提是<span class="math inline">\(\tilde{L}(\theta, z)\)</span>对<span class="math inline">\(z\)</span>可微，并且可以通过先从一个与<span class="math inline">\(\theta\)</span>无关的噪声分布<span class="math inline">\(q_0\)</span>中采样<span class="math inline">\(\epsilon\)</span>，然后通过确定性和可微的函数<span class="math inline">\(z = g(\theta, \epsilon)\)</span>转换得到<span class="math inline">\(z\)</span>。<br>
例如，可以从标准正态分布中采样：<br>
<span class="math display">\[z = g(\theta, \epsilon) = \mu + \sigma
\epsilon\]</span></p>
<p>其中<span class="math inline">\(\theta = (\mu, \sigma)\)</span>。</p>
<p>我们可以将目标函数重写为：<br>
<span class="math display">\[L(\theta) =
\mathbb{E}_{q_\theta(z)}\left[\tilde{L}(\theta, z)\right] =
\mathbb{E}_{q_0(\epsilon)}\left[\tilde{L}(\theta, g(\theta,
\epsilon))\right]\]</span></p>
<p>由于<span class="math inline">\(q_0(\epsilon)\)</span>与<span class="math inline">\(\theta\)</span>无关，可以将梯度算子推入期望中，从而获得：<br>
<span class="math display">\[\nabla_\theta L(\theta) =
\mathbb{E}_{q_0(\epsilon)}\left[\nabla_\theta \tilde{L}(\theta,
g(\theta, \epsilon))\right]\]</span></p>
<p>通过蒙特卡洛方法进行近似：<br>
<span class="math display">\[\nabla_\theta L(\theta) \approx \frac{1}{S}
\sum_{s=1}^{S} \nabla_\theta \tilde{L}(\theta, g(\theta,
\epsilon_s))\]</span></p>
<p><img src="/images/Fundamentals-Optimization/10.png" srcset="/img/loading.gif" lazyload></p>
<p>当<span class="math inline">\(\tilde{L}\)</span>依赖于<span class="math inline">\(\theta\)</span>和噪声样本<span class="math inline">\(z\)</span>时，需要使用总导数计算梯度。对于形式为<span class="math inline">\(\tilde{L}(\theta_1, \ldots, \theta_d, z_1(\theta),
\ldots, z_d(\theta))\)</span>的函数，其对<span class="math inline">\(\theta_i\)</span>的总导数为：<br>
<span class="math display">\[\frac{\partial \tilde{L}}{\partial
\theta_i}\bigg|_{TD} = \frac{\partial \tilde{L}}{\partial \theta_i} +
\sum_j \frac{\partial \tilde{L}}{\partial z_j} \frac{\partial
z_j}{\partial \theta_i}\]</span></p>
<p>进而得到：<br>
<span class="math display">\[\nabla_\theta \tilde{L}(\theta,
z)\bigg|_{TD} = \nabla_z \tilde{L}(\theta, z) J + \nabla_\theta
\tilde{L}(\theta, z)\]</span></p>
<p>其中，<span class="math inline">\(J\)</span>为噪声变换的雅可比矩阵：<span class="math inline">\(J = \frac{\partial z}{\partial
\theta}\)</span>，这也是一种计算方法。</p>
<p>特别的，在变分推断中，ELBO（证据下界）目标形式为：<br>
<span class="math display">\[\tilde{L}(\theta, z) = \log p(z, x) - \log
q(z|\theta)\]</span></p>
<p>梯度为：<br>
<span class="math display">\[\nabla_\theta \tilde{L}(\theta, z) =
\nabla_z \left[\log p(z, x) - \log q(z|\theta)\right] J - \nabla_\theta
\log q(z|\theta)\]</span></p>
<p>这里第一项是通过生成样本<span class="math inline">\(z\)</span>对目标的间接影响，第二项是<span class="math inline">\(\theta\)</span>对目标的直接影响。第二项在期望上为零，但在有限样本中可能非零。为了减少方差，可以使用“断开”的<span class="math inline">\(\theta&#39;\)</span>替代<span class="math inline">\(\theta\)</span>来计算：<br>
<span class="math display">\[g = \nabla_\theta \left[\log p(z, x) - \log
q(z|\theta&#39;)\right]\]</span></p>
<p>其它项如下：<br>
<span class="math display">\[\epsilon \sim q_0(\epsilon) \\ z =
g(\epsilon, \theta) \\θ′=stop-gradient(θ)\]</span></p>
<p>这被叫做<strong>sticking the landing or STL
estimator</strong>。需要指出的，这不一定比不忽略第二项的效果更好，实际中可以使用这两者的加权平均。</p>
<h3 id="gumbel-softmax技巧">6. Gumbel Softmax技巧</h3>
<p>在处理离散变量时，传统的重参数化技巧不可用。但是，我们可以将离散变量放松为连续变量，从而实现类似的效果。</p>
<p>考虑一个包含<span class="math inline">\(K\)</span>位的 one-hot
向量<span class="math inline">\(d\)</span>，其中<span class="math inline">\(d_k \in \{0, 1\}\)</span>且<span class="math inline">\(\sum_{k=1}^{K} d_k =
1\)</span>。这可以用于表示一个<span class="math inline">\(K\)</span>-元的分类变量。设<span class="math inline">\(P(d) = \text{Cat}(d|\pi)\)</span>，其中<span class="math inline">\(\pi_k = P(d_k = 1)\)</span>，满足<span class="math inline">\(0 \leq \pi_k \leq
1\)</span>。我们也可以将分布参数化为<span class="math inline">\((\alpha_1, \ldots, \alpha_K)\)</span>，其中<span class="math inline">\(\pi_k = \frac{\alpha_k}{\sum_{k&#39; = 1}^{K}
\alpha_{k&#39;}}\)</span>​​。我们记作<span class="math inline">\(d \sim
\text{Cat}(d|\alpha)\)</span>。</p>
<p>我们可以通过以下公式从该分布计算 one-hot 向量<span class="math inline">\(d\)</span>：<br>
<span class="math display">\[d =
\text{onehot}\left(\arg\max_k\left[\epsilon_k + \log
\alpha_k\right]\right)\]</span></p>
<p>其中<span class="math inline">\(\epsilon_k \sim \text{Gumbel}(0,
1)\)</span>，从 Gumbel 分布中采样。可以通过先采样<span class="math inline">\(u_k \sim \text{Uniform}(0,
1)\)</span>，然后计算<span class="math inline">\(\epsilon_k =
-\log(-\log(u_k))\)</span>来得到。<strong>Gumbel-Max Trick</strong>
提供了分类分布的重参数化表示。遗憾的是，<span class="math inline">\(argmax\)</span>的导数在边界处未定义，这使得梯度计算变得复杂。</p>
<p>为了克服这个问题，我们可以将<span class="math inline">\(argmax\)</span>替换为<span class="math inline">\(softmax\)</span>，并将离散的 one-hot 向量<span class="math inline">\(d\)</span>替换为连续放松<span class="math inline">\(x \in \Delta^{K-1}\)</span>，其中<br>
<span class="math display">\[\Delta^{K-1} = \{ x \in \mathbb{R}^K : x_k
\in [0, 1], \sum_{k=1}^{K} x_k = 1 \}\]</span></p>
<p>这样我们可以写出：<br>
<span class="math display">\[x_k = \frac{\exp\left(\frac{\log \alpha_k +
\epsilon_k}{\tau}\right)}{\sum_{k&#39; = 1}^{K} \exp\left(\frac{\log
\alpha_{k&#39;} + \epsilon_{k&#39;}}{\tau}\right)}\]</span></p>
<p>其中<span class="math inline">\(\tau &gt;
0\)</span>是温度参数。随着<span class="math inline">\(\tau \to
0\)</span>，这个分布平滑地接近离散分布。通过将<span class="math inline">\(f(d)\)</span>替换为<span class="math inline">\(f(x)\)</span>，我们可以对<span class="math inline">\(x\)</span>进行重参数化梯度计算。这允许我们在进行优化时有效地处理离散变量。</p>
<p><img src="/images/Fundamentals-Optimization/11.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="直通估计器-straight-through-estimator">7. 直通估计器
(Straight-Through Estimator)</h3>
<p>直通估计器主要用于近似量化信号的梯度。考虑一个阈值函数：<br>
<span class="math display">\[f(x) = \begin{cases} 1 &amp; \text{if } x
&gt; 0 \\ 0 &amp; \text{if } x \leq 0 \end{cases}\]</span></p>
<p>这个函数没有定义良好的梯度，因为它是一个分段常数函数。</p>
<p>直通估计器的基本思想是，在反向传播过程中将<span class="math inline">\(g(x) = f&#39;(x)\)</span>的计算替换为<span class="math inline">\(g(x) =
x\)</span>。这样做的好处是可以在没有梯度的情况下为网络的训练提供一个近似值。
在实际应用中，我们有时会用硬双曲正切函数替代<span class="math inline">\(g(x) = x\)</span>，其定义为：<br>
<span class="math display">\[\text{HardTanh}(x) = \begin{cases} x &amp;
\text{if } -1 \leq x \leq 1 \\ 1 &amp; \text{if } x &gt; 1 \\ -1 &amp;
\text{if } x &lt; -1 \end{cases}\]</span></p>
<p>这种替代确保了反向传播的梯度不会变得过大，有助于稳定训练过程。</p>
<h2 id="三自然梯度下降">三、自然梯度下降</h2>
<p><strong>自然梯度下降（Natural Gradient
Descent，NGD）</strong>是一种优化方法，主要用于优化条件概率分布<span class="math inline">\(p_\theta(y|x)\)</span>的参数。与常规的梯度下降方法不同，NGD
通过测量引发的分布之间的距离来计算参数更新，而不是直接使用参数值的距离。这种方法特别适用于处理参数间相互作用较强的情况，比如在高维空间中的概率分布。</p>
<p>以两个高斯分布为例，<span class="math inline">\(p_\theta = p(y|\mu,
\sigma)\)</span>和<span class="math inline">\(p_{\theta&#39;} =
p(y|\mu&#39;,
\sigma&#39;)\)</span>。如果直接计算参数向量之间的欧几里得距离：<br>
<span class="math display">\[||\theta - \theta&#39; ||^2 = (\mu -
\mu&#39;)^2 + (\sigma - \sigma&#39;)^2\]</span></p>
<p>并不能反映出分布的真实变化。实际上，预测分布的形式为：<br>
<span class="math display">\[\exp\left(-\frac{1}{2\sigma^2}(y -
\mu)^2\right)\]</span></p>
<p>这意味着，均值<span class="math inline">\(\mu\)</span>对于不同的方差<span class="math inline">\(\sigma\)</span>的影响大小会有区别。下图 (a-b)
说明了当方差较小和较大时，均值变化对分布的影响是不同的。明显方差小的
时候均值的影响会更大</p>
<p><img src="/images/Fundamentals-Optimization/12.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="自然梯度的定义">1. 自然梯度的定义</h3>
<p>NGD 的关键在于用 KL
散度来度量两个概率分布之间的距离。根据之前的推导，我们有：<br>
<span class="math display">\[D_{KL}(p_\theta(y|x) \parallel
p_{\theta+\delta}(y|x)) \approx \frac{1}{2} \delta^T F_x
\delta\]</span></p>
<p>其中<span class="math inline">\(F_x\)</span>​ 是 <strong>Fisher
信息矩阵 (FIM)</strong>，定义为：<br>
<span class="math display">\[F_x(\theta) =
-\mathbb{E}_{p_\theta(y|x)}\left[\nabla^2 \log p_\theta(y|x)\right] =
\mathbb{E}_{p_\theta(y|x)}\left[(\nabla \log p_\theta(y|x))(\nabla \log
p_\theta(y|x))^T\right]\]</span></p>
<p>我们可以使用平均 FIM 来计算当前和更新分布之间的平均 KL 散度：<br>
<span class="math display">\[F(\theta) =
\mathbb{E}_{p_D(x)}\left[F_x(\theta)\right]\]</span></p>
<p>自然梯度下降通过使用 FIM 的逆作为预条件矩阵来进行参数更新：<br>
<span class="math display">\[\theta_{t+1} = \theta_t - \eta_t
F(\theta_t)^{-1} g_t\]</span></p>
<p>其中<span class="math inline">\(g_t\)</span>​ 是常规梯度。</p>
<p>因此，定义自然梯度为：<br>
<span class="math display">\[F^{-1} g_t = F^{-1} \nabla L(\theta_t)
\equiv \tilde{\nabla} L(\theta_t)\]</span></p>
<h3 id="自然梯度下降的解释">2. 自然梯度下降的解释</h3>
<p>标准的梯度下降可以被理解为在目标函数的线性近似下进行优化，同时对参数变化的<span class="math inline">\(\ell_2\)</span>​ 范数施加惩罚。如果设定<span class="math inline">\(\theta_{t+1} = \theta_t +
\delta\)</span>，我们优化的目标为：<br>
<span class="math display">\[M_t(\delta) = L(\theta_t) + g_t^T \delta +
\eta \frac{||\delta||^2}{2}\]</span></p>
<p>其中<span class="math inline">\(g_t\)</span>​ 是在点<span class="math inline">\(\theta_t\)</span>处的梯度，<span class="math inline">\(\eta\)</span>是步长。</p>
<p><img src="/images/Fundamentals-Optimization/13.png" srcset="/img/loading.gif" lazyload></p>
<p>现在我们用基于 Fisher 信息矩阵 (FIM) 的距离替换平方距离，即：<br>
<span class="math display">\[||\delta||^2_F = \delta^T F
\delta\]</span></p>
<p>这在<strong>whitened coordinate
system</strong>中是等价的，即使用<span class="math inline">\(\phi =
F^{1/2} \theta\)</span>进行变换。我们可以得到：<br>
<span class="math display">\[||\phi_{t+1} - \phi_t||^2 = ||F^{1/2}
(\theta_t + \delta) - F^{1/2} \theta_t||^2 = ||F^{1/2} \delta||^2 =
||\delta||^2_F\]</span></p>
<p>则新的优化目标变为：<br>
<span class="math display">\[M_t(\delta) = L(\theta_t) + g_t^T \delta +
\eta \delta^T F \delta\]</span></p>
<p>通过求解<span class="math inline">\(\nabla_\delta M_t(\delta) =
0\)</span>，我们可以得到更新公式：<br>
<span class="math display">\[\delta_t = -\eta F^{-1} g_t\]</span></p>
<p>这与自然梯度的方向一致。因此，我们可以将 NGD 视为一种<strong>trust
region method</strong>，其中使用了目标函数的一阶近似，并在约束中使用 FIM
距离。</p>
<p>在上述推导中，我们假设 F 是常数矩阵。在大多数问题中，FIM
会在空间中的每个点上变化，这意味着我们是在一个黎曼流形的曲面上进行优化。对于某些模型，尽管我们还是使用目标函数的一阶近似，我们仍然可以高效地计算
FIM，捕捉曲率信息。</p>
<p>如果<span class="math inline">\(p(y|x,
\theta)\)</span>是一个指数族分布，其自然参数由<span class="math inline">\(\eta = f(x, \theta)\)</span>计算，那么可以证明 NGD
实际上与<strong>广义高斯-牛顿（GGN）方法</strong>是相同的 。这意味着 NGD
在某些情况下可以看作是高斯-牛顿优化方法的应用。</p>
<h3 id="自然梯度下降-ngd-的优点">3. 自然梯度下降 (NGD) 的优点</h3>
<p>使用 FIM 作为预处理矩阵的一个主要优点是 FIM
总是正定的，而海森矩阵（Hessian）在鞍点处可能具有负特征值。这在高维空间中很常见，可能导致优化过程的不稳定。</p>
<p>同时FIM
可以通过小批量数据简单地在线近似，因为它是关于梯度向量外积的期望：<br>
<span class="math display">\[F_x(\theta) = \mathbb{E}_{p_\theta(y|x)}
\left[ (\nabla \log p_\theta(y|x))(\nabla \log p_\theta(y|x))^T
\right]\]</span></p>
<p>与之相比，研究显示，基于海森矩阵的方法对小批量数据引入的噪声非常敏感。</p>
<p>NGD
更新参数的方式侧重于对预测最重要的部分，这使得在不确定区域中可以采取更大的步骤，从而帮助避免陷入平坦区域或鞍点。</p>
<p>以一个二维高斯为例子：</p>
<p><img src="/images/Fundamentals-Optimization/14.png" srcset="/img/loading.gif" lazyload></p>
<p>在梯度下降过程中，NGD能够更快地收敛到全局最优解，相较于普通的梯度下降方法，NGD
在参数空间中的运动更加直接和高效。同时 NGD
对概率分布的参数化方式不敏感，因此即使在复杂的概率模型中（例如深度神经网络），也能保持同样的收敛效果。</p>
<p>一个具体的对比如下：</p>
<p><img src="/images/Fundamentals-Optimization/15.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="近似自然梯度">4. 近似自然梯度</h3>
<p>NGD 的主要缺点是计算 FIM
（及其逆）的计算成本较高。为了加速计算，一些方法对 FIM
的形式做出假设，以便高效地反转。例如：</p>
<p>有学者提出了 <strong>KFAC 方法（Kronecker Factored Approximate
Curvature）</strong>，该方法将深度神经网络的 FIM
近似为一个块对角矩阵，每个块是两个小矩阵的 Kronecker
积。这种方法在监督学习和强化学习中表现良好，并且已被证明在过参数化情况下能够收敛到
DNN 的全局最优解。</p>
<p>另一种简化方法是使用经验分布来近似 FIM。具体定义如下：<br>
<span class="math display">\[\begin{align*} F &amp;=
\mathbb{E}_{p_\theta(x,y)} \left[ \nabla \log p(y|x, \theta) \nabla \log
p(y|x, \theta)^T \right] \\ &amp;\approx \mathbb{E}_{p_D(x,y)} \left[
\nabla \log p(y|x, \theta) \nabla \log p(y|x, \theta)^T \right] \\
&amp;= \frac{1}{|D|} \sum_{(x,y) \in D} \nabla \log p(y|x, \theta)
\nabla \log p(y|x, \theta)^T \end{align*}\]</span></p>
<p>这种近似方法易于计算，但在平坦区域，经验 Fisher
可能变得奇异，从而导致算法陷入停滞。</p>
<p>另一种策略是精确计算
F，但使用<strong>截断共轭梯度（CG）方法</strong>近似计算<span class="math inline">\(F^{-1}g\)</span>，其中每一步 CG
使用高效的海森-向量乘法方法。但这种方法可能较慢，因为进行单次参数更新需要许多
CG 迭代。</p>
<h3 id="自然梯度对于指数族的应用">5. 自然梯度对于指数族的应用</h3>
<p>假设损失函数<span class="math inline">\(L\)</span>具有以下形式的期望损失：</p>
<p><span class="math display">\[L(\mu) =
\mathbb{E}_{q_\mu(z)}\left[\tilde{L}(z)\right]\]</span></p>
<p>其中<span class="math inline">\(q_\mu(z)\)</span>是具有矩参数<span class="math inline">\(\mu\)</span>的指数族分布。</p>
<p>事实证明，相对于矩参数的梯度与自然参数<span class="math inline">\(\lambda\)</span>的自然梯度是相同的。这是通过链式法则得出的：</p>
<p><span class="math display">\[\frac{d}{d\lambda} L(\lambda) =
\frac{d\mu}{d\lambda} \frac{d}{d\mu} L(\mu) = F(\lambda) \nabla_\mu
L(\mu)\]</span></p>
<p>其中<span class="math inline">\(L(\mu) =
L(\lambda(\mu))\)</span>，并且：</p>
<p><span class="math display">\[F(\lambda) = \nabla_\lambda \mu(\lambda)
= \nabla^2_\lambda A(\lambda)\]</span></p>
<p>因此，</p>
<p><span class="math display">\[\tilde{\nabla}_{\lambda} L(\lambda) =
F(\lambda)^{-1} \nabla_\lambda L(\lambda) = \nabla_\mu
L(\mu)\]</span></p>
<p>接下来需要计算相对于矩参数的标注梯度。具体如何进行计算将取决于<span class="math inline">\(q\)</span>的形式以及<span class="math inline">\(L(\lambda)\)</span>的形式。</p>
<h4 id="高斯情况下的解析计算">5.1 高斯情况下的解析计算</h4>
<p>假设分布<span class="math inline">\(q(z) = \mathcal{N}(z|m,
V)\)</span>，我们推导如何计算与矩参数（moment
parameters）相关的自然梯度。</p>
<p>根据Probability中对高斯分布的介绍，我们有</p>
<ul>
<li>自然参数：<span class="math inline">\(\lambda^{(1)} = V^{-1}m, \quad
\lambda^{(2)} = -\frac{1}{2} V^{-1}\)</span></li>
<li>矩参数：<span class="math inline">\(\mu^{(1)} = m, \quad \mu^{(2)} =
V + mm^T\)</span></li>
</ul>
<p>通过链式法则计算梯度：</p>
<p>对于矩参数的梯度，我们有：</p>
<p><span class="math display">\[\begin{align*} &amp;\frac{\partial
L}{\partial \mu^{(1)}} = \frac{\partial L}{\partial m} \frac{\partial
m}{\partial \mu^{(1)}} + \frac{\partial L}{\partial v} \frac{\partial
v}{\partial \mu^{(1)}}  = \frac{\partial L}{\partial m} - 2
\frac{\partial L}{\partial v} m \\  &amp;\frac{\partial L}{\partial
\mu^{(2)}} = \frac{\partial L}{\partial m} \frac{\partial m}{\partial
\mu^{(2)}} + \frac{\partial L}{\partial v} \frac{\partial v}{\partial
\mu^{(2)}} = \frac{\partial L}{\partial v} \end{align*}\]</span></p>
<p>通过 Bonnet 定理和 Price 定理，我们可以得到： <span class="math display">\[\frac{\partial}{\partial m_i} \mathbb{E}\left[
\tilde{L}(z) \right] = \mathbb{E}\left[ \frac{\partial}{\partial
\theta_i} \tilde{L}(z) \right] \\\frac{\partial}{\partial V_{ij}}
\mathbb{E}\left[ \tilde{L}(z) \right] = c_{ij} \mathbb{E}\left[
\frac{\partial^2}{\partial \theta_i \partial \theta_j} \tilde{L}(z)
\right]\]</span></p>
<p>多变量情况下的结果：<br>
<span class="math display">\[\begin{align*} \nabla_{\mu^{(1)}} E_q(z)
\left[ \tilde{L}(z) \right] &amp;= \nabla_m E_q(z) \left[ \tilde{L}(z)
\right] - 2 \nabla_V E_q(z) \left[ \tilde{L}(z) \right] m \\  &amp;=
E_q(z) \left[ \nabla_z \tilde{L}(z) \right] - E_q(z) \left[ \nabla^2_z
\tilde{L}(z) \right] m \\  \nabla_{\mu^{(2)}} E_q(z) \left[ \tilde{L}(z)
\right] &amp;= \nabla_V E_q(z) \left[ \tilde{L}(z) \right] \\  &amp;=
\frac{1}{2} E_q(z) \left[ \nabla^2_z \tilde{L}(z) \right]
\end{align*}\]</span></p>
<h4 id="一般情况下的随机近似">5.2 一般情况下的随机近似</h4>
<p>在一般情况下，解析计算自然梯度可能很困难。可以使用<strong>蒙特卡洛近似</strong>。</p>
<p>期望损失的定义：<br>
<span class="math display">\[L(\mu) =
\mathbb{E}_{q_\mu(z)}[\tilde{L}(z)]\]</span></p>
<p>自然梯度的表达：<br>
<span class="math display">\[\nabla_\mu L(\mu) = F(\lambda)^{-1}
\nabla_\lambda L(\lambda)\]</span></p>
<p>期望的近似：<br>
<span class="math display">\[\begin{align*} F(\lambda) &amp;=
\nabla_\lambda \mu(\lambda) = \nabla_\lambda E_{q_\lambda}(z) \left[
T(z) \right] \\  \nabla_\lambda L(\lambda) &amp;= \nabla_\lambda
E_{q_\lambda}(z) \left[ \tilde{L}(z) \right] \end{align*}\]</span></p>
<p>如果<span class="math inline">\(q\)</span>是可重参数化的，可以使用重参数化技巧将梯度推入期望算子内，从而对样本<span class="math inline">\(z\)</span>进行采样并计算梯度。</p>
<h4 id="熵的自然梯度">5.3 熵的自然梯度</h4>
<p>自然梯度<span class="math inline">\(\tilde{\nabla}_{\lambda}
H(\lambda)\)</span>表示指数族分布的熵<span class="math inline">\(H(\lambda)\)</span>相对于自然参数<span class="math inline">\(\lambda\)</span>的梯度，其公式为：</p>
<p><span class="math display">\[\tilde{\nabla}_{\lambda} H(\lambda) =
-\nabla_\mu \mathbb{E}_{q_\mu(z)}[\log q(z)]\]</span></p>
<p>我们可以将<span class="math inline">\(q(z)\)</span>的对数表示为：</p>
<p><span class="math display">\[\log q(z) = \log h(z) + T(z)^T \lambda -
A(\lambda)\]</span></p>
<p>期望的梯度</p>
<p>由于<span class="math inline">\(E[T(z)] =
\mu\)</span>，我们可以对<span class="math inline">\(\log
q(z)\)</span>求<span class="math inline">\(\mu\)</span>的梯度：</p>
<p><span class="math display">\[\nabla_\mu E_{q_\mu(z)}[\log q(z)] =
\nabla_\mu E_{q(z)}[\log h(z)] + \nabla_\mu \mu^T \lambda(\mu) -
\nabla_\mu A(\lambda)\]</span></p>
<p>因为<span class="math inline">\(\lambda\)</span>是<span class="math inline">\(\mu\)</span>的函数，我们有：</p>
<p><span class="math display">\[\nabla_\mu \mu^T \lambda = \lambda +
(\nabla_\mu \lambda)^T \mu = \lambda + (F^{-1}_\lambda \nabla_\lambda
\lambda)^T \mu = \lambda + F^{-1}_\lambda \mu\]</span></p>
<p>这里<span class="math inline">\(F(\lambda)\)</span>是Fisher信息矩阵。由<span class="math inline">\(\mu = \nabla_\lambda A(\lambda)\)</span>可得：</p>
<p><span class="math display">\[\nabla_\mu A(\lambda) = F^{-1}_\lambda
\nabla_\lambda A(\lambda) = F^{-1}_\lambda \mu\]</span></p>
<p>将以上结果代入，我们得到：</p>
<p><span class="math display">\[-\nabla_\mu \mathbb{E}_{q_\mu(z)}[\log
q(z)] = -\nabla_\mu \mathbb{E}_q[\log h(z)] - \lambda\]</span></p>
<p>如果我们假设<span class="math inline">\(h(z)\)</span>是常数（这种情况在许多实际应用中成立），则得到：</p>
<p><span class="math display">\[\tilde{\nabla}_{\lambda} H(\lambda) =
-\lambda\]</span></p>
<h2 id="四边界优化mm算法">四、边界优化（MM）算法</h2>
<p><strong>边界优化（Bound optimization）</strong>或者称为
<strong>MM（Majorize-Minimize）算法</strong>该方法主要通过构造一个次级函数<span class="math inline">\(Q(\theta,
\theta^t)\)</span>，使其成为目标函数<span class="math inline">\(\ell(\theta)\)</span>的下界，来最大化目标函数<span class="math inline">\(\ell(\theta)\)</span>。这种方法在许多应用中都非常有效，例如期望最大化（EM）算法和一些聚类算法。</p>
<h3 id="一般算法">1. 一般算法</h3>
<p>我们的目标是最大化某个函数<span class="math inline">\(\ell(\theta)\)</span>，MM算法的基本思路是构造一个代理函数<span class="math inline">\(Q(\theta, \theta^t)\)</span>，使其满足以下条件</p>
<p><em><span class="math inline">\(Q(\theta, \theta^t) \leq
\ell(\theta)\)</span> </em><span class="math inline">\(Q(\theta^t,
\theta^t) = \ell(\theta^t)\)</span></p>
<p>如果满足这些条件，我们称<span class="math inline">\(Q\)</span>小于等于<span class="math inline">\(\ell\)</span>。然后在每一步进行如下更新：</p>
<p><span class="math display">\[\theta^{t+1} = \arg\max_\theta Q(\theta,
\theta^t)\]</span></p>
<p>这一过程保证了原始目标函数的单调增加：</p>
<p><span class="math display">\[\ell(\theta^{t+1}) \geq Q(\theta^{t+1},
\theta^t) \geq Q(\theta^t, \theta^t) = \ell(\theta^t)\]</span></p>
<p>这保证了每一步都会提升目标函数的值。</p>
<p><img src="/images/Fundamentals-Optimization/16.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="示例逻辑回归">2 示例：逻辑回归</h3>
<p>在逻辑回归中，如果我们希望最大化的函数<span class="math inline">\(\ell(\theta)\)</span>是一个凹函数，可以通过对其海森矩阵（Hessian）进行界定来构造有效的下界。即寻找一个负定矩阵<span class="math inline">\(B\)</span>使得<span class="math inline">\(H(\theta) \succ B\)</span></p>
<p>通过泰勒展开，可以证明：</p>
<p><span class="math display">\[\ell(\theta) \geq \ell(\theta^t) +
(\theta - \theta^t)^T g(\theta^t) + \frac{1}{2} (\theta - \theta^t)^T B
(\theta - \theta^t)\]</span></p>
<p>其中<span class="math inline">\(g(\theta^t) = \nabla
\ell(\theta^t)\)</span>。</p>
<p>因此，可以构造以下有效的下界（这里的等于是泰勒展开前两项意义下的相等）：</p>
<p><span class="math display">\[Q(\theta, \theta^t) = \theta^T
(g(\theta^t) - B\theta^t) + \frac{1}{2} \theta^T B \theta\]</span></p>
<p>对应的更新规则变为：</p>
<p><span class="math display">\[\theta^{t+1} = \theta^t - B^{-1}
g(\theta^t)\]</span></p>
<p>这类似于牛顿法的更新，但使用的是固定的矩阵<span class="math inline">\(B\)</span>，而不是每次迭代时变化的海森矩阵<span class="math inline">\(H(\theta^t)\)</span>。</p>
<h4 id="应用示例多类逻辑回归">2.1 应用示例：多类逻辑回归</h4>
<p>以多类逻辑回归为例，假设<span class="math inline">\(p(y_n = c | x_n,
w)\)</span>表示样本<span class="math inline">\(n\)</span>属于类<span class="math inline">\(c\)</span>的概率，公式为：</p>
<p><span class="math display">\[p(y_n = c|x_n, w) = \frac{e^{w_c^T
x_n}}{\sum_{i=1}^C e^{w_i^T x_n}}\]</span></p>
<p>由于归一化条件，我们可以只学习<span class="math inline">\(C-1\)</span>个<span class="math inline">\(w_i\)</span>。参数<span class="math inline">\(\theta\)</span>对应权重矩阵<span class="math inline">\(w\)</span>。</p>
<p>逻辑回归的对数似然可以表示为：</p>
<p><span class="math display">\[\ell(w) = \sum_{n=1}^N \left(
\sum_{c=1}^{C-1} y_{nc} w_c^T x_n - \log \sum_{c=1}^C e^{w_c^T x_n}
\right)\]</span></p>
<p>其梯度和海森矩阵分别为：</p>
<p><span class="math display">\[g(w) = \sum_{n=1}^N (y_n - p_n(w))
\otimes x_n  \\ H(w) = -\sum_{n=1}^N \left( \text{diag}(p_n(w)) - p_n(w)
p_n(w)^T \right) \otimes (x_n x_n^T)\]</span></p>
<p>通过构造海森矩阵的下界，可以得到：</p>
<p><span class="math display">\[H(w) \succ -\frac{1}{2} \left( I -
\frac{1}{C} \mathbf{1} \mathbf{1}^T \right) \otimes \left( \sum_{n=1}^N
x_n x_n^T \right) \equiv B\]</span></p>
<p>这里的<span class="math inline">\(I\)</span>是一个<span class="math inline">\((C−1)\)</span>维的单位矩阵，而<span class="math inline">\(1\)</span>是一个全为 1 的<span class="math inline">\((C -
1)\)</span>维向量。在二分类的情况下，这可以变为：</p>
<p><span class="math display">\[H(w) \succ -\frac{1}{2} \left(1 -
\frac{1}{2}\right) \left(\sum_{n=1}^N x_n^T x_n\right) = -\frac{1}{4}
X^T X\]</span></p>
<p>这是因为<span class="math inline">\(p_n \leq
0.5\)</span>，所以有<span class="math inline">\(- (p_n - p_n^2) \geq
-0.25\)</span>。</p>
<p>因此更新规则为：</p>
<p><span class="math display">\[w^{t+1} = w^t - B^{-1}
g(w^t)\]</span></p>
<p>在二分类的情况下，<span class="math inline">\(g_t = \nabla \ell(w_t)
= X^T (y - \mu_t)\)</span>，则更新规则为：</p>
<p><span class="math display">\[w^{t+1} = w^t - 4(X^TX)^{-1}
g^t\]</span></p>
<p>与牛顿法（IRLS）的标准更新比较：</p>
<p><span class="math display">\[w^{t+1} = w^t - H^{-1} g(w^t) =  = w^t −
(X^TS^tX)^{−1}g^t\]</span></p>
<p>可以看出，使用下界的MM算法在每一步的计算上会更快，因为<span class="math inline">\((X^T X)^{-1}\)</span>可以预先计算。</p>
<h3 id="em算法">3. EM算法</h3>
<p>EM算法通过在两个步骤之间交替进行来估计模型参数：</p>
<ol type="1">
<li><strong>E步骤（期望步骤）</strong>：估计隐藏变量或缺失值。</li>
<li><strong>M步骤（最大化步骤）</strong>：使用完全观察到的数据计算MLE。</li>
</ol>
<p>这个过程需要迭代，因为期望值依赖于参数，而参数又依赖于期望值。</p>
<h4 id="下界">3.1 下界</h4>
<p>EM算法的目标是最大化观察数据的对数似然函数：</p>
<p><span class="math display">\[\ell(\theta) = \sum_{n=1}^{N} \log p(y_n
| \theta) = \sum_{n=1}^{N} \log \left( \sum_{z_n} p(y_n, z_n | \theta)
\right)\]</span></p>
<p>其中<span class="math inline">\(y_n\)</span>​ 是可观察变量，<span class="math inline">\(z_n\)</span>​
是隐藏变量。直接优化这个对数似然函数是困难的，因为对数函数不能被推入求和符号内部。</p>
<p>EM算法通过引入任意分布<span class="math inline">\(q_n(z_n)\)</span>来解决这个问题。观察数据的对数似然函数可以写为：</p>
<p><span class="math display">\[\ell(\theta) = \sum_{n=1}^{N} \log
\left( \sum_{z_n} q_n(z_n) \frac{p(y_n, z_n | \theta)}{q_n(z_n)}
\right)\]</span></p>
<p>利用詹森不等式（Jensen’s
inequality），可以将对数函数推入期望之内，得到对数似然函数的下界：</p>
<p><span class="math display">\[\ell(\theta) \geq \sum_n \sum_{z_n}
q_n(z_n) \log \frac{p(y_n, z_n | \theta)}{q_n(z_n)}\]</span></p>
<p>这可以进一步写为：</p>
<p><span class="math display">\[\ell(\theta) \geq \sum_n
\mathbb{E}_{q_n}[\log p(y_n, z_n | \theta)] + H(q_n)\]</span></p>
<p>其中<span class="math inline">\(H(q)\)</span>是概率分布<span class="math inline">\(q\)</span>的熵。定义下界为ELBO：</p>
<p><span class="math display">\[\mathcal{L}(\theta, \{q_n\} | D) =
\sum_n \mathcal{L}(\theta, q_n | y_n)\]</span></p>
<p>优化这个下界是变分推断的基础。</p>
<p><img src="/images/Fundamentals-Optimization/17.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="e步骤">3.2 E步骤</h4>
<p>下界的每一项可以写为：</p>
<p><span class="math display">\[\mathcal{L}(\theta, q_n | y_n) =
\sum_{z_n} q_n(z_n) \log \frac{p(y_n, z_n |
\theta)}{q_n(z_n)}\]</span></p>
<p>这可以分解为：</p>
<p><span class="math display">\[\begin{align*} \mathcal{L}(\theta, q_n |
y_n) &amp;= \sum_{z_n} q_n(z_n) \log \frac{p(y_n, z_n |
\theta)}{q_n(z_n)} \\ &amp;= \sum_{z_n} q_n(z_n) \log \frac{p(z_n | y_n,
\theta) p(y_n | \theta)}{q_n(z_n)} \\ &amp;= \sum_{z_n} q_n(z_n) \log
\frac{p(z_n | y_n, \theta)}{q_n(z_n)} + \sum_{z_n} q_n(z_n) \log p(y_n |
\theta) \\ &amp;= -D_{KL}(q_n(z_n) \parallel p(z_n | y_n, \theta)) +
\log p(y_n | \theta) \end{align*}\]</span></p>
<p>因此，我们可以通过将每个<span class="math inline">\(q_n\)</span>设置为：</p>
<p><span class="math display">\[q_n^* = p(z_n | y_n,
\theta)\]</span></p>
<p>来最大化下界<span class="math inline">\(\mathcal{L}(\theta, \{q_n\} |
D)\)</span>。这就是E步骤。此时，ELBO就等于最大似然：</p>
<p><span class="math display">\[\mathcal{L}(\theta, \{q_n^*\} | D) =
\sum_n \log p(y_n | \theta) = \ell(\theta | D)\]</span></p>
<h4 id="m步骤">3.3 M步骤</h4>
<p>在M步骤中，我们需要最大化：</p>
<p><span class="math display">\[\mathcal{L}(\theta,
\{q_n^t\})\]</span></p>
<p>由于熵项<span class="math inline">\(H(q_n)\)</span>在<span class="math inline">\(\theta\)</span>方面是常数，因此在M步骤中可以忽略这些项。我们剩下的部分是：</p>
<p><span class="math display">\[\ell_t(\theta) = \sum_n
\mathbb{E}_{q_n^t(z_n)} [\log p(y_n, z_n | \theta)]\]</span></p>
<p>如果联合概率属于指数族，我们可以将其重写为：</p>
<p><span class="math display">\[\ell_t(\theta) = \sum_n
\mathbb{E}[T(y_n, z_n)]^T \theta - A(\theta)\]</span></p>
<p>在M步骤中，我们最大化期望的完整数据对数似然函数，得到：</p>
<p><span class="math display">\[\theta^{t+1} = \arg \max_{\theta} \sum_n
\mathbb{E}_{q_n^t} [\log p(y_n, z_n | \theta)]\]</span></p>
<p>对于指数族的情况，最大化可以通过匹配期望充分统计量的矩来闭合地求解。</p>
<h4 id="例子">3.4 例子</h4>
<p>书中以缺失数据的MLE为例子：</p>
<p><img src="/images/Fundamentals-Optimization/18.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/images/Fundamentals-Optimization/19.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="扩展em算法">3.5 扩展EM算法</h4>
<ul>
<li><strong>Variational EM （变分 EM）</strong></li>
</ul>
<p><strong>变分 EM</strong> 是 EM 算法的一种变体。在 E
步中，我们使用一种称为变分推断的方法来近似后验分布。具体来说，在 E
步中，我们选择一个分布<span class="math inline">\(q^*_n\)</span>​
来最小化<span class="math inline">\(q_n\)</span>​ 与真实后验分布<span class="math inline">\(p(z_n | x_n, \theta)\)</span>之间的 KL 散度：</p>
<p><span class="math display">\[q^*_n = \arg \min_{q_n \in Q} D_{KL}(q_n
\| p(z_n | x_n, \theta))\]</span></p>
<p>这实际上是一个变分推断过程。在这种情况下，<span class="math inline">\(Q\)</span>是我们定义的一个分布族。如果分布族<span class="math inline">\(Q\)</span>足够灵活，能够包含真实的后验分布，那么<span class="math inline">\(q_n\)</span>可以接近<span class="math inline">\(p(z_n | x_n, \theta)\)</span>，使得 KL 散度趋于
0。</p>
<p>为了计算简便，通常选择较为简单的分布族。例如，即使真实后验分布是相关的，我们可能也会假设<span class="math inline">\(q_n(z_n) = N(z_n | \mu_n,
\text{diag}(\sigma_n))\)</span>（即独立的多元正态分布）。</p>
<p>在这种情况下，使用有限的分布族<span class="math inline">\(Q\)</span>代替真实的后验分布，称为 变分 EM。变分
EM 不一定能保证增加实际的对数似然值，但可以单调增加变分下界。</p>
<ul>
<li><strong>Hard EM</strong></li>
</ul>
<p>在变分 EM
的框架下，假设我们使用的是一个退化的后验近似，即仅考虑后验分布的一个点估计：</p>
<p><span class="math display">\[q(z | x_n) =
\delta_{z_{\hat{n}}}(z)\]</span></p>
<p>这样<span class="math inline">\(z_{\hat{n}} = \arg \max_z p(z |
x_n)\)</span>，即后验分布的最大值点。这样的方式称为 <strong>Hard
EM</strong>，即在 E 步中忽略了<span class="math inline">\(z_n\)</span>​
的不确定性。</p>
<p>这种方法的缺点是，它很容易导致过拟合，特别是在隐变量的数量与数据量成正比的情况下。</p>
<ul>
<li><strong>Monte Carlo EM</strong></li>
</ul>
<p>当 E 步难以求解时，可以使用 Monte Carlo
方法来近似期望的充分统计量。具体地，我们从后验分布中采样：</p>
<p><span class="math display">\[z^s_n \sim p(z_n | x_n,
\theta^{(t)})\]</span></p>
<p>然后计算每个样本的充分统计量，最后将结果取平均。这种方法称为
<strong>Monte Carlo EM（MCEM）</strong>。</p>
<p>每个 E 步中都要等待 MCMC
收敛会非常耗时。另一种选择是使用随机近似法（stochastic
approximation），即在 E
步中只进行简短的采样，之后进行部分参数更新。这种方法称为
<strong>随机近似 EM（Stochastic Approximation EM）</strong>，通常比 MCEM
更快。</p>
<ul>
<li><strong>Generalized EM （广义 EM）</strong></li>
</ul>
<p>在某些情况下，我们可以精确地执行 E 步，但无法精确地执行 M
步。然而，即使不精确执行 M
步，也可以通过增加期望的完整数据对数似然来单调增加对数似然。这种情况下，我们可以只进行“部分”
M 步，例如执行几个梯度下降步。这种方法称为 <strong>广义
EM（GEM）</strong>。</p>
<p>具体地，我们可以使用一个<strong>牛顿-拉弗森（Newton-Raphson）</strong>步骤来更新参数：</p>
<p><span class="math display">\[\theta^{(t+1)} = \theta^{(t)} - \eta_t
H_t^{-1} g_t\]</span></p>
<p>其中，<span class="math inline">\(0 &lt; \eta_t \leq
1\)</span>是步长，<span class="math inline">\(g_t\)</span>和<span class="math inline">\(H_t\)</span>​ 分别表示梯度和 Hessian 矩阵：</p>
<p><span class="math display">\[g_t = \frac{\partial}{\partial \theta}
Q(\theta, \theta^{(t)}) \big|_{\theta = \theta^{(t)}}​ \\H_t =
\frac{\partial^2}{\partial \theta \partial \theta^T} Q(\theta,
\theta^{(t)}) \big|_{\theta = \theta^{(t)}}\]</span></p>
<p>当<span class="math inline">\(\eta_t = 1\)</span>时，这被称为梯度 EM
算法。为了加速算法，也可以采用较大的步长，如在准牛顿 EM 中使用 BFGS
近似替代 Hessian。</p>
<h2 id="五贝叶斯优化">五、贝叶斯优化</h2>
<p><strong>贝叶斯优化（Bayesian Optimization）</strong>简称
BayesOpt，它是一种基于模型的黑盒优化方法，旨在优化难以评估的目标函数<span class="math inline">\(f : X \to
R\)</span>的情形。（例如模拟成本比较高、训练复杂模型等）。由于计算代价高，我们希望尽可能少地调用目标函数，即减少查询<span class="math inline">\(x\)</span>的次数。因此，贝叶斯优化通过构建一个<strong>代理函数</strong>来近似目标函数<span class="math inline">\(f\)</span>并在每次查询进行选择，避免重复昂贵的函数评估。</p>
<p>贝叶斯优化的核心思想是：在构建代理函数的基础上权衡探索（exploration）和利用（exploitation）。</p>
<ul>
<li><strong>探索</strong>指的是在不确定的区域进行查询，以改善对代理模型的整体了解；</li>
<li><strong>利用</strong>指的是在目标函数<span class="math inline">\(f(x)\)</span>预期较高的区域查询，以更快地找到最优点。这种权衡称为探索-利用困境。</li>
</ul>
<p>假设目标函数的查询数据集为<span class="math inline">\(D_n = \{(x_i,
y_i) : i = 1, ..., n\}\)</span>，其中<span class="math inline">\(y_i =
f(x_i) + \epsilon_i\)</span>，其中<span class="math inline">\(\epsilon_i\)</span>​
是一个可能的噪声项。基于此数据集构建的代理模型可以估计<span class="math inline">\(f\)</span>的概率分布<span class="math inline">\(p(f |
D_n)\)</span>。每一步优化中，我们通过<strong>采集函数（acquisition
function）</strong>来选择下一个查询点<span class="math inline">\(x_{n+1}\)</span>​，采集函数根据模型不确定性和目标值的期望收益计算出最优的查询点。</p>
<h3 id="顺序模型优化sequential-model-based-optimization-smbo">1.
顺序模型优化（Sequential Model-Based Optimization, SMBO）</h3>
<p>贝叶斯优化是一种<strong>顺序模型优化（SMBO）</strong>的方法。在每一次迭代中，贝叶斯优化通过一个已标记的数据集<span class="math inline">\(D_n = \{(x_i, y_i) : i = 1, ...,
n\}\)</span>来更新对代理模型的估计。该数据集记录了每个查询点<span class="math inline">\(x_i\)</span>​ 及其对应的函数值<span class="math inline">\(y_i = f(x_i) +
\epsilon_i\)</span>。基于此数据集，我们可以估计目标函数的概率分布<span class="math inline">\(p(f | D_n)\)</span>，然后使用采集函数<span class="math inline">\(\alpha(x; D_n)\)</span>来决定下一个查询点<span class="math inline">\(x_{n+1}\)</span>​。查询<span class="math inline">\(x_{n+1}\)</span>​ 获得<span class="math inline">\(y_{n+1} = f(x_{n+1}) +
\epsilon_{n+1}\)</span>后，我们更新对目标函数的估计，然后重复上述步骤。</p>
<p><img src="/images/Fundamentals-Optimization/20.png" srcset="/img/loading.gif" lazyload></p>
<p>贝叶斯优化的主要步骤包括：</p>
<ul>
<li>代理模型的构建和更新：代理模型用于近似目标函数<span class="math inline">\(f\)</span>的后验分布<span class="math inline">\(p(f | D_n)\)</span>。</li>
<li>采集函数的定义和优化：采集函数<span class="math inline">\(\alpha(x;
D_n)\)</span>用于评估查询点的潜在收益，从而决定下一个查询点的位置。</li>
</ul>
<p>下图展示了贝叶斯优化的运行过程：</p>
<ul>
<li>在初始时，通过两个已查询点<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>​
确定了代理模型在这些位置上的函数值，模型在这两点附近的不确定性趋近于0。</li>
<li>采集函数（绿色曲线）在已查询点的位置值为
0，并在代理模型不确定性较高的区域达到最大值。</li>
<li>之后的迭代中，随着新的点被查询和观测，模型逐渐减少了对真实函数的估计不确定性，逐步逼近目标函数的全局最优解。</li>
</ul>
<p><img src="/images/Fundamentals-Optimization/21.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="代理函数">2. 代理函数</h3>
<p>对于代理函数，主要有<strong>高斯过程</strong>（Gaussian Processes,
GPs）、<strong>贝叶斯神经网络</strong>（Bayesian Neural Networks,
BNNs）等。</p>
<ul>
<li><strong>高斯过程（GPs）</strong></li>
</ul>
<p>高斯过程是一种常用的代理函数。在 GP 中，<span class="math inline">\(p(f(x)|D_n)\)</span>被建模为正态分布<span class="math inline">\(N(f|\mu_n(x),
\sigma_n^2(x))\)</span>，其中均值<span class="math inline">\(\mu_n(x)\)</span>和方差<span class="math inline">\(\sigma_n(x)\)</span>可以通过训练数据集<span class="math inline">\(D_n\)</span>​ 推导得出。</p>
<p>核函数<span class="math inline">\(K_\theta(x,
x&#39;)\)</span>用于度量输入点<span class="math inline">\(x\)</span>和<span class="math inline">\(x′\)</span>之间的相似度。相似度高的点对应该有相似的函数值，因此可以正相关。高斯过程据此在训练点之间内插值（有时甚至可以外推）。核函数的选择至关重要。通常可以通过最大化边际似然来估计核参数<span class="math inline">\(\theta\)</span>，或者使用贝叶斯推断来近似边际化<span class="math inline">\(\theta\)</span>。</p>
<p>高斯过程在数据较少时效果很好，支持闭式的贝叶斯更新，但计算代价为<span class="math inline">\(O(N^3)\)</span>（其中<span class="math inline">\(N\)</span>为样本数），对于大量函数评估来说会很慢。有一些方法可以将计算复杂度降低至<span class="math inline">\(O(NM^2)\)</span>，其中<span class="math inline">\(M\)</span>是可选参数，但会牺牲精度。</p>
<ul>
<li><strong>贝叶斯神经网络（BNNs）</strong></li>
</ul>
<p>贝叶斯神经网络是高斯过程的一种自然替代。使用线性回归时，可以高效地进行精确的贝叶斯推断。但若使用非线性模型（如深度神经网络，DNN），则需使用近似推断。</p>
<p>BNNs 提供了一个在贝叶斯优化中替代 GPs
的方式，因为它们能够建模非线性关系，且在大数据量下通常更高效。关于贝叶斯网络的具体内容会后面进行学习。</p>
<p>还可以使用其他形式的回归模型。例如，随机森林集成模型在贝叶斯优化中表现良好，因为它们可以处理条件参数空间，但需要bootstrapping来获得不确定性估计，计算较慢。</p>
<h3 id="采集函数">3. 采集函数</h3>
<p>采集函数用来评估每个可能的查询点的预期效用。一般表示为：</p>
<p><span class="math display">\[\alpha(x|D_n) =
\mathbb{E}_{p(y|x,D_n)}[U(x, y; D_n)]\]</span></p>
<p>其中：</p>
<p><em><span class="math inline">\(y = f(x)\)</span>是在点<span class="math inline">\(x\)</span>处未知函数的值， </em><span class="math inline">\(U\)</span>是效用函数，它决定不同采集函数的形式。</p>
<p>下面介绍一些常见的采集函数。</p>
<h4 id="改进概率probability-of-improvement-pi">3.1 改进概率（Probability
of Improvement, PI）</h4>
<p><strong>改进概率</strong>用于评估某一点是否可能带来比当前最优观测值更好的结果。定义如下：</p>
<p>首先，设定目前的最优值（incumbent）为：<br>
<span class="math display">\[M_n = \max_{i=1}^n y_i\]</span></p>
<p>如果观测是有噪声的，可以选择最高均值代替最大观测值。定义效用函数：</p>
<p><span class="math display">\[U(x, y; D_n) = I(y &gt;
M_n)\]</span></p>
<p>其中<span class="math inline">\(I(\cdot)\)</span>是指示函数，即当<span class="math inline">\(y\)</span>超过当前最优值<span class="math inline">\(M_n\)</span>​ 时，产生效用 1，否则为 0。</p>
<p>因此，PI 采集函数可以表示为：<br>
<span class="math display">\[\alpha_{\text{PI}}(x; D_n) = p(f(x) &gt;
M_n | D_n)\]</span></p>
<p>若代理模型是高斯过程，可以得到 PI
的闭式解（就是简单的高斯分布求概率）：</p>
<p><span class="math display">\[\alpha_{\text{PI}}(x; D_n) =
\Phi\left(\gamma_n(x, M_n)\right)\]</span></p>
<p><span class="math display">\[\gamma_n(x, \tau) = \frac{\mu_n(x) -
\tau}{\sigma_n(x)}\]</span></p>
<p>其中：</p>
<p><em><span class="math inline">\(\Phi\)</span>是标准正态分布的累积分布函数（CDF），
</em><span class="math inline">\(\mu_n(x)\)</span>和<span class="math inline">\(\sigma_n(x)\)</span>分别是高斯过程在<span class="math inline">\(x\)</span>处的均值和标准差。</p>
<h4 id="期望改进expected-improvement-ei">3.2 期望改进（Expected
Improvement, EI）</h4>
<p><strong>期望改进</strong>考虑的是改进的量，而不仅仅是是否产生改进。定义效用函数为
：</p>
<p><span class="math display">\[U(x, y; D_n) = (y - M_n)I(y &gt;
M_n)\]</span></p>
<p>这样只有<span class="math inline">\(y &gt; M_n\)</span>​
时才会有正值的效用。</p>
<p>因此，EI 采集函数表示为：<br>
<span class="math display">\[\alpha_{\text{EI}}(x; D_n) =
\mathbb{E}_{D_n}[(f(x) - M_n)I(f(x) &gt; M_n)]\]</span></p>
<p>在高斯过程模型下，EI 有以下闭式解：</p>
<p><span class="math display">\[\alpha_{\text{EI}}(x; D_n) = (\mu_n(x) -
M_n)\Phi(\gamma) + \sigma_n(x)\phi(\gamma)\]</span></p>
<p>其中：</p>
<p><em><span class="math inline">\(\phi\)</span>是标准正态分布的概率密度函数
</em><span class="math inline">\(\gamma = \gamma_n(x, M_n) =
\frac{\mu_n(x) - M_n}{\sigma_n(x)}\)</span></p>
<p>我们可以注意到EI 的两个部分：</p>
<ul>
<li>第一项<span class="math inline">\((\mu_n(x) -
M_n)\Phi(\gamma)\)</span>促进利用（选择均值高的点）</li>
<li>第二项<span class="math inline">\(\sigma_n(x)\phi(\gamma)\)</span>则促进探索（选择方差大的点）。</li>
</ul>
<p>如果无法计算预测方差，可以使用蒙特卡洛方法近似：</p>
<p><span class="math display">\[\alpha_{\text{EI}}(x; D_n) \approx
\frac{1}{S} \sum_{s=1}^S \max(\mu_n^s(x) - M_n, 0)\]</span></p>
<h4 id="上置信界upper-confidence-bound-ucb">3.3 上置信界（Upper
Confidence Bound, UCB）</h4>
<p><strong>上置信界</strong>通过计算函数的上置信区间来决定评估点。其采集函数定义为：</p>
<p><span class="math display">\[\alpha_{\text{UCB}}(x; D_n) = \mu_n(x) +
\beta_n \sigma_n(x)\]</span></p>
<p>其中<span class="math inline">\(\beta_n\)</span>​
控制置信区间的宽度。在高斯过程代理模型下，这种方法称为 GP-UCB。</p>
<h4 id="汤普森采样thompson-sampling">3.4 汤普森采样（Thompson
Sampling）</h4>
<p><strong>汤普森采样</strong>尝试直接从后验分布中采样，以找到潜在的最优点。采集函数定义为：</p>
<p><span class="math display">\[\alpha(x; D_n) =
\mathbb{E}_{p(\theta|D_n)} \left[ I\left( x = \arg\max_{x&#39;}
f_\theta(x&#39;) \right) \right]\]</span></p>
<p>通过从<span class="math inline">\(p(\theta|D_n)\)</span>中采样一个<span class="math inline">\(\tilde{\theta}\)</span>，我们选择最大化<span class="math inline">\(f_{\tilde{\theta}}(x)\)</span>的点。对于高斯过程，采样会比较复杂，因此应用起来需要特殊的技术。</p>
<h4 id="熵搜索entropy-search">3.5 熵搜索（Entropy Search）</h4>
<p><strong>熵搜索</strong>直接最小化对最优点位置的<strong>不确定性</strong>。熵搜索的效用函数定义为：</p>
<p><span class="math display">\[U(x, y; D_n) = H(x^*|D_n) - H(x^*|D_n
\cup \{(x, y)\})\]</span></p>
<p>其中<span class="math inline">\(H(x^*|D_n)\)</span>是后验分布<span class="math inline">\(p^*(x|D_n)\)</span>的熵。熵搜索的采集函数为：</p>
<p><span class="math display">\[\alpha_{\text{ES}}(x; D_n) =
\mathbb{E}_{p(y|x, D_n)}[U(x, y; D_n)] = H(x^*|D_n) - \mathbb{E}_{p(y|x,
D_n)}[H(x^*|D_n \cup \{(x, y)\})]\]</span></p>
<p>通过<strong>预测熵搜索（Predictive Entropy Search,
PES）</strong>，可以使用互信息的对称性来简化该采集函数：</p>
<p><span class="math display">\[\alpha_{\text{PES}}(x; D_n) = H(y|D_n,
x) - \mathbb{E}_{x^*|D_n}[H(y|D_n, x, x^*)]\]</span></p>
<p>在这里，可以通过汤普森采样来近似积分。</p>
<h4 id="知识梯度-knowledge-gradient">3.6 知识梯度 (Knowledge
Gradient)</h4>
<p>知识梯度获取函数的核心思想是：通过考虑在查询一个新点后，更新我们的后验分布，然后基于新的分布进一步寻找最大值。这种方法不只是关注当前步骤的最大化，而是展望两步，从而达到长远的优化效果。</p>
<p>假设我们在点<span class="math inline">\(x\)</span>查询后，得到了新的观测值<span class="math inline">\(y\)</span>，可以根据新的信念找到下一个可能的最佳值：<br>
<span class="math display">\[V_{n+1}(x, y) = \max_{x&#39;}
\mathbb{E}_{p(f|x, y, D_n)} [f(x&#39;)]\]</span></p>
<p>其中<span class="math inline">\(V_{n+1}(x, y)\)</span>表示在位置<span class="math inline">\(x\)</span>查询并得到结果<span class="math inline">\(y\)</span>后，下一步所能达到的最大值。</p>
<p>由于我们在进行查询时并不知道真实的<span class="math inline">\(y\)</span>值，因此需要对所有可能的<span class="math inline">\(y\)</span>取期望，以得出在查询<span class="math inline">\(x\)</span>位置后的期望的增益：<br>
<span class="math display">\[V_{n+1}(x) = \mathbb{E}_{p(y|x, D_n)}
[V_{n+1}(x, y)]\]</span></p>
<p>知识梯度获取函数的定义如下：<br>
<span class="math display">\[\alpha_{KG}(x; D_n) = \mathbb{E}_{D_n}
\left[(V_{n+1}(x) - M_n) \cdot I(V_{n+1}(x) &gt;
M_n)\right]\]</span></p>
<p>这里<span class="math inline">\(M_n = \max_{i=1}^n y_i\)</span>，​
是当前已观察到的最佳值（即，迄今为止观察到的最大值）。该函数的定义类似于期望提升（Expected
Improvement,
EI），区别在于知识梯度考虑的是观察新点后可以利用的新知识，而不仅仅是找到一个新的最大值。</p>
<p>下面是上面方法之间在一个实践中的对比：</p>
<p><img src="/images/Fundamentals-Optimization/22.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="六无梯度优化">六、无梯度优化</h2>
<p><strong>无梯度优化（DFO，Derivative-free
Optimization）</strong>指的是在不知道函数的导数信息时如何进行优化。根据目标函数的评估成本，无梯度优化可以分为<strong>贝叶斯优化</strong>（适用于高评估成本的情况）和<strong>随机局部搜索</strong>或<strong>进化搜索</strong>（适用于低评估成本的情况）。贝叶斯优化已经讲过了，所以下面的内容主要集中在随机局部搜索或进化搜索。</p>
<h3 id="局部搜索local-search">1. 局部搜索（Local Search）</h3>
<p>局部搜索是一类启发式优化算法，旨在寻找离散、非结构化搜索空间中的全局最大值。传统的梯度更新形式为：</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t + \eta_t
d_t\]</span></p>
<p>但在无梯度优化中无法使用此更新形式，因此使用一个离散版本的更新方式。具体来说，更新的公式为：</p>
<p><span class="math display">\[L(x)x_{t+1} = \arg \max_{x \in
\text{nbr}(x_t)} L(x)\]</span></p>
<p>其中<span class="math inline">\(\text{nbr}(x_t) \subset
X\)</span>表示<span class="math inline">\(x_t\)</span>的邻域，这一方法被称为<strong>爬山算法</strong>（hill
climbing）、<strong>最陡上升</strong>（steepest
ascent）或<strong>贪心搜索</strong>。</p>
<p>若一个点的邻域包含整个搜索空间，则上面公式可在一步内返回全局最优解，但通常这种邻域过大，难以完全搜索。因此，通常会定义<strong>局部邻域</strong>。例如，在<strong>8皇后问题</strong>中，目标是将8个皇后放置在
8×8 棋盘上，使它们互不攻击。8皇后的状态空间<span class="math inline">\(X
= 64^8\)</span>，但由于约束，只有大约 17M
个可行状态。定义每个状态的邻域为所有通过将一个皇后移动到同列其他位置而生成的状态，因此每个状态有
56
个邻居。然而，随机生成的初始状态通过最陡上升法只能成功解决14%的问题，并且在失败时会停留在局部最优解处。</p>
<h4 id="随机局部搜索stochastic-local-search">1.1
随机局部搜索（Stochastic Local Search）</h4>
<p>爬山算法是一种贪心算法，因为它在邻域内选择最优点。这种方法容易卡在局部最优解。为了减少这种情况，一个解决方法是将目标在每一步的最大化从确定性转变为<strong>随机化</strong>。具体而言，可以定义邻居的概率分布，概率与邻居改进的程度成正比，从而随机采样一个邻居点。这被称为<strong>随机爬山法</strong>（stochastic
hill climbing）。</p>
<p>如果逐渐减小该概率分布的熵，使算法逐渐趋于贪心，则得到<strong>模拟退火算法</strong>（simulated
annealing）。另一种方法是使用贪心爬山算法，但在遇到局部最优解时，从一个新的随机起点重新开始。这种方法称为<strong>随机重启爬山法</strong>（random
restart hill
climbing）。例如在8皇后问题中，如果每次爬山搜索的成功概率为<span class="math inline">\(p \approx 0.14\)</span>，期望需要<span class="math inline">\(R = 1/p \approx
7\)</span>次重启才能找到有效解。</p>
<h4 id="禁忌搜索tabu-search">1.2 禁忌搜索（Tabu Search）</h4>
<p>爬山法在达到局部最优或平台时会停止。虽然可以通过随机重启来避免这种情况，但会丢弃已有的信息。<strong>禁忌搜索</strong>（Tabu
Search）是一种更智能的替代方法。禁忌搜索允许移动到得分下降的状态，只要该状态之前没有访问过。为此，我们维护一个<strong>禁忌表</strong>（tabu
list），记录最近访问的<span class="math inline">\(\tau\)</span>个状态，从而强制算法探索新的状态，增加逃离局部最优解的机会。</p>
<p>禁忌搜索达到局部最高点<span class="math inline">\(x_t\)</span>​
时，会移动到邻居<span class="math inline">\(x_{t+1} \in
\text{nbr}(x_t)\)</span>，该点得分较低。接着它会移动到之前状态的邻居<span class="math inline">\(x_{t+2} \in
\text{nbr}(x_{t+1})\)</span>，禁忌表阻止它返回到峰顶，从而使它继续探索，直到找到新的峰顶，或达到最多非改进步数<span class="math inline">\(c_{\text{max}}\)</span>​。</p>
<p><img src="/images/Fundamentals-Optimization/23.png" srcset="/img/loading.gif" lazyload></p>
<p>在8皇后问题中，禁忌搜索能将解决成功率从14%提高到94%，平均每个成功实例需要21步，失败实例需要64步。</p>
<h3 id="模拟退火-simulated-annealing">2. 模拟退火 (Simulated
Annealing)</h3>
<p>模拟退火是一种随机局部搜索算法，通常用于寻找黑箱函数<span class="math inline">\(E(x)\)</span>的全局最小值，这里的<span class="math inline">\(E\)</span>被称为能量函数。模拟退火的灵感来源于物理学中的退火过程，通过逐步降低“温度”来达到目标。</p>
<p>将能量函数<span class="math inline">\(E(x)\)</span>转换为状态概率分布：<br>
<span class="math display">\[p(x) = \exp(-E(x))\]</span></p>
<p>这里的<span class="math inline">\(p(x)\)</span>是未归一化的概率分布，目的是构建一个与能量成反比的概率分布。</p>
<p>模拟退火每次会使用一种变体的 Metropolis-Hastings
算法（采样算法）来从概率分布中采样。每次迭代中，算法会选择一个新的候选状态<span class="math inline">\(x′\)</span>，然后按照概率接受或拒绝该状态。接受概率由能量差值和当前“温度”决定：<br>
<span class="math display">\[\text{接受概率} = \min \left( 1, \exp
\left( \frac{E(x) - E(x&#39;)}{T} \right) \right)\]</span></p>
<p>其中<span class="math inline">\(T\)</span>是“温度”参数，随着迭代次数增加逐渐减小。在高温阶段，算法倾向于接受更差的解，以避免陷入局部极小值；在低温阶段，逐渐收敛于全局最优解。</p>
<h3 id="进化算法-evolutionary-algorithms">3. 进化算法 (Evolutionary
Algorithms)</h3>
<p>进化算法是一类仿生算法，模拟自然选择和遗传进化的过程，以优化复杂目标函数。这类算法通常使用一个种群<span class="math inline">\(S_t\)</span>来表示候选解的集合。</p>
<p>进化算法的主要组成部分</p>
<ul>
<li><strong>适应度 (Fitness)</strong>：
每个候选解的“适应度”是其目标函数的值，即评估该解的好坏。</li>
<li><strong>选择函数 (Selection Function)</strong>：
从当前种群中选择适应度较高的成员作为“父代”生成“子代”。常见的选择策略包括：
<ul>
<li><strong>截断选择 (Truncation Selection)</strong>：
从适应度最高的前<span class="math inline">\(K\)</span>个成员中随机选择父代。</li>
<li><strong>锦标赛选择 (Tournament Selection)</strong>：
每次从种群中随机选择<span class="math inline">\(K\)</span>个成员，选择适应度最高的个体作为父代。</li>
<li><strong>适应度比例选择 (Fitness Proportionate Selection)</strong>：
按照个体适应度的相对比例选择父代（也叫轮盘选择）。</li>
</ul></li>
<li><strong>重组 (Recombination) 和变异 (Mutation)</strong>：
生成新候选解的关键操作：
<ul>
<li><strong>交叉 (Crossover)</strong>：
对两个父代进行基因交换，产生子代。例如在遗传算法中，每个个体可以表示为二进制或整数向量，随机选择切割点并交换父代的子串。</li>
<li><strong>变异 (Mutation)</strong>：
对单个个体进行小范围随机改变，用于增加种群多样性。</li>
</ul></li>
</ul>
<p><img src="/images/Fundamentals-Optimization/24.png" srcset="/img/loading.gif" lazyload></p>
<p>常见的进化算法如下：</p>
<ul>
<li><strong>遗传算法 (Genetic Algorithm, GA)</strong>：
使用二进制或整数表示个体，通过交叉和变异产生新的个体，如上图。</li>
<li><strong>遗传编程 (Genetic Programming, GP)</strong>：
使用树状结构表示个体，适合生成结构化对象或程序，如下图。</li>
<li><strong>代理辅助进化算法 (Surrogate-assisted EA)</strong>：
使用近似模型替代真实的目标函数，以减少评估开销。</li>
<li><strong>记忆算法 (Memetic Algorithm)</strong>：
结合进化算法和局部搜索，提升求解效率。</li>
</ul>
<p><img src="/images/Fundamentals-Optimization/25.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="分布估计算法">4. 分布估计算法</h3>
<p><strong>分布估计算法（Estimation of Distribution Algorithms,
EDA）</strong>是一种进化算法（EA）的变体。EDA
的主要思想是用概率模型来表示高适应度解的分布，而不是通过基因操作（如交叉、变异）来生成新解。</p>
<p>传统的进化算法依赖遗传操作来保持和生成候选解的种群，而 EDA
则采用显式的概率模型来估计解的分布。在每次迭代中，EDA
从当前的概率模型中采样生成候选解，选出最优的部分解，然后基于这些解更新概率模型，从而使其逐步向最优解靠近。</p>
<p>具体的 EDA 操作步骤：</p>
<ul>
<li><strong>候选解采样</strong>：从当前模型<span class="math inline">\(p(x|\theta_t)\)</span>中采样<span class="math inline">\(K&#39; &gt; K\)</span>个候选解，构成种群<span class="math inline">\(S_t = \{x_k \sim p(x|\theta_t)\}\)</span>。</li>
<li><strong>选择操作</strong>：用适应度函数对这些候选解排序，选择出最优的<span class="math inline">\(K\)</span>个解，记为<span class="math inline">\(S^*_t\)</span>（截断选择）。</li>
<li><strong>更新概率模型</strong>：利用最大似然估计（MLE）将新模型<span class="math inline">\(p(x|\theta_{t+1})\)</span>拟合到<span class="math inline">\(S^*_t\)</span>​ 上，得到下一代的解分布。</li>
</ul>
<p>EDA 本质上是通过最小化<span class="math inline">\(S^*_t\)</span>​
的经验分布与新模型分布<span class="math inline">\(p(x|\theta_{t+1})\)</span>的交叉熵来进行更新，因此与交叉熵法（CEM）有一定联系。对比来看，交叉熵法通常假设模型为多元高斯分布<span class="math inline">\(N(x|\mu, \Sigma)\)</span>，而 EDA 更加通用。</p>
<p>在实际应用中，为了表示解空间中的变量依赖性，可以选择更加复杂的概率模型。</p>
<ul>
<li>对于连续变量，可以使用多元高斯模型<span class="math inline">\(p(x) =
N(x|\mu, \Sigma)\)</span>，此方法被称为多元正态估计算法（EMNA）。</li>
<li>对于离散变量：可以用概率图模型（如树结构、贝叶斯网络）来捕捉变量之间的依赖关系。Chow-Liu
算法可以用于树结构的学习，而更复杂的图模型结构也可以通过 BOA
等算法学习。</li>
</ul>
<p><img src="/images/Fundamentals-Optimization/26.png" srcset="/img/loading.gif" lazyload></p>
<p>随着深度学习的应用，可以使用深度生成模型来表示解分布。例如，可以使用去噪自编码器、NADE、DNN
回归模型、RBM（受限玻尔兹曼机）和 VAE（变分自编码器）等。</p>
<h4 id="示例umda">4.1 示例：UMDA</h4>
<p>考虑一个简单的例子，目标空间是长度为<span class="math inline">\(D\)</span>的二进制字符串，适应度函数为</p>
<p><span class="math display">\[f(x) = \sum_{d=1}^D x_d\]</span></p>
<p>其中<span class="math inline">\(x_d \in \{0, 1\}\)</span>（称为
one-max 函数）。一个简单的概率模型是完全分解的模型：</p>
<p><span class="math display">\[p(x|\theta) = \prod_{d=1}^D
\text{Ber}(x_d|\theta_d)\]</span></p>
<p>这称为<strong>单变量边际分布算法（UMDA）</strong>。对于这种伯努利分布，可以通过统计<span class="math inline">\(S^*_t\)</span>​ 中各位置的 1 的比例来估计参数：</p>
<p><span class="math display">\[\hat{\theta}_{d, t+1} = \frac{1}{N_t}
\sum_{k=1}^K I(x_{k, d} = 1)\]</span></p>
<p>其中<span class="math inline">\(K =
|S^*_t|\)</span>，表示选择的候选解数量。为了平滑参数更新，可以使用如下增量更新公式：</p>
<p><span class="math display">\[\hat{\theta}_{d, t+1} = (1 - \eta_t)
\hat{\theta}_{d, t} + \eta_t \theta_{d, t}\]</span></p>
<p>其中，<span class="math inline">\(\eta_t\)</span>是学习率，<span class="math inline">\(\theta_{d, t}\)</span>是第<span class="math inline">\(t\)</span>代选择子集中第<span class="math inline">\(d\)</span>位为 1
的比例。这个更新方法称为基于种群的增量学习（PBIL）。</p>
<h4 id="交叉熵法cem">4.2 交叉熵法（CEM）</h4>
<p>交叉熵法是一种特殊的分布估计算法（EDA），其中种群由多元高斯分布表示。算法的主要步骤如下：</p>
<ul>
<li><strong>设置均值和协方差</strong>：<span class="math inline">\(\mu_{t+1}\)</span>和<span class="math inline">\(\Sigma_{t+1}\)</span>被设置为<span class="math inline">\(S^*_{t+1}\)</span>的经验均值和协方差，<span class="math inline">\(S^*_{t+1}\)</span>是前 K 个样本。</li>
<li><strong>优化问题</strong>： 在 CEM
中，我们希望最大化以下目标：<br>
<span class="math display">\[\theta_{t+1} = \arg\max_{\theta} \sum_{i
\in S_t} p_t(i) \log p(x_{t,i} | \theta)\]</span></li>
</ul>
<p>其中<span class="math inline">\(p_t(i)\)</span>是与选择的样本<span class="math inline">\(S^*_t\)</span>相关的概率分布。</p>
<h3 id="进化策略evolutionary-strategies-es">5. 进化策略（Evolutionary
Strategies, ES）</h3>
<p>进化策略是一种基于分布的优化方法，其中种群的分布用高斯分布表示。与
CEM 不同，ES 通过对期望目标的梯度上升来更新参数，而不是使用
MLE。主要步骤如下：</p>
<ul>
<li><strong>平滑目标函数</strong>：<br>
<span class="math display">\[L(\theta) =
\mathbb{E}_{p(x|\theta)}[f(x)]\]</span></li>
<li><strong>计算梯度</strong>： 使用 REINFORCE 估计器计算梯度：<br>
<span class="math display">\[\nabla_\theta L(\theta) =
\mathbb{E}_{p(x|\theta)}[f(x) \nabla_\theta \log
p(x|\theta)]\]</span></li>
</ul>
<p>这个期望可以通过蒙特卡罗采样进行近似。</p>
<p>当概率模型属于指数族时，可以计算自然梯度，通常收敛速度更快。<strong>自然进化策略（Natural
Evolution Strategies,
NES）</strong>使用自然梯度替代“普通”梯度，以加速优化。</p>
<p>CMA-ES 是一种
NES，主要特征在于它以加权的方式更新均值和协方差。具体步骤如下：</p>
<ol type="1">
<li><strong>计算加权均值</strong>： 新均值设为当前样本的加权 MLE。</li>
<li><strong>更新协方差</strong>：
使用“进化路径”来累积搜索方向，更新协方差，更新公式较为复杂。</li>
</ol>
<p>CMA-ES 通过这些更新近似目标函数<span class="math inline">\(L(\theta)\)</span>的自然梯度，而无需显式建模费舍尔信息矩阵。</p>
<p><img src="/images/Fundamentals-Optimization/27.png" srcset="/img/loading.gif" lazyload></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Probabilistic-Machine-Learning/" class="category-chain-item">Probabilistic Machine Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="print-no-link">#机器学习</a>
      
        <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/" class="print-no-link">#概率论与数理统计</a>
      
        <a href="/tags/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" class="print-no-link">#优化方法</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>[Probabilistic Machine Learning]: Fundamentals-Optimization</div>
      <div>https://jia040223.github.io/2024/10/29/Fundamentals-Optimization/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Serendipity</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年10月29日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/10/24/Fundamentals-Information%20theory/" title="[Probabilistic Machine Learning]: Fundamentals-Information theory">
                        <span class="hidden-mobile">[Probabilistic Machine Learning]: Fundamentals-Information theory</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"Ug8725bpf4JJJkltPotjuquU-MdYXbMMI","appKey":"Po3fbdR9RiF08kxafXGlNgd5","path":"window.location.pathname","placeholder":"留言仅限讨论，严禁广告等行为","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"https://ug8725bp.api.lncldglobal.com","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
