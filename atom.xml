<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Serendipity&#39;s Blog</title>
  
  
  <link href="https://jia040223.github.io/atom.xml" rel="self"/>
  
  <link href="https://jia040223.github.io/"/>
  <updated>2024-09-29T17:01:04.065Z</updated>
  <id>https://jia040223.github.io/</id>
  
  <author>
    <name>Serendipity</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>更新说明 2024.9.30</title>
    <link href="https://jia040223.github.io/2024/09/30/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/"/>
    <id>https://jia040223.github.io/2024/09/30/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/</id>
    <published>2024-09-29T16:34:30.000Z</published>
    <updated>2024-09-29T17:01:04.065Z</updated>
    
    <content type="html"><![CDATA[<p>国庆假期到了，这学期课程压力比较小，所以也是能为以后的科研学习一下相关知识。但国庆假期还是给自己放了一个大长假，这段时间估计是不太会更新了。</p><h2 id="stanford-cs236">Stanford CS236</h2><p>最近StanfordCS236课程也算是看完了，后面可能还会有一些内容打算写一写吧。主要还是围绕diffusion，包括</p><ul><li>ldm</li><li>diffusion的condition控制</li><li>如何把diffusion用于离散的数据</li></ul><p>前面的文章可能也会补一补。感觉diffusion涉及到的数学知识还是挺多的，后面有机会可以来补一补数学基础。</p><h2 id="probabilistic-machine-learning">Probabilistic MachineLearning</h2><p>打算学习一下<strong>Probabilistic MachineLearning</strong>这本书，后面应该也会边学边记录一下，也强烈给读者推荐这本书，特别对于像我这样致力于在AI领域进行研究但基础比较薄弱的同学。</p><p>这本书应该也是将来一段时间我的学习重点了，内容还是很多的。</p><h2 id="数学">数学</h2><p>StanfordCS236课程还是涉及到挺多的数学知识，后面有机会可以来补一补数学基础。之前保研复习了一下微积分，线代，微分方程这些，后面可能会多看一看优化相关（比如什么拉格朗日对偶问题，每次遇到都是混过去了）的知识，同时对diffusion涉及的一些知识也多了解了解，可能包括：</p><ul><li>SDE和ODE的解法</li><li>傅里叶变换</li><li>优化理论</li></ul><h2 id="科研">科研</h2><p>国庆之后也可能会具体进行一些导师的项目，后面在科研上的学习有机会也可以记录一下。</p><h2 id="碎碎念">碎碎念</h2><p>感觉还是太菜了，什么都不会。感觉大学四年在课堂上学的东西真的太基础了。</p><p>以前本科的实习也就是看了几篇论文就开始做，然后也就用的别人的模型，在上面小修小补，以至于做了一学期的生成模型，现在看了StanfordCS236，感觉以前真的啥都不知道。</p><p>虽然可能跟着别人脚步走也能发论文吧，但还是希望能夯实一下理论基础，希望以后科研的日子能过得轻松一点。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;国庆假期到了，这学期课程压力比较小，所以也是能为以后的科研学习一下相关知识。但国庆假期还是给自己放了一个大长假，这段时间估计是不太会更新了。&lt;/p&gt;
&lt;h2 id=&quot;stanford-cs236&quot;&gt;Stanford CS236&lt;/h2&gt;
&lt;p&gt;最近Stanford
C</summary>
      
    
    
    
    <category term="更新日志" scheme="https://jia040223.github.io/categories/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/"/>
    
    
    <category term="更新日志" scheme="https://jia040223.github.io/tags/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Model原理</title>
    <link href="https://jia040223.github.io/2024/09/29/Diffusion%20Model%E5%8E%9F%E7%90%86/"/>
    <id>https://jia040223.github.io/2024/09/29/Diffusion%20Model%E5%8E%9F%E7%90%86/</id>
    <published>2024-09-29T10:34:53.000Z</published>
    <updated>2024-09-29T17:08:28.988Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习StanfordCS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h2 id="引入">引入</h2><p>前面的课程中我们已经学习了许多生成模型的架构，例如VAEs，Score BasedModels等。在课程的最后也是总算来到当前最火的生成模型架构：DiffusionModel。其实DiffusionModel与前面模型或多或少都有一定的联系，我们也可以从不同的视角来理解它。</p><p>笔者本科科研也算是学习研究了一些Diffusion相关的工作，但之前一直没有去梳理生成模型的发展，也没有深究其背后的数学原理。所以借此几乎，正好对一些知识进行整理，并对生成模型进行部分回顾。首先从DDPM和DDIM入手吧，这两篇文章也是之前科研实践学习过很多次了。</p><h2 id="ddpm">DDPM</h2><p>首先我们知道，DDPM是个马尔科夫模型（如下图），DDPM包括两个步骤。这两个步骤在原文中定义为前向加噪（forward，下图从右到左）和后向去噪（reverse，下图从左到右）。</p><p><img src="/images/Diffusion%20Model原理/1.png"></p><p>从 <span class="math inline">\(x_0\)</span> 到 <span class="math inline">\(x_T\)</span>的过程就是前向加噪过程，我们可以看到加噪过程就是对原始图片 <span class="math inline">\(x_0\)</span>不断添加噪声，使其最后信噪比趋近于0，此时得到的图片也就变成噪声了，而与之相对应的去噪过程就是还原过程，即从噪声不断去噪还原为图片。</p><p>我们通过往图片中加入噪声，使得图片变得模糊起来，当加的步骤足够多的时候（也就是T的取值越大的时候，一般取1000），图片已经非常接近一张纯噪声。纯噪声也就意味着多样性，我们的模型在去噪（还原）的过程中能够产生更加多样的图片。</p><p>这里的操作实际上就是指在图片加入噪声 <span class="math inline">\(noise\)</span> ，噪声 <span class="math inline">\(noise\)</span>本身的分布可以是很多样的（btw，保研还被问过这个问题），而论文中采用的是<strong>标准正态分布</strong>，其理由是考虑到其优良的性质，在接下来的公式推理中见到。</p><h3 id="推导">推导</h3><p>从上面的图可知，DDPM将前向过程和逆向过程都设计为了马尔可夫链的形式：</p><ul><li>称从 <span class="math inline">\(x_0\)</span> 到 <span class="math inline">\(x_T\)</span> 的马尔可夫链为<strong>前向过程(forward process)</strong> 或<strong>扩散过程 (diffusionprocess)</strong>；</li><li>称从 <span class="math inline">\(x_T\)</span> 到 <span class="math inline">\(x_0\)</span> 的马尔可夫链为<strong>逆向过程(reverse process)</strong> 或<strong>去噪过程 (denoisingprocess)</strong>.</li></ul><p>所以我们的损失函数通过极大似然估计来进行。但这里我们又会遇到和VAE一样的问题，<span class="math inline">\(log(P(x))\)</span> 中的 <span class="math inline">\(P(x)\)</span> 需要对 <span class="math inline">\(x_{1:T}\)</span>进行积分，此时我们便可以效仿VAE的做法，即把 <span class="math inline">\(x_{1:T}\)</span>作为类似VAE中的潜变量，去优化对数似然的下界ELBO（为什么是下界可以参考我都VAEs的文章，简单来说就是用<strong>琴生不等式</strong>即可）：</p><p><span class="math display">\[\begin{align*} ELBO &amp;= \mathbb{E}_{\mathbf{x}_{1:T} \simq(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \left[\log\frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert\mathbf{x}_0)} \right] \\&amp;= \mathbb{E}_{\mathbf{x}_{1:T} \simq(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \left[ \log\frac{p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}{\prod_{t=1}^T q(\mathbf{x}_t \vert \mathbf{x}_{t-1})}\right]  \end{align*}\]</span></p><p>至于这里为啥要在给定 <span class="math inline">\(x_0\)</span>下计算，一方面是单纯的 <span class="math inline">\(q(\mathbf{x}_{1:T})\)</span>我们没办法计算得出，而 <span class="math inline">\(q(\mathbf{x}_{1:T}|\mathbf{x}_0)\)</span>我们能求出其闭式解，另一方面在训练时我们的确已经 <span class="math inline">\(x_0\)</span>的信息。</p><p>OK，我们继续进行推导</p><p><span class="math display">\[\begin{align} &amp;\ \ \ \ \ \text{ELBO}(\mathbf x_0) \\ &amp;=\mathbbE_{q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{p(\mathbfx_T)\prod_{t=1}^{T}p(\mathbf x_{t-1}\vert\mathbfx_t)}{\prod_{t=1}^{T}q(\mathbf x_t\vert\mathbf x_{t-1})}\right]\\&amp;=\mathbb E_{q(\mathbf x_{1:T}\vert\mathbfx_0)}\left[\log\frac{p(\mathbf x_T)\prod_{t=1}^{T}p(\mathbfx_{t-1}\vert\mathbf x_t)}{q(\mathbf x_1\vert\mathbfx_0)\prod_{t=2}^{T}q(\mathbf x_t\vert\mathbf x_{t-1},\mathbfx_0)}\right]\\ &amp;=\mathbb E_{q(\mathbf x_{1:T}\vert\mathbfx_0)}\left[\log\frac{p(\mathbf x_T)\prod_{t=1}^{T}p(\mathbfx_{t-1}\vert\mathbf x_t)}{q(\mathbf x_1\vert\mathbfx_0)\prod_{t=2}^{T}\frac{q(\mathbf x_t\vert\mathbf x_0)q(\mathbfx_{t-1}\vert\mathbf x_t,\mathbf x_0)}{q(\mathbf x_{t-1}\vert\mathbfx_0)} }\right]\\ &amp;=\mathbb E_{q(\mathbf x_{1:T}\vert\mathbfx_0)}\left[\log\frac{p(\mathbf x_T)\prod_{t=1}^{T}p(\mathbfx_{t-1}\vert\mathbf x_t)}{q(\mathbf x_T\vert\mathbfx_0)\prod_{t=2}^{T}q(\mathbf x_{t-1}\vert\mathbf x_t,\mathbfx_0)}\right]\\ &amp;=\mathbb E_{q(\mathbf x_{1:T}\vert\mathbfx_0)}\left[\log p(\mathbf x_0\vert\mathbf x_1)\right]+\mathbbE_{q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{p(\mathbfx_T)}{q(\mathbf x_T\vert\mathbf x_0)}\right]+\sum_{t=2}^T\mathbbE_{q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{p(\mathbfx_{t-1}\vert\mathbf x_t)}{q(\mathbf x_{t-1}\vert\mathbf x_t,\mathbfx_0)}\right]\\ &amp;=\mathbb E_{q(\mathbf x_{1}\vert\mathbfx_0)}\left[\log p(\mathbf x_0\vert\mathbf x_1)\right]+\mathbbE_{q(\mathbf x_{T}\vert\mathbf x_0)}\left[\log\frac{p(\mathbfx_T)}{q(\mathbf x_T\vert\mathbf x_0)}\right]+\sum_{t=2}^T\mathbbE_{q(\mathbf x_t\vert\mathbf x_0)}\mathbb E_{q(\mathbfx_{t-1}\vert\mathbf x_t,\mathbf x_0)}\left[\log\frac{p(\mathbfx_{t-1}\vert\mathbf x_t)}{q(\mathbf x_{t-1}\vert\mathbf x_t,\mathbfx_0)}\right]\\ &amp;=\underbrace{\mathbb E_{q(\mathbf x_{1}\vert\mathbfx_0)}\left[\log p(\mathbf x_0\vert\mathbfx_1)\right]}_\text{reconstruction term}-\underbrace{\text{KL}(q(\mathbfx_T\vert\mathbf x_0)\Vert p(\mathbf x_T))}_\text{regularizationterm}-\sum_{t=2}^T\mathbb E_{q(\mathbf x_t\vert\mathbfx_0)}\underbrace{\left[\text{KL}(q(\mathbf x_{t-1}\vert\mathbfx_t,\mathbf x_0)\Vert p(\mathbf x_{t-1}\vert\mathbfx_t))\right]}_\text{denoising matching terms} \end{align}\]</span></p><p>同样出现了重构项、正则项和匹配项。重构项要求 $x_1 $ 能够重构 <span class="math inline">\(x_0\)</span> ，正则项要求 <span class="math inline">\(x_T\)</span>的后验分布逼近先验分布，而匹配项则建立起相邻两项 $x_{t−1},x_t $之间的联系。</p><p>现在，我们只需要为式中出现的所有概率分布设计具体的形式，就可以代入计算了。为了让KL 散度可解，一个自然的想法就是把它们都设计为正态分布的形式。</p><h3 id="前向过程">前向过程</h3><p>在DDPM的前向过程中，对于 <span class="math inline">\(t \in[1,T]\)</span> 时刻， <span class="math inline">\(x_t\)</span> 和 <span class="math inline">\(x_{t-1}\)</span> 满足如下关系：</p><p><span class="math display">\[x_t = \sqrt{1-\beta_t}x_{t-1} +\sqrt{\beta_t }\epsilon,  \ \ \ \epsilon\sim N(0,1)\]</span></p><p>其中 <span class="math inline">\(β_t∈(0,1)\)</span>是事先指定的超参数，代表从 $x_{t−1} $ 到 $x_t $ 这一步的方差。</p><p>这里的系数设定为开根号的 $ $，是为了保证马尔科夫链的最后收敛为标准高斯分布。</p><p><strong><span class="math inline">\(\sqrt\beta\)</span> 和 <span class="math inline">\(\sqrt{1-\beta}\)</span> 是怎么来的：</strong></p><p>我们这里先不管 <span class="math inline">\(\beta\)</span>，把两个系数分别设为 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 。</p><p>公式变为：</p><p><span class="math display">\[x_t = ax_{t-1} + b\epsilon\]</span></p><p>我们希望，当 <span class="math inline">\(t\)</span>趋于无穷的时候，<span class="math inline">\(x_t \sim N(0,1), x_{t-1} \simN(0,1)\)</span></p><p>我们知道当两个高斯分布相加时，</p><p><span class="math display">\[X\sim N(\mu_X,\sigma_X^2),Y\simN(\mu_Y,\sigma_Y^2) \]</span></p><p><span class="math display">\[Z=aX+bY \]</span></p><p>则</p><p><span class="math display">\[Z \sim N(a\mu_X+b\mu_Y,a^2\sigma^2+b^2\sigma^2)\]</span></p><p>所以此时</p><p><span class="math display">\[x_t~\simN(a\mu_{t-1}+b\mu_\epsilon,a^2\sigma_{t-1}^2+b^2\sigma_\epsilon^2)\]</span></p><p><span class="math display">\[x_t\sim N(a·0+b·0,a^2·1+b^2·1)\]</span></p><p><span class="math display">\[x_t \sim N(0,a^2+b^2) \]</span></p><p>我们想让 <span class="math inline">\(x_{t-1}\)</span> 和 <span class="math inline">\(\epsilon\)</span> 得到的 <span class="math inline">\(x_{t}\)</span> 也服从标准正态分布，即 $ x_{t}N(0,1)$ ，那么我们就只能让 <span class="math inline">\(a^2+b^2=1\)</span> 。</p><p>再令 <span class="math inline">\(\beta=a^2\)</span> ，则 <span class="math inline">\(a=\sqrt{\beta},b=\sqrt{1-\beta}\)</span> 。</p><p>或者也可以令 <span class="math inline">\(\alpha=b^2\)</span> ，则 $a=x_{t-1}+$ 。</p><p>说白了，这俩系数就是为了让两个服从标准正态分布的噪声相加得到的东西还是服从正态分布。</p><p>OK，在这基础上我们可以继续推导，<strong>让 <span class="math inline">\(x_t\)</span> 用 <span class="math inline">\(x_0\)</span> 来表示</strong>：</p><p>令 <span class="math inline">\(\alpha_t=1-\beta_t\)</span>，则公式变为：</p><p><span class="math display">\[x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon\]</span></p><p>继续推导：</p><p><span class="math display">\[\begin{align*} x_t&amp;=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon\\&amp;=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1} }x_{t-2}+\sqrt{1-\alpha_{t-1}}\epsilon)+\sqrt{1-\alpha_t}\epsilon\\  &amp;=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t(1-\alpha_{t-1})}\epsilon +\sqrt{1-\alpha_t}\epsilon\\ \end{align*}\]</span></p><p>上式最后一行第二项和第三项，可以看做两个正态分布相加。</p><p>由于两个正态分布 <span class="math inline">\(X\simN(\mu_x,\sigma_x^2), Y\sim N(\mu_y, \sigma_y^2)\)</span> ，相加后有</p><p><span class="math inline">\(aX+bY\simN(a\mu_x+b\mu_y,a^2\sigma_x^2+b^2\sigma_y^2)\)</span>。所以，合并两个正态分布，得到：</p><p><span class="math display">\[x_t=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1} }\epsilon\]</span></p><p>由数学归纳法，可以推导出：</p><p><span class="math display">\[x_t=\sqrt{\alpha_t\alpha_{t-1}...\alpha_1}x_0+\sqrt{1-\alpha_t\alpha_{t-1}...\alpha_1}\epsilon\]</span></p><p>再令 <span class="math inline">\(\bar\alpha_t=\alpha_t\alpha_{t-1}...\alpha_1\)</span>，则公式可以进一步化简为：</p><p><span class="math inline">\(x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_{t} }\epsilon\)</span> ，由于</p><p><span class="math display">\[\lim_{t\to\infty}\sqrt{\bar\alpha_t}=0,\quad\lim_{t\to\infty}\sqrt{1-\bar\alpha_t}=1\]</span></p><p>所以我们能够保证马尔科夫链最后能够收敛于标准正态分布</p><h3 id="逆向过程">逆向过程</h3><p>这里从我们熟知的贝叶斯公式出发：</p><p><span class="math display">\[P(A|B)=\frac{P(B|A)P(A)}{P(B)}\]</span></p><p>可知</p><p><span class="math display">\[P(x_{t-1}|x_t)=\frac{P(x_t|x_{t-1})P(x_{t-1})}{P(x_t)}\]</span></p><p>这里我们的 <span class="math inline">\(P(x_{t-1})\)</span> 和 <span class="math inline">\(P(x_t)\)</span> 我们都不知道，但在已知 $ x_0$的情况下有：</p><p><span class="math display">\[P(x_{t-1}|x_t,x_0)=\frac{P(x_t|x_{t-1},x_0)P(x_{t-1}|x_0)}{P(x_t|x_0)}\]</span></p><p>把 <span class="math inline">\(x_0=\sqrt{\bar{\alpha_t} }x_0\)</span>和 <span class="math inline">\(x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_{t} }\epsilon\)</span>带入上式，可得：</p><p><span class="math display">\[P(x_{t-1}|x_t,x_0)=\frac{N(\sqrt{\alpha_t}x_0,1-\bar\alpha_t) N(\sqrt{\bar\alpha_{t-1}}x_0,1-\bar\alpha_{t-1}) }{ N(\sqrt{\bar\alpha_{t}}x_0,1-\bar\alpha_{t}) }\]</span></p><p>已知高斯分布的概率密度函数为：</p><p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\]</span></p><p>所以</p><p><span class="math display">\[P(x_{t-1}|x_t,x_0)\propto   exp-\frac{1}{2}  [   \frac{(x_t-\sqrt{\alpha_t}x_{t-1})^2}{1-\alpha_t}+\frac{(x_{t-1}-\sqrt{\bar\alpha_{t-1} }x_0)^2}{1-\bar\alpha_{t-1} }-\frac{(x_{t}-\sqrt{\bar\alpha_{t} }x_0)^2}{1-\bar\alpha_{t} }]\]</span></p><p>此时由于 <span class="math inline">\(x_{t-1}\)</span>是我们关注的变量，所以整理成关于 <span class="math inline">\(x_{t-1}\)</span> 的形式：</p><p><span class="math display">\[P(x_{t-1}|x_t,x_0)\propto  exp-\frac{1}{2}  [   (\frac{\alpha_t}{1-\alpha_t}+\frac{1}{1-\bar\alpha_{t-1}})x_{t-1}^2  -(\frac{-2\sqrt{\alpha_t}x_t}{1-\alpha_t}   +    \frac{-2\sqrt{\bar\alpha_{t-1}}x_0}{1-\bar\alpha_{t-1} })x_{t-1}   +C(x_t,x_0) ]\]</span></p><p>其中第三项 <span class="math inline">\(C(x_t,x_0)\)</span> 与 <span class="math inline">\(x_{t-1}\)</span>无关，作为指数上相加的部分，可以拿到最前面只影响最前面的系数。</p><p>所以此时：</p><p><span class="math display">\[P(x_{t-1}|x_t,x_0)\propto  exp-\frac{1}{2}  [   (\frac{\alpha_t}{1-\alpha_t}+\frac{1}{1-\bar\alpha_{t-1}})x_{t-1}^2  -(\frac{-2\sqrt{\alpha_t}x_t}{1-\alpha_t}   +  \frac{-2\sqrt{\bar\alpha_{t-1}}x_0}{1-\bar\alpha_{t-1} })x_{t-1}]\]</span></p><p>又因为标准正态分布满足 <span class="math inline">\(\propto exp -\frac{x^2-2\mu x + \mu^2}{2\sigma^2}\)</span> ，所以我们可以得到 <span class="math inline">\(P(x_{t-1}|x_t,x_0)\)</span> 对应的方差</p><p><span class="math display">\[\frac{1}{\sigma^2}=\frac{\alpha_t}{1-\alpha_t}+\frac{1}{1-\bar\alpha_{t-1}}  =\frac{1-\alpha_t\bar\alpha_{t-1}}{(1-\alpha_t)(1-\bar\alpha_{t-1})}  =\frac{1-\bar\alpha_{t}}{(1-\alpha_t)(1-\bar\alpha_{t-1})}\]</span></p><p>这里 <span class="math inline">\(\alpha_t\bar\alpha_{t-1}=\bar\alpha_t\)</span>。所以：</p><p><span class="math display">\[\sigma^2=\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}\]</span></p><p>再看 <span class="math inline">\(x_{t-1}\)</span>的一次项，得到：</p><p><span class="math display">\[\frac{2\mu}{\sigma^2}=(\frac{-2\sqrt{\alpha_t}x_t}{1-\alpha_t}   +  \frac{-2\sqrt{\bar\alpha_{t-1}}x_0}{1-\bar\alpha_{t-1} })\]</span></p><p>把 <span class="math inline">\(\sigma^2\)</span> 和 <span class="math inline">\(x_0\)</span> 带入上式，化简得到： <span class="math display">\[\mu=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t} }\epsilon)\]</span></p><p>所以说： <span class="math display">\[P(x_{t-1}|x_t, x_0)\simN(\frac{1}{\sqrt{\alpha_t} }(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\epsilon),\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t})\]</span></p><p>回顾一下我们写的这一大段公式，也就是说，我们已知了先验概率，推导出了后验概率的表达式，得到了在给定<span class="math inline">\(x_0\)</span> 后的<span class="math inline">\(x_{t-1}\)</span>的分布的均值和方差。也就是说，上面公式中，我们的</p><p><span class="math display">\[q(x_{t-1}\vert x_t,x_0)\simN(\frac{1}{\sqrt{\alpha_t} }(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\epsilon),\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t})\]</span></p><p>接下来， <span class="math inline">\(\epsilon\)</span>的具体值，我们让模型去拟合就好了。</p><h3 id="损失函数">损失函数</h3><p>我们之前已经推导了ELBO的具体形式：</p><p><span class="math display">\[\text{ELBO}= \underbrace{E_{x_1\simq(x_1\vert x_0)}[\log p_\theta(x_0\vert x_1)]}_{ {L_0} }-\underbrace{KL(q(x_T \vert  x_0)\|p(x_T))}_{ {L_T} }-\sum_{t=2}^T\underbrace{E_{x_t\sim q(x_t\vertx_0)}\left[KL(q(x_{t-1}\vert x_t,x_0)\|p_\theta(x_{t-1}\vertx_t))\right]}_{ {L_{t-1} }}\]</span></p><p>这里 <span class="math inline">\(q(x_{t-1}\vert x_t,x_0)\)</span>我们已经得到了， <span class="math inline">\(q(x_{t}|x_0)\)</span>也是我们定义的。只需要定义 <span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>即可，为了计算方便，我们也选择与 <span class="math inline">\(q(x_{t-1}\vert x_t,x_0)\)</span> 一样的形式。</p><p><span class="math display">\[p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)= \mathcal{N}(\textbf{x}_{t-1}; \mu_\theta(\textbf{x}_t, t),\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}I)\]</span></p><p>其中 <span class="math inline">\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) =\frac{1}{\sqrt{\alpha_t} } \Big( \mathbf{x}_t - \frac{1 -\alpha_t}{\sqrt{1 - \bar{\alpha}_t} }\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)\)</span> ，而 <span class="math inline">\({\epsilon}_\theta(\mathbf{x}_t, t)\)</span>就是我们模型的输出。此时，我们带入可以得到</p><p><span class="math display">\[\begin{align}  \mathbf{x}_{t-1} &amp;=\mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t} } ( \mathbf{x}_t- \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t} }{\epsilon}_\theta(\mathbf{x}_t, t) ),\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}I)  \end{align}\]</span></p><p>带入上面KL散度的公式，可以得到损失函数 <span class="math inline">\(L_t\)</span> 便为：</p><p><span class="math display">\[\begin{aligned} L_t  &amp;=\mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon} } \Big[\frac{1}{2 \|\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \|\color{blue}{\tilde{\boldsymbol{\mu} }_t(\mathbf{x}_t, \mathbf{x}_0)} -\color{green}{\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \|^2 \Big] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon} }\Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \|\color{blue}{\frac{1}{\sqrt{\alpha_t} } \Big( \mathbf{x}_t - \frac{1 -\alpha_t}{\sqrt{1 - \bar{\alpha}_t} } \boldsymbol{\epsilon}_t \Big)} -\color{green}{\frac{1}{\sqrt{\alpha_t} } \Big( \mathbf{x}_t - \frac{1 -\alpha_t}{\sqrt{1 - \bar{\alpha}_t} } \boldsymbol{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t) \Big)} \|^2 \Big] \\ &amp;=\mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon} } \Big[\frac{ (1 -\alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \|\boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t -\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\ &amp;=\mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon} } \Big[\frac{ (1 -\alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \|\boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t -\boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1- \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2\Big]  \end{aligned}\]</span></p><p>发现可以使用不用权重的简单形式就可以训练得到好的结果，即</p><p><span class="math display">\[\begin{aligned} L_\text{simple} &amp;=\mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t}\Big[\|\boldsymbol{\epsilon}_t -\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\ &amp;=\mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t}\Big[\|\boldsymbol{\epsilon}_t -\boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1- \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big]\end{aligned}\]</span></p><p>这样，我们就获得了DDPM的最终目标函数：</p><p><span class="math display">\[ L_\text{simple}(\theta)=\mathbbE_{t,x_0,\epsilon}\left[\Vert\epsilon-\epsilon_\theta(x_t,t)\Vert^2\right]\]</span></p><p>具体训练流程和采样流程如下：</p><p><img src="/images/Diffusion%20Model原理/2.png"></p><h2 id="ddim">DDIM</h2><p>DDPM虽好，但它只能一步一步老老实实通过 <span class="math inline">\(x_{t}\)</span> 预测 <span class="math inline">\(x_{t-1}\)</span> ，不能跨步运算，如果 <span class="math inline">\(T =1000\)</span>，那么生成一整图像就需要用网络推理1000次，效率很低。于是为了结局这个问题，DDIM出现了，而且最巧妙的是它不需要重新训练模型。</p><p>DDIM始于一个假设，它假设了</p><p><span class="math display">\[P(x_{prev}|x_t,x_0)\simN(kx_0+mx_t,\sigma_2)\]</span></p><p><span class="math display">\[x_{prev}=kx_0+mx_t+\sigma\epsilon,\ \ \\ \ \epsilon\sim N(0,1)\]</span></p><p>又因为加噪过程满足公式 <span class="math inline">\(x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_{t} }\epsilon\)</span></p><p>把 <span class="math inline">\(x_t\)</span> 带入 <span class="math inline">\(x_{t-1}\)</span> 合并同类项得到：</p><p><span class="math display">\[\begin{align*}x_{prev}&amp;=kx_0+m(\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon)+\sigma\epsilon\\&amp;=(k+m\sqrt{\bar\alpha_t})x_0+\epsilon&#39;\end{align*}\]</span></p><p><span class="math display">\[\epsilon&#39;\simN(0,m^2(1-\bar\alpha_t)+\sigma^2)\]</span></p><p>又因为 <span class="math inline">\(x_{prev}=\sqrt {\bar\alpha_{prev}}x_0+\sqrt{1-\bar\alpha_{prev} }\epsilon\)</span>，满足对应系数相同，有：</p><p><span class="math display">\[k+m\sqrt{\bar\alpha_t}=\sqrt{\bar{\alpha_{prev}}}\\ m^2(1-\bar\alpha_t)+\sigma^2=1-\bar\alpha_{prev}\]</span></p><p>求得：</p><p><span class="math display">\[m=\frac{\sqrt{1-\bar\alpha_{prev}-\sigma^2}}{\sqrt{1-\bar\alpha_t} }\\  k=\sqrt{\bar\alpha_{prev}}-\frac{\sqrt{1-\bar\alpha_{prev}-\sigma^2} }{\sqrt{1-\bar\alpha_t}}\sqrt{\bar\alpha_t}\]</span></p><p>带入公式最终化简得：</p><p><span class="math display">\[x_{prev}=\sqrt{\bar{\alpha_{prev} }}(\frac{x_t-\sqrt{1-\bar\alpha_t}\epsilon_t}{\sqrt{\bar\alpha_t}})  +\sqrt{1-\bar\alpha_{prev}-\sigma^2}\epsilon_t+\sigma^2\epsilon\]</span></p><p>其中 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(prev\)</span>可以相隔多个迭代步数，一般相隔20可以做到采样速度和采样质量比较好地平衡。所以一般DDPM要做1000步，而DDIM是需要50步就可以完成采样。</p><p>当这里的 <span class="math inline">\(\sigma\)</span>选取0的时候，也就意味着变成了一个确定性采样的过程。此时的DDIM就变成了一个FlowModels，事实上论文里也是这么做的。</p><h2 id="从不同角度看扩散模型">从不同角度看扩散模型</h2><p>前面我们DDPM的推导过程中，其实可以把扩散模型看成一个给定后验的<strong>多层VAE</strong>。即认为设定了<span class="math inline">\(p(x_{1:T}|x_0)\)</span>的形式，然后让模型来从潜变量中采样，最终生成图片。</p><p>而DDIM把这个过程变成了一个确定性过程，也就是说把潜变量和数据之间做了一个双射，所以此时也就可以看成<strong>FlowModels</strong>的一个了</p><p>事实上，扩散模型的连续和离散其实对应着随机过程里的概念。一般来说，discretetime指的是随机过程中的时间 <span class="math inline">\(t\)</span>只能取离散整数值，而continous-time则指的是时间参数 <span class="math inline">\(t\)</span> 可以取连续值。discretetime随机过程中的参数在一个离散的时间点只能改变一次；而continuous-time随机过程的参数则可以随时发生变化。</p><h3 id="ddpm和sde">DDPM和SDE</h3><p>我们在DDPM里的加噪过程。每一个timestep，我们都会按照如下的离散马尔可夫链进行加噪：</p><p><span class="math display">\[x_i = \sqrt{1 - \beta_i}x_{i-1} +\sqrt{\beta_i} \epsilon_{i-1}, i=1,..., N\]</span></p><p>为了将上述过程连续化，我们需要引入连续时间随机过程。<strong>而连续时间其实就是让每个离散的时间间隔</strong><span class="math inline">\(\Delta t\)</span><strong>无限趋近于0，其实也等价于求出</strong> <span class="math inline">\(N \to \infty\)</span><strong>​时，上述马尔可夫链的极限</strong></p><p>在求极限之前，我们需要先引入一组辅助的noise scale <span class="math inline">\(\{\bar{\beta}_i = N \beta_i\}_{i=1}^N\)</span>，并将上面的式子改写如下：</p><p><span class="math display">\[x_i = \sqrt{1 - \frac{\bar{\beta}_i}{N}}x_{i-1} + \sqrt{\frac{\bar{\beta}_i}{N} }\epsilon_{i-1}, i = 1,...,N\]</span></p><p>在 <span class="math inline">\(N \to \infty\)</span> ​时，上面的 <span class="math inline">\(\{\bar{\beta}_i\}_{i=1}^{N}\)</span>就成了一个关于时间 <span class="math inline">\(t\)</span> 的连续函数 $(t)$ ​，并且 <span class="math inline">\(t \in [0, 1]\)</span>。随后，我们可以假设 <span class="math inline">\(\Delta t =\frac{1}{N}\)</span> ​，在每个 <span class="math inline">\(i\Deltat\)</span> 时刻，连续函数 <span class="math inline">\(\beta(t), x(t),\epsilon(t)\)</span> 都等于之前的离散值，即：</p><p><span class="math display">\[\beta(\frac{i}{N}) = \bar{\beta}_i,x(\frac{i}{N}) = x_i, \epsilon(\frac{i}{N})=\epsilon_i \]</span></p><p>在 <span class="math inline">\(t \in \{0, 1, ...,\frac{N-1}{N}\}\)</span> ​以及 <span class="math inline">\(\Deltat=\frac{1}{N}\)</span>的情况下，我们就可以用连续函数改写之前的式子：</p><p><span class="math display">\[\begin{align} x(t+ \Delta t) &amp;=\sqrt{1-\beta(t+\Delta t)\Delta t}\ x(t) + \sqrt{\beta(t+\Delta t)\Deltat}\ \epsilon(t) \\ &amp; \approx x(t) - \frac{1}{2}\beta(t+\Delta t)\Delta t\ x(t) + \sqrt{\beta(t+\Delta t)\Delta t}\ \epsilon(t) \\ &amp;\approx x(t) - \frac{1}{2}\beta(t)\Delta t\ x(t) + \sqrt{\beta(t)\Deltat}\ \epsilon(t) \end{align} \]</span></p><p>上面的近似只有在 <span class="math inline">\(\Delta t \ll 1\)</span>时成立。我们将其再移项后就可以得到下式：</p><p><span class="math display">\[x(t+\Delta t) - x(t) \approx-\frac{1}{2} \beta(t)\Delta t\ x(t) + \sqrt{\beta(t)\Delta t}\\epsilon(t) \\ \mathrm{d} x = -\frac{1}{2}\beta(t)x \mathrm{d}t +\sqrt{\beta(t)} \mathrm{d}w \]</span></p><p>其中， <span class="math inline">\(w\)</span> ​表示的就是WienerProcess。这里面的第二个式子，就是一SDE方程。</p><p>至此，我们证明了DDPM连续化之后，就可以得到一个SDE方程，并且它是一种VariancePreserving的SDE。<strong>Variance Preserving的含义是当</strong> <span class="math inline">\(t \to \infty\)</span><strong>时，它的方差依然有界</strong>。</p><p>与此<strong>反向过程也是一个SDE方程，称为reverse SDE</strong>：</p><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - g^2(t)\nabla _{\mathbf{x} }\logp(\mathbf{x})]\text{d}\mathbf{t} + g(t)\text{d}\mathbf{w}\]</span></p><p>这个反向过程中的未知量就只有分数函数 $ <em>x p</em>{t}(x)$​。至此，DDPM和分数模型也产生了联系，实际上二者之间是相互等价的。而DDPM和分数模型本质上都是在学习这个reverseSDE的解。 我们可以看到，DDPM每一步的去噪其实本质上与<strong>AnnealedLangevin dynamics</strong>是一模一样的。</p><p><img src="/images/Diffusion%20Model原理/3.png"></p><h3 id="ddim与ode">DDIM与ODE</h3><p>首先对于一个SDE，</p><p><span class="math display">\[\text{d}\mathbf{x}=\mathbf{f}(\mathbf{x}, t)\text{d}\mathbf{t} +g(t)\text{d}\mathbf{w}\]</span></p><p>我们写出它的<strong>福克-普朗克方程（Fokker-Planckequation）</strong>：</p><p><span class="math display">\[\begin{align*} \nabla _{t}p(\mathbf{x},t) &amp;= -\nabla _{\mathbf{x} }[\mathbf{f}(\mathbf{x}, t)p(\mathbf{x},t)] + \frac{1}{2}g^{2}(t)\nabla _{\mathbf{x} }^{2}p(\mathbf{x}, t)\\&amp;= -\nabla _{\mathbf{x} }[\mathbf{f}(\mathbf{x}, t)p(\mathbf{x}, t)- \frac{1}{2}(g^{2}(t) - \sigma^{2}(t))\nabla_\mathbf{x}p(\mathbf{x},t)] + \frac{1}{2}\sigma^{2}(t)\nabla _{\mathbf{x} }^{2}p(\mathbf{x},t)\\   &amp;= -\nabla _{\mathbf{x} }[(\mathbf{f}(\mathbf{x}, t) -\frac{1}{2}(g^{2}(t) - \sigma^{2}(t))\nabla_\mathbf{x}\log p(\mathbf{x},t))p(\mathbf{x})] + \frac{1}{2}\sigma^{2}(t)\nabla _{\mathbf{x}}^{2}p(\mathbf{x}, t)\\\end{align*}\]</span></p><p>现在我们把福克-普朗克方程变成了这样：</p><p><span class="math display">\[\nabla_{t}p(\mathbf{x}, t) =-\nabla_{\mathbf{x} }[(\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}(g^{2}(t)- \sigma^{2}(t))\nabla_\mathbf{x}\log p(\mathbf{x}, t))p(\mathbf{x})] +\frac{1}{2}\sigma^{2}(t)\nabla _{\mathbf{x} }^{2}p(\mathbf{x},t)\]</span></p><p>其对应的SDE为：</p><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}(g^{2}(t) -\sigma^{2}(t))\nabla_{\mathbf{x} }\logp_{t}(\mathbf{x})]\text{d}\mathbf{t} +\sigma(t)\text{d}\mathbf{w}\]</span></p><p>因为前后两个SDE是等价的，他们对应的 <span class="math inline">\(p_{t}(\mathbf{x})\)</span>是一样的，意味着我们可以改变第二个SDE的方差 <span class="math inline">\(\sigma(t)\)</span> 。当我们取 <span class="math inline">\(\sigma(t)=0\)</span>，可以得到一个<strong>常微分方程(Ordinary Differential Equation,ODE)</strong>,</p><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}g^{2}(t)\nabla_ {\mathbf{x}}\log p_{t}(\mathbf{x})]\text{d}\mathbf{t}\]</span></p><p><img src="/images/Diffusion%20Model原理/4.png"></p><p>这个结论有什么作用呢？首先，我们其实更在乎的是边缘概率分布 <span class="math inline">\(q_t(x)\)</span> ，因为我们需要保证它在足够长的时刻<span class="math inline">\(T\)</span> ， <span class="math inline">\(q_T(x)\)</span> 可以变成一个纯噪声，同时我们还需要<span class="math inline">\(q_0(x)\)</span>​符合原始数据分布。上述结论可以保证这一点。同时，扩散模型本质上是在学习一个扩散过程的逆过程，既然前向SDE存在一个对应的ODE，<strong>那么反向过程reverseSDE其实也有一个对应的ODE，这个反向过程对应的ODE形式也是上面的式子</strong>。</p><p>而 DDIM 恰是一种确定性情形，所以我们自然会想到——能不能用 ODE来描述一个 DDIM 呢？答案是肯定的。DDIM的公式如下：</p><p><span class="math display">\[\begin{align}x_{t-1}&amp;=\sqrt{\bar\alpha_{t-1}}x_\theta(x_t,t)+\sqrt{1-\bar\alpha_{t-1} }\epsilon_\theta(x_t,t)\\&amp;=\frac{\sqrt{\bar\alpha_{t-1} }}{\sqrt{\bar\alpha_t}}\left(x_t-\sqrt{1-\bar\alpha_t}\epsilon_\theta(x_t,t)\right)+\sqrt{1-\bar\alpha_{t-1}}\epsilon_\theta(x_t,t) \end{align}\]</span></p><p>两边均减去 <span class="math inline">\(x_t\)</span> ，得：</p><p><span class="math display">\[\begin{align}x_{t-1}-x_t&amp;=\frac{1}{\sqrt{\bar\alpha_t}}\left[\left(\sqrt{\bar\alpha_{t-1}}-\sqrt{\bar\alpha_t}\right)x_t-\left(\sqrt{\bar\alpha_{t-1}(1-\bar\alpha_t)}-\sqrt{\bar\alpha_t(1-\bar\alpha_{t-1})}\right)\epsilon_\theta(\mathbfx_t,t)\right]\\ &amp;=\frac{1}{\sqrt{\bar\alpha_t}}\left(\frac{\bar\alpha_{t-1}-\bar\alpha_t}{\sqrt{\bar\alpha_{t-1}}+\sqrt{\bar\alpha_t}}x_t-\frac{\bar\alpha_{t-1}-\bar\alpha_t}{\sqrt{\bar\alpha_{t-1}(1-\bar\alpha_t)}+\sqrt{\bar\alpha_t(1-\bar\alpha_{t-1})}}\epsilon_\theta(x_t,t)\right)\\&amp;=\frac{\bar\alpha_{t-1}-\bar\alpha_t}{\sqrt{\bar\alpha_t}}\left(\frac{x_t}{\sqrt{\bar\alpha_{t-1} }+\sqrt{\bar\alpha_t}}-\frac{\epsilon_\theta(\mathbfx_t,t)}{\sqrt{\bar\alpha_{t-1}(1-\bar\alpha_t)}+\sqrt{\bar\alpha_t(1-\bar\alpha_{t-1})}}\right) \end{align}\]</span></p><p>记 <span class="math inline">\(x(t)=x_t,\barα(t)=\barα_t\)</span>，将 <span class="math inline">\(t-1\)</span> 换成 <span class="math inline">\(t−Δt\)</span> 并令 <span class="math inline">\(Δt→0\)</span> ，得：</p><p><span class="math display">\[\mathrm dx=\frac{\mathrmd\bar\alpha(t)}{\sqrt{\bar\alpha(t)}}\left(\frac{x(t)}{2\sqrt{\bar\alpha(t)}}-\frac{\epsilon_\theta(x(t),t)}{2\sqrt{\bar\alpha(t)(1-\bar\alpha(t))}}\right)=\frac{\bar\alpha&#39;(t)}{2\bar\alpha(t)}\left(x(t)-\frac{\epsilon_\theta(x(t),t)}{\sqrt{1-\bar\alpha(t)}}\right)\mathrm dt \]</span></p><p><strong>这就是 DDIM 的 ODE 描述</strong>。</p><p>在 DDPM 的设置下，有 $f(x,t)=−β(t)x,g(t)= $ ，代入</p><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}g^{2}(t)\nabla_ {\mathbf{x}}\log p_{t}(\mathbf{x})]\text{d}\mathbf{t}\]</span></p><p>得：</p><p><span class="math display">\[\mathrmdx=\left[-\frac{1}{2}\beta(t)x-\frac{1}{2}\beta(t)\nabla_{\mathbf{x}}\log p_{t}(\mathbf{x})\right]\mathrmdt=-\frac{1}{2}\beta(t)\left[x+\nabla_{\mathbf{x} }\logp_{t}(\mathbf{x})\right]\mathrm dt\]</span></p><p>与我们上面的式子对应。</p><p>既然引入了ODE，那么我们的模型就可以去学习如何解这个ODE，同时也可以引入各种传统的ODEsolver例如：Euler method, Runge–Kuttamethod等一些方法。这就是为什么我们可以看到像StableDiffusion之类的模型会有那么多sampler的原因，本质上都是一些ODEsolver和SDE solver。但是后面的研究者发现，传统的ODEsolver在采样效果上比不过DDIM，这就非常奇怪了。DPM-Solver的作者在他们的论文中给出了原因：<strong>DDIM充分利用了diffusionODE的半线性结构（semi-linear structure），并且它是一个semi-linearODE的一阶Solver，而传统的ODEsolver并没有利用好这个半线性结构，因此DDIM的准确度会更高一些，因此采样效果也更好。</strong></p><p>这里还需要注意的点是，<strong>diffusion ODE这类模型相比diffusionSDE存在着诸多好处</strong>，比如：</p><ul><li>没有随机性，ODE是一个确定性过程，可以以更快的速度收敛，因此可以达到更快的采样速度</li><li>由于是确定性过程，可以计算数据似然（likelihood）等。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford
CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h2 id=&quot;引入&quot;&gt;引入&lt;/h2&gt;
&lt;p&gt;前面的课程中我们已经学习了许多生成模型的架构，例如VAEs，Score Based
Models等。在课程的最后</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Score Based Models</title>
    <link href="https://jia040223.github.io/2024/09/24/Score%20Based%20Models/"/>
    <id>https://jia040223.github.io/2024/09/24/Score%20Based%20Models/</id>
    <published>2024-09-24T12:40:58.000Z</published>
    <updated>2024-09-25T10:50:29.370Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习StanfordCS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h1 id="引入">引入</h1><h2 id="score-function">Score function</h2><p>上一次我们学习了Energy Based Model。其核心做法是对一个数据集 <span class="math inline">\({x_{1}, x_{2}, ..., x_{N}}\)</span>，我们把数据的概率分布 <span class="math inline">\(p(x)\)</span>建模为：</p><p><span class="math display">\[p_{\theta}(\mathbf{x}) =\frac{e^{-f_{\theta}(\mathbf{x})}}{Z_{\theta}}\]</span></p><p>这里 <span class="math inline">\(f_{\theta}(\mathbf{x})\in\mathbb{R}\)</span> 。 <span class="math inline">\(Z_{\theta}\)</span>是归一化项保证 <span class="math inline">\(p_{\theta}(\mathbf{x})\)</span> 是概率。 <span class="math inline">\(\theta\)</span> 是他们的参数。<br>我们一般可以通过最大似然估计的方式来训练参数 <span class="math inline">\(\theta\)</span> ，</p><p><span class="math display">\[\max_{\theta}\sum\limits_{i=1}^{N}\log_{\theta}(\mathbf{x}_{i})\]</span></p><p>但是因为</p><p><span class="math display">\[\log p_{\theta}(\mathbf{x}) =-f_{\theta}(\mathbf{x}) - \log Z_{\theta}\]</span></p><p><span class="math inline">\(Z_{\theta}\)</span>是intractable的，我们无法求出 <span class="math inline">\(\logp_{\theta}(\mathbf{x})\)</span> ，自然也就无法优化参数 <span class="math inline">\(\theta\)</span> 。</p><p><strong>为了解决归一化项无法计算的问题，我们引入scorefunction。</strong> score function的定义为 <span class="math inline">\(\nabla _{\mathbf{x}}\logp(\mathbf{x})\)</span></p><p>所以我们可以发现，score function是与 <span class="math inline">\(Z_{\theta}\)</span> 无关的：</p><p><span class="math display">\[\mathbf{s}_{\theta}(\mathbf{x}) =\nabla_{\mathbf{x}}\log(\mathbf{x}_{\theta}) =-\nabla_{\mathbf{x}}f_{\theta}(\mathbf{x}) - \nabla_{\mathbf{x}}\logZ_{\theta} = -\nabla_{\mathbf{x}}f _{\theta}(\mathbf{x})\]</span></p><h1 id="score-based-model">Score Based Model</h1><h2 id="score-matching">Score matching</h2><p>现在我们想要训练一个网络来估计出真实的scorefunction。自然地，我们可以最小化真实的scorefunction和网络输出的MSE：</p><p><span class="math display">\[\mathcal{L} =\frac{1}{2}\mathbb{E}_{p(\mathbf{x})}[||\nabla_{\mathbf{x}}\log p(\mathbf{x}) -\mathbf{s} _{\theta}(\mathbf{x})||^{2}]\]</span></p><p><img src="/images/Score%20Based%20Models/1.png"><br>但是这样的一个loss我们是算不出来的，因为我们并不知道真实的 <span class="math inline">\(p(\mathbf{x})\)</span> 是什么。<strong>而scorematching方法就可以让我们在不知道真实的</strong> <span class="math inline">\(p(\mathbf{x})\)</span><strong>的情况下最小化这个loss。</strong>Scorematching的推导如下：<br>我们把上面loss的期望写开，二次项打开，可以得到</p><p><span class="math display">\[\begin{align*}\mathcal{L} =&amp;\frac{1}{2}\mathbb{E}_{p(\mathbf{x})}[||\nabla _{\mathbf{x}}\logp(\mathbf{x}) - \mathbf{s} _{\theta}(\mathbf{x})||^{2}]\\=&amp;\frac{1}{2}\int p(\mathbf{x}) [||\nabla _{\mathbf{x}}\logp(\mathbf{x})||^{2} + ||\mathbf{s} _{\theta}(\mathbf{x})||^{2} -2(\nabla _{\mathbf{x}}\log p(\mathbf{x}))^{T}\mathbf{s}_{\theta}(\mathbf{x})] d \mathbf{x}\end{align*}\]</span></p><p>第一项对于 <span class="math inline">\(\theta\)</span>来说是常数可以忽略。<br>第二项为</p><p><span class="math display">\[\int p(\mathbf{x}) ||\mathbf{s}_{\theta}(\mathbf{x})||^{2} d \mathbf{x}\]</span></p><p>对于第三项，若 <span class="math inline">\(\mathbf{x}\)</span>的维度为 <span class="math inline">\(N\)</span> ：</p><p><span class="math display">\[\begin{align*}&amp; -2\int p(\mathbf{x}) (\nabla _{\mathbf{x}}\logp(\mathbf{x}))^{T}\mathbf{s} _{\theta}(\mathbf{x}) d\mathbf{x}\\   =&amp; -2 \int p(\mathbf{x})\sum\limits_{i=1}^{N}\frac{\partial \log p(\mathbf{x})}{\partial\mathbf{x}_{i}}\mathbf{s}_{\theta i}(\mathbf{x}) d \mathbf{x}\\   =&amp;-2 \sum\limits_{i=1}^{N} \int p(\mathbf{x}) \frac{1}{p(\mathbf{x})}\frac{\partial p(\mathbf{x})}{\partial \mathbf{x}_{i}}\mathbf{s}_{\thetai}(\mathbf{x}) d \mathbf{x}\\   =&amp; -2 \sum\limits_{i=1}^{N} \int\frac{\partial p(\mathbf{x})}{\partial \mathbf{x}_{i}}\mathbf{s}_{\thetai}(\mathbf{x}) d \mathbf{x}\\ =&amp; 2 \sum\limits_{i=1}^{N} - \int\frac{\partial p(\mathbf{x})\mathbf{s}_{\theta i}(\mathbf{x})}{\partial\mathbf{x}_{i}} d \mathbf{x} + \int p(\mathbf{x}) \frac{\partial\mathbf{s}_{\theta i}(\mathbf{x})}{\partial \mathbf{x}_{i}}  d\mathbf{x}\\  =&amp;  2 \sum\limits_{i=1}^{N} - \intp(\mathbf{x})\mathbf{s}_{\thetai}(\mathbf{x})\bigg\rvert^{\infty}_{-\infty} d \mathbf{x_{/i}} + \intp(\mathbf{x}) \frac{\partial \mathbf{s}_{\theta i}(\mathbf{x})}{\partial\mathbf{x}_{i}}  d \mathbf{x}\\   =&amp; 2 \sum\limits_{i=1}^{N} \intp(\mathbf{x}) \frac{\partial \mathbf{s}_{\theta i}(\mathbf{x})}{\partial\mathbf{x}_{i}}  d \mathbf{x}\\    =&amp; 2\int p(\mathbf{x})\sum\limits_{i=1}^{N} \frac{\partial \mathbf{s}_{\thetai}(\mathbf{x})}{\partial \mathbf{x}_{i}}  d \mathbf{x}\\ =&amp; 2\intp(\mathbf{x}) \text{tr}(\nabla_{\mathbf{x}}\mathbf{s}_{\theta}(\mathbf{x})) d \mathbf{x}\end{align*}\]</span></p><p>所以最后的loss是第二和第三项的和：</p><p><span class="math display">\[\begin{align*} \mathcal{L} &amp;=\frac{1}{2} \int p(\mathbf{x})||\mathbf{s} _{\theta}(\mathbf{x})||^{2} d \mathbf{x} + \intp(\mathbf{x}) \text{tr}(\nabla_{\mathbf{x}}\mathbf{s}_{\theta}(\mathbf{x})) d \mathbf{x}\\\\   &amp;=\mathbb{E}_{p(\mathbf{x})}[\frac{1}{2}||\mathbf{s}_{\theta}(\mathbf{x})||^{2} + \text{tr}(\nabla_{\mathbf{x}}\mathbf{s}_{\theta}(\mathbf{x}))]\end{align*}\]</span></p><p><img src="/images/Score%20Based%20Models/2.png"><br>当然，这个推导虽然是从能量模型引入的，但并不局限于能量模型，事实上，他是一个更大的模型家族。</p><p><img src="/images/Score%20Based%20Models/3.png"></p><h2 id="score-matching-langevin-dynamics-smld">Score Matching LangevinDynamics (SMLD)</h2><p>现在我们已经通过神经网络学习到了数据分布的scorefunction，那么如何用scorefunction从这个数据分布中得到样本呢？答案就是朗之万动力学采样(LangevinDynamics):</p><p><span class="math display">\[\mathbf{x}_{i+1} = \mathbf{x}_{i} + \epsilon \nabla_{\mathbf{x}}\logp(\mathbf{x}) + \sqrt{2 \epsilon}\mathbf{z}_{i}, \quad \mathbf{z} _{i}\sim \mathcal{N}(\mathbf{0}, \mathbf{I}), \quad i=0,1,\cdots K\\]</span></p><p>这里的采样是一个迭代的过程。 <span class="math inline">\(\epsilon\)</span> 是一个很小的量。 <span class="math inline">\(\mathbf{x}_{0}\)</span>随机初始，通过上面的迭代式更新。当迭代次数 <span class="math inline">\(K\)</span> 足够大的时候， <span class="math inline">\(\mathbf{x}\)</span> 就收敛于该分布的一个样本。</p><p><img src="/images/Score%20Based%20Models/4.png"><br>上图的具体解释我就不再赘述了。</p><p>这样我们其实就得到了一个生成模型。我们可以先训练一个网络用来估计scorefunction，然后用Langevin Dynamics和网络估计的scorefunction采样，就可以得到原分布的样本。因为整个方法由scorematching和Langevin Dynamics两部分组成，所以叫<strong>SMLD</strong>。</p><h2 id="训练">训练</h2><p>说完了损失函数和采样过程，那么对这个模型我们怎么训练呢？相信敏锐的读者已经注意到了，我们损失函数：</p><p><span class="math display">\[\begin{align*} \mathcal{L}  &amp;=\mathbb{E}_{p(\mathbf{x})}[\frac{1}{2}||\mathbf{s}_{\theta}(\mathbf{x})||^{2} + \text{tr}(\nabla_{\mathbf{x}}\mathbf{s}_{\theta}(\mathbf{x}))]\end{align*}\]</span></p><p>这个第二项并不是很好计算。对于维度为 <span class="math inline">\(N\)</span> 的数据，我们计算雅可比矩阵的迹需要进行<span class="math inline">\(N\)</span>次反向传播，这对于高维度的数据的训练是不能接受的。</p><p>对于这个问题，主要有两种解决方法。</p><h3 id="denoising-score-matching">Denoising score matching</h3><p>Denoising score matching的做法就是在 score matching的基础上，对输入数据加噪。<strong>需要注意的是，此时的 score是对加噪后的数据进行求导，而非原输入数据。</strong>score的方向是(对数)概率密度增长最快的方向，也就是最接近真实数据的方向。<br>Denoising score matching 的玩法是：在给定输入 <span class="math inline">\(x\)</span> 的情况下，将条件分布$q(|x)$建模为高斯分布，其中 <span class="math inline">\(\tilde{x}\)</span>代表加噪后的数据，并且边缘化这个条件分布，以 <span class="math inline">\(p(\tilde{x}) \equiv \int q(\tilde{x}|x)p(x)dx\)</span>来近似原数据分布，<strong>因此噪声强度不太大时，我们可以认为加噪后数据的概率分布与原数据的概率分布大致相同</strong>。</p><p><img src="/images/Score%20Based%20Models/5.png"></p><p>此时，score <span class="math inline">\(\frac{\partiallog(p(\tilde{x}))}{\partial \tilde{x}}\)</span> 中由于 $ p(x)$项在求导时与 <span class="math inline">\(\tilde{x}\)</span>无关，可以略去了，具体推导如下：</p><p><span class="math display">\[\begin{align*} \frac{1}{2} \mathbb{E}_{\tilde{x} \sim q_{\sigma}} \left[\| \nabla_{\tilde{x}} \log q_{\sigma}(\tilde{x}) - s_{\theta}(\tilde{x})\|_2^2 \right] &amp;= \frac{1}{2} \int q_{\sigma}(\tilde{x}) \|\nabla_{\tilde{x}} \log q_{\sigma}(\tilde{x}) - s_{\theta}(\tilde{x})\|_2^2 d\tilde{x} \\ &amp;= \frac{1}{2} \int q_{\sigma}(\tilde{x}) \|\nabla_{\tilde{x}} \log q_{\sigma}(\tilde{x}) \|_2^2 d\tilde{x} +\frac{1}{2} \int q_{\sigma}(\tilde{x}) \| s_{\theta}(\tilde{x}) \|_2^2d\tilde{x}- \int q_{\sigma}(\tilde{x}) \nabla_{\tilde{x}} \logq_{\sigma}(\tilde{x})^T s_{\theta}(\tilde{x}) d\tilde{x} \end{align*}\]</span><br>这里一样的，第一项是常数，第二项只涉及 <span class="math inline">\(s_{\theta}(\tilde{x})\)</span>，我们可以处理，第三项比较棘手。但我们可以类似地用分布积分法进行处理：</p><p><span class="math display">\[\begin{align*} &amp;- \int q_{\sigma}(\tilde{x}) \nabla_{\tilde{x}} \logq_{\sigma}(\tilde{x})^T s_{\theta}(\tilde{x}) d\tilde{x} \\ &amp;= -\int q_{\sigma}(\tilde{x}) \frac{1}{q_{\sigma}(\tilde{x})}\nabla_{\tilde{x}} q_{\sigma}(\tilde{x})^T s_{\theta}(\tilde{x})d\tilde{x} \\ &amp;= - \int \nabla_{\tilde{x}} q_{\sigma}(\tilde{x})^Ts_{\theta}(\tilde{x}) d\tilde{x} \\ &amp;= - \int \nabla_{\tilde{x}}\left( \int p_{\text{data}}(x) q_{\sigma}(\tilde{x} | x) dx \right)^Ts_{\theta}(\tilde{x}) d\tilde{x} \\ &amp;= - \int \left( \intp_{\text{data}}(x) \nabla_{\tilde{x}} q_{\sigma}(\tilde{x} | x) dx\right)^T s_{\theta}(\tilde{x}) d\tilde{x} \\ &amp;= - \int \left( \intp_{\text{data}}(x) q_{\sigma}(\tilde{x} | x) \nabla_{\tilde{x}} \logq_{\sigma}(\tilde{x} | x) dx \right)^T s_{\theta}(\tilde{x}) d\tilde{x}\\ &amp;= - \int \int p_{\text{data}}(x) q_{\sigma}(\tilde{x} | x)\nabla_{\tilde{x}} \log q_{\sigma}(\tilde{x} |x)^Ts_{\theta}(\tilde{x})  dx \ d\tilde{x}  \end{align*}\]</span><br>这里我们 <span class="math inline">\(q(\tilde{x}|x)\)</span>是已知的，也就可以计算了。</p><p>OK，让我们代入原式之中：</p><p><span class="math display">\[\begin{align*} &amp;\frac{1}{2} \mathbb{E}_{\tilde{\mathbf{x}} \simq_{\sigma}} \left[ \|\nabla_{\tilde{\mathbf{x}}} \log q_{\sigma}(\tilde{\mathbf{x}}) - s_{\theta} (\tilde{\mathbf{x}}) \|_2^2 \right] \\&amp;= \text{const.} + \frac{1}{2} \mathbb{E}_{\mathbf{x} \simq_{\sigma}} \left[ \| s_{\theta} (\mathbf{x}) \|_2^2 \right] - \intq_{\sigma} (\tilde{\mathbf{x}}) \nabla_{\tilde{\mathbf{x}}} \logq_{\sigma} (\tilde{\mathbf{x}})^{\top} s_{\theta} (\tilde{\mathbf{x}})d\tilde{\mathbf{x}} \\ &amp;= \text{const.} + \frac{1}{2}\mathbb{E}_{\mathbf{x} \sim q_{\sigma}} \left[ \| s_{\theta}(\tilde{\mathbf{x}}) \|_2^2 \right] - \mathbb{E}_{\mathbf{x} \simp_{\text{data}}(\mathbf{x}), \tilde{\mathbf{x}} \simq_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x})} \left[\nabla_{\tilde{\mathbf{x}}} \log q_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x})^{\top} s_{\theta} (\tilde{\mathbf{x}})\right] \\ &amp;= \text{const.} + \frac{1}{2} \mathbb{E}_{\mathbf{x}\sim p_{\text{data}}(\mathbf{x}), \tilde{\mathbf{x}} \simq_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x})} \left[ \| s_{\theta}(\tilde{\mathbf{x}}) - \nabla_{\tilde{\mathbf{x}}} \log q_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x}) \|_2^2 \right] - \frac{1}{2}\mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\mathbf{x}),\tilde{\mathbf{x}} \sim q_{\sigma}(\tilde{\mathbf{x}})} \left[ \|\nabla_{\tilde{\mathbf{x}}} \log q_{\sigma} (\tilde{\mathbf{x}}) \|_2^2\right] \\ &amp;= \text{const.} + \frac{1}{2} \mathbb{E}_{\mathbf{x}\sim p_{\text{data}}(\mathbf{x}), \tilde{\mathbf{x}} \simq_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x})} \left[ \| s_{\theta}(\tilde{\mathbf{x}}) - \nabla_{\tilde{\mathbf{x}}} \log q_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x}) \|_2^2 \right] +\text{const.}      \end{align*}\]</span></p><p>看到没有！这也就是说，score 的方向与所加噪声的方向是相反的。 于是，在denoising score matching 的体制下，朝着 score的方向走，其实就是在<strong>去噪，在做 denoising</strong>。</p><p><img src="/images/Score%20Based%20Models/6.png"><br>在实践中，我们可以选择将 <span class="math inline">\(q(\tilde{x}|x)\)</span> 建模为 <span class="math inline">\(N(\tilde{x};x;\sigma^2)\)</span> ，即均值为原数据<span class="math inline">\(x\)</span> ，方差为预设的 <span class="math inline">\(\sigma^2\)</span>的高斯分布。于是，根据高斯分布的性质，有：</p><p><span class="math display">\[\tilde{x}=x + \sigma \epsilon,\epsilon\sim N(0,I)\]</span></p><p>其中， <span class="math inline">\(\epsilon\)</span>是从标准高斯分布中采样出来的噪声。</p><p>接着，在以上化简出的 score 中代入高斯分布的概率密度函数，可以得到score 为：</p><p><span class="math display">\[\frac{\partial log(q(\tilde{x}|x))}{\partial \tilde{x}} =-(\frac{\tilde{x}-x}{\sigma^2})=-\frac{\epsilon}{\sigma}\]</span></p><p>虽然我们对计算进行了大幅度简化，但这也导致了我们估计的是<strong>加噪数据的梯度</strong>。具体训练流程如下：</p><p><img src="/images/Score%20Based%20Models/7.png"></p><h3 id="sliced-score-matching">Sliced score matching</h3><p>Sliced scorematching的思想是，如果模型预测的梯度与真实梯度相同等价于他们在不同方向下的投影均相同，所以我们引入一个投影向量用于训练。这样我们的目标和最终化简（用<strong>分部积分</strong>即可）的格式如下：</p><ul><li><strong>goal：</strong> <span class="math display">\[\frac{1}{2} \mathbb{E}_{\mathbf{v} \sim p_v} \mathbb{E}_{\mathbf{x} \simp_{\text{data}}} \left[ \left( \mathbf{v}^{\top} \nabla_{\mathbf{x}}\log p_{\text{data}} (\mathbf{x}) - \mathbf{v}^{\top} s_{\theta}(\mathbf{x}) \right)^2 \right]\]</span></li><li><strong>loss：</strong> <span class="math display">\[\mathbb{E}_{\mathbf{v} \sim p_v}\mathbb{E}_{\mathbf{x} \sim p_{\text{data}}} \left[ \mathbf{v}^{\top}\nabla_{\mathbf{x}} s_{\theta} (\mathbf{x}) \mathbf{v} + \frac{1}{2}(\mathbf{v}^{\top} s_{\theta} (\mathbf{x}))^2 \right]\]</span></li></ul><p><img src="/images/Score%20Based%20Models/8.png"><br>这样我们便只需要进行<strong>一次</strong>反向传播了，大大减少了训练需要的计算量，计算图如下：</p><p><img src="/images/Score%20Based%20Models/9.png"><br>具体训练过程如下：</p><p><img src="/images/Score%20Based%20Models/10.png"><br>虽然这种方法的训练计算量会比Denoising scorematching大，但它是对真实数据梯度进行的估计</p><h2 id="问题">问题</h2><p>现在我们得到了SMLD生成模型，但实际上这个模型由很大的问题。首先看一下其在实践中的效果：</p><p><img src="/images/Score%20Based%20Models/11.png"><br>可以看到效果并不好。我们不妨从损失函数来分析一下原因：</p><p><span class="math display">\[\mathcal{L}    = \mathbb{E}_{p(\mathbf{x})}[||\nabla_{\mathbf{x}}\logp(\mathbf{x}) - \mathbf{s}_{\theta}(\mathbf{x})||^{2}]     = \intp(\mathbf{x})||\nabla_{\mathbf{x}}\log p(\mathbf{x}) - \mathbf{s}_{\theta}(\mathbf{x})||^{2}  d \mathbf{x}\\]</span></p><p>观察我们用来训练神经网络的损失函数，我们可以发现这个L2项其实是被<span class="math inline">\(p(\mathbf{x})\)</span>加权了。所以对于低概率的区域，估计出来的score function就很不准确：</p><p><img src="/images/Score%20Based%20Models/12.png"><br>对于上面这张图来说，只有在高概率的红色区域，loss才高，scorefunction可以被准确地估计出来。但如果我们采样的初始点在低概率区域的话，因为估计出的scorefunction不准确，很有可能生成不出真实分布的样本。</p><p>此外，在现实中，比如对于图片来说，其往往是分布在一个<strong>低维度流型</strong>上，也就是大部分空间的概率密度几乎为0，此时我们的梯度定义已经失去了意义：</p><p><img src="/images/Score%20Based%20Models/13.png"><br>同时，我们通过<strong>LangevinDynamics</strong>进行采样并不能很好还原聚点的样本比：</p><p><img src="/images/Score%20Based%20Models/14.png"></p><h2 id="smld的改进">SMLD的改进</h2><p>那怎么样才能解决上面的问题呢？<strong>Denoising scorematching</strong>给我们给了一定的启发。<br>其实可以通过给数据增加噪声扰动的方式扩大高概率区域的面积。给原始分布加上高斯噪声，原始分布的方差会变大。这样相当于高概率区域的面积就增大了，更多区域的scorefunction可以被准确地估计出来。</p><p><img src="/images/Score%20Based%20Models/15.png"><br>但是噪声扰动的强度如何控制是个问题：</p><ul><li>强度太小起不到效果，高概率区域的面积还是太小</li><li>强度太大会破坏数据的原始分布，估计出来的scorefunction就和原分布关系不大了</li></ul><p>所以噪声强度越高，高概率区域面积越大，训练得到的梯度越准，但与原始数据的梯度差距也就越大。所以我们不妨加不同程度的噪声，让网络可以学到加了不同噪声的原始分布的scorefunction。这样既保证了原始低概率密度地区能学习到有效的梯度，同时原始高概率密度区的梯度估计是准确的。</p><p><img src="/images/Score%20Based%20Models/16.png"><br>说起来很拗口，其实很好理解。我们定义序列 <span class="math inline">\({\sigma_{1 \sim L}} , \quad \sigma {1} \lt \sigma{2} \lt \cdots \lt \sigma _{L}\)</span>，代表从小到大的噪声强度。这样我们可以定义经过噪声扰动之后的数据样本，服从一个经过噪声扰动之后的分布，</p><p><span class="math display">\[\mathbf{x} + \sigma_{i}\mathbf{z}  = \int p(\mathbf{y})\mathcal{N}(\mathbf{x}|\mathbf{y}, \sigma {i}^{2}\mathbf{I})d\mathbf{y}\\]</span></p><p>我们用神经网络来估计经过噪声扰动过的分布的scorefunction，并把噪声强度 <span class="math inline">\(\sigma_i\)</span>作为一个输入：</p><p><span class="math display">\[\mathcal{L} = \frac{1}{L}\sum_\limits {i=1}^{L} \lambda (i)\mathbb{E}_{p _{\sigma {i}}(\mathbf{x})}[||\nabla_{\mathbf{x}}\logp_{\sigma _ {i}}(\mathbf{x}) - \mathbf{s} _{\theta}(\mathbf{x,\sigma_i})||^{2}]\]</span></p><p>其中 <span class="math inline">\(\lambda(i)\)</span>是权重，在实践中可以取 <span class="math inline">\(\sigma_{i}^{2}\)</span></p><p><img src="/images/Score%20Based%20Models/17.png"><br>采样方式也要做出相应的变化，我们对于不同的噪声强度 <span class="math inline">\(L, L-1, \cdots, 1\)</span>做Langevin采样，<strong>上一个scale的结果作为这一次的初始化</strong>。这样我们每一次的初始化都能在梯度估计的有效区域。</p><p><img src="/images/Score%20Based%20Models/18.png"><br>这种采样方式也叫做<strong>Annealed Langevindynamics</strong>，具体训练流程如下：</p><p><img src="/images/Score%20Based%20Models/19.png"></p><h2 id="从离散到连续">从离散到连续</h2><p>当我们做Langevindynamics迭代次数足够多时，我们可以用<strong>随机微分方程(StochasticDifferential Equation, SDE)</strong>来建模这个采样过程。</p><p><span class="math display">\[\mathbf{x}_{i+1} = \mathbf{x}_{i} +\epsilon \nabla_{\mathbf{x}}\log p(\mathbf{x}_i) + \sqrt{2\epsilon}\mathbf{z}_{i}, \quad i=0,1,\cdots K\]</span></p><p>当 <span class="math inline">\(K\to\infty\)</span> 时，我们定义 <span class="math inline">\(\Delta t = \epsilon,\; \Delta t \to 0\)</span></p><p><span class="math display">\[\mathbf{x}_{t+\Delta t} -\mathbf{x}_{t}= \nabla_{\mathbf{x}}\log p(\mathbf{x}_i)\Delta t +\sqrt{2 \Delta t}\mathbf{z}_{i}\]</span></p><p>我们将 <span class="math inline">\(\nabla _{\mathbf{x}}\logp(\mathbf{x}_i)\)</span> 和 <span class="math inline">\(\sqrt{2}\)</span> 一般化为 <span class="math inline">\(\mathbf{f}(\mathbf{x}, t)\)</span> 和 <span class="math inline">\(g(t)\)</span> ，这样上面就变成了</p><p><span class="math display">\[\mathbf{x} _{t+\Delta t} -\mathbf{x}_{t}= \mathbf{f}(\mathbf{x}, t)\Delta t + g(t) \sqrt{\Deltat}\mathbf{z} _{i}\]</span></p><p>其中</p><p><span class="math display">\[\sqrt{\Delta t}\mathbf{z} _{i} \sim\mathcal{N}(\mathbf{0}, \Delta t\mathbf{I})\]</span></p><p>这里可以引入布朗运动，如果我们定义 <span class="math inline">\(\mathbf{w}\)</span> 是一个布朗运动，那么</p><p><span class="math display">\[\begin{gather*}\mathbf{w}_{t+\Delta t} = \mathbf{w}_{t} +\mathcal{N}(\mathbf{0}, \Delta t\mathbf{I}),\\   \sqrt{\Deltat}\mathbf{z} _{i} = \mathbf{w}_{t+\Delta t} -\mathbf{w}_{t}.\end{gather*}\]</span></p><p>讲布朗运动带入到上面，得到</p><p><span class="math display">\[\mathbf{x}_{t+\Delta t} -\mathbf{x}_{t}= \mathbf{f}(\mathbf{x}, t)\Delta t +g(t)(\mathbf{w}_{t+\Delta t} - \mathbf{w}_{t})\]</span></p><p>当 <span class="math inline">\(\Delta t \to 0\)</span> ,</p><p><span class="math display">\[\text{d}\mathbf{x}=\mathbf{f}(\mathbf{x}, t)\text{d}\mathbf{t} +g(t)\text{d}\mathbf{w}\]</span></p><p>这里 <span class="math inline">\(\mathbf{f}(\mathbf{x}, t)\)</span>叫做<strong>drift coefficient</strong>, <span class="math inline">\(g(t)\)</span> 代表<strong>diffusioncoefficient</strong>。SDE的解也就代表了数据不断加噪声的过程。</p><p><img src="/images/Score%20Based%20Models/20.png"><br>有了正向过程的SDE，我们可以得到</p><ul><li>反向的SDE</li></ul><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - g^2(t)\nabla _{\mathbf{x}}\logp(\mathbf{x})]\text{d}\mathbf{t} + g(t)\text{d}\mathbf{w}\]</span></p><ul><li>以及score matching的损失函数</li></ul><p><span class="math display">\[\mathbb{E}_{t\in \mathcal{U}(0, T)}\mathbb{E}_{p_{t}(\mathbf{x})}[g^2(t)||\nabla_{\mathbf{x}}\logp_t(\mathbf{x}) - \mathbf{s}_{\theta}(\mathbf{x})||^2]\]</span></p><p>可以看到，当我们知道了score后，就能解这个反向的SDE了。</p><p><img src="/images/Score%20Based%20Models/21.png"><br>整个基于SDE框架就是：我们在正向过程在图像中加噪声训练神经网络做scorematching，估计出scorefunction。然后在反向过程中从高斯噪声通过逆向SDE过程生成出数据分布的样本。</p><p><img src="/images/Score%20Based%20Models/22.png"></p><h2 id="从sde到ode">从SDE到ODE</h2><p>对于一个SDE，</p><p><span class="math display">\[\text{d}\mathbf{x}=\mathbf{f}(\mathbf{x}, t)\text{d}\mathbf{t} +g(t)\text{d}\mathbf{w}\]</span></p><p>我们写出它的<strong>福克-普朗克方程（Fokker-Planckequation）</strong>：</p><p><span class="math display">\[\begin{align*} \nabla _{t}p(\mathbf{x}, t) &amp;= -\nabla_{\mathbf{x}}[\mathbf{f}(\mathbf{x}, t)p(\mathbf{x}, t)] +\frac{1}{2}g^{2}(t)\nabla _{\mathbf{x}}^{2}p(\mathbf{x}, t)\\ &amp;=-\nabla _{\mathbf{x}}[\mathbf{f}(\mathbf{x}, t)p(\mathbf{x}, t) -\frac{1}{2}(g^{2}(t) - \sigma^{2}(t))\nabla_\mathbf{x}p(\mathbf{x}, t)]+ \frac{1}{2}\sigma^{2}(t)\nabla _{\mathbf{x}}^{2}p(\mathbf{x},t)\\   &amp;= -\nabla _{\mathbf{x}}[(\mathbf{f}(\mathbf{x}, t) -\frac{1}{2}(g^{2}(t) - \sigma^{2}(t))\nabla_\mathbf{x}\log p(\mathbf{x},t))p(\mathbf{x})] + \frac{1}{2}\sigma^{2}(t)\nabla_{\mathbf{x}}^{2}p(\mathbf{x}, t)\\\end{align*}\]</span></p><p>现在我们把福克-普朗克方程变成了这样：</p><p><span class="math display">\[\nabla_{t}p(\mathbf{x}, t) =-\nabla_{\mathbf{x}}[(\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}(g^{2}(t) -\sigma^{2}(t))\nabla_\mathbf{x}\log p(\mathbf{x}, t))p(\mathbf{x})] +\frac{1}{2}\sigma^{2}(t)\nabla _{\mathbf{x}}^{2}p(\mathbf{x}, t)\]</span></p><p>其对应的SDE为：</p><p><span class="math display">\[\text{d}\mathbf{x}= [\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}(g^{2}(t) -\sigma^{2}(t))\nabla_{\mathbf{x}}\logp_{t}(\mathbf{x})]\text{d}\mathbf{t} + \sigma(t)\text{d}\mathbf{w}\]</span></p><p>因为前后两个SDE是等价的，他们对应的 <span class="math inline">\(p_{t}(\mathbf{x})\)</span>是一样的，意味着我们可以改变第二个SDE的方差 <span class="math inline">\(\sigma(t)\)</span> 。当我们取 <span class="math inline">\(\sigma(t)=0\)</span>，可以得到一个<strong>常微分方程(Ordinary Differential Equation,ODE)</strong>,</p><p><span class="math display">\[\text{d}\mathbf{x}=[\mathbf{f}(\mathbf{x}, t) - \frac{1}{2}g^{2}(t)\nabla_{\mathbf{x}}\logp_{t}(\mathbf{x})]\text{d}\mathbf{t}\]</span></p><p>下图就展示了SDE和ODE解的过程，可以看到ODE的轨迹是确定光滑的，而SDE的轨迹是随机的。这两个过程中的任意边缘分布<span class="math inline">\({p_{t}(\mathbf{x})}_{t\in[0, T]}\)</span>都是一样的。</p><p><img src="/images/Score%20Based%20Models/23.png"><br>ODE形式有它的优点在于：</p><ul><li>因为ODE比SDE好解，所以ODE的采样速度更快。</li><li>因为ODE是不带随机噪声的，整个过程是确定的，是可逆的，所以这个<strong>ODE也可以看做Normalizingflows</strong>，可以用来估计概率密度和似然。</li></ul><p>但同时由于没有了随机噪声，可能导致多样性更差，实践中生成效果也不如SDE。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford
CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h1 id=&quot;引入&quot;&gt;引入&lt;/h1&gt;
&lt;h2 id=&quot;score-function&quot;&gt;Score function&lt;/h2&gt;
&lt;p&gt;上一次我们学习了Ener</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Energy Based Models</title>
    <link href="https://jia040223.github.io/2024/09/20/Energy%20Based%20Models/"/>
    <id>https://jia040223.github.io/2024/09/20/Energy%20Based%20Models/</id>
    <published>2024-09-20T11:46:30.000Z</published>
    <updated>2024-09-25T11:18:58.626Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习StanfordCS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h2 id="引入">引入</h2><p>生成模型的核心目标是对目标样本的概率分布进行预测。而对于一个概率密度函数<span class="math inline">\(P(x)\)</span>，它只需要满足下面两个条件：</p><ul><li><strong>非负</strong>， <span class="math inline">\(P(x)\)</span>在任何一个点都不能小于0，这很显然。</li><li><strong>积分为1</strong>， <span class="math inline">\(P(x)\)</span>从负无穷积分到正无穷得是1。</li></ul><p>其中对于第二点，如果 <span class="math inline">\(P(x)\)</span>的不是1，是 <span class="math inline">\(Z\)</span>，我们进行一下<strong>归一化</strong>，除一下 <span class="math inline">\(Z\)</span>就是1啦。反正至少得是有限的。那么如果我们有一个函数 <span class="math inline">\(f(x)\)</span>，我们只需要对其进行变换，满足上面两个特点，便能将其转化为一个概率密度函数。</p><p>首先可以让 <span class="math inline">\(f(x)\)</span>变为<strong>非负</strong>的 <span class="math inline">\(g(x)\)</span>，比如</p><ul><li><span class="math inline">\(g(x) = f(x)^2\)</span></li><li><span class="math inline">\(g(x) = e^{f(x)}\)</span></li><li><span class="math inline">\(g(x) = log(1 + f(x)^2)\)</span></li><li>......</li></ul><p><img src="/images/Energy%20Based%20Models/1.png"></p><p>可以看到这样的选择有很多，然后接下来便是<strong>归一化</strong>了，只需要</p><p><span class="math display">\[P(x) = \frac{g(x)}{\int g(x)dx} =\frac{g(x)}{Z}\]</span></p><p><img src="/images/Energy%20Based%20Models/2.png"></p><p>那么所谓的<strong>Energy Based Model</strong>呢，其实很简单，我们就是假设这个函数 <span class="math inline">\(g(x) =e^{f(x)}\)</span> 。</p><p>这个时候，下面那个体积volume呢，也叫做<strong>partitionfunction</strong>。</p><p>为啥要 <span class="math inline">\(exp()\)</span>呢？因为希望在算概率的时候取log，和这个 $ e x p ( ) $很多时候能够抵消。而且也和统计物理（虽然笔者并没有研究过统计物理）也有一些联系，这也是energy名字的最初由来。</p><h2 id="基本定义">基本定义</h2><p>对数据的概率分布进行描述时，这些概率分布都可以写成基于能量函数的形式(energyfunciton)， <span class="math inline">\(f(\mathbf x )\)</span>。对于连续变量，每个数据点对应一个概率密度函数值，对应一个能量值，如此概率分布即可写成如下玻尔兹曼分布的形式，也叫作吉布斯分布(Boltzmann/Gibbsdistribution)：</p><ul><li><span class="math inline">\(p(\mathbf x )=\frac{e^{f(\mathbfx)}}{Z}\)</span></li><li><span class="math inline">\(Z\)</span>为概率归一化的分母，也称为<strong>配分函数(partitionfunction)</strong>， <span class="math inline">\(Z=\int e^{f(\mathbf x)}dx\)</span></li></ul><p>由以上公式可知，概率值较高的位置对应着能力较低的点。举一个简单的例子看一下，将高斯分布以能量函数的形式表示：</p><p><span class="math display">\[f(x;\mu,\sigma^2)=-\frac{1}{2\sigma^2}(x-\mu)^2\]</span></p><p><span class="math display">\[p(x)=\frac{e^{f(\mathbf x)}}{\inte^{f(\mathbf x)}dx}=\frac{e^{-\frac{1}{2\sigma^2}(x-\mu)^2}}{\sqrt {2\pi\sigma^2}}\]</span></p><h2 id="部分应用">部分应用</h2><h3 id="分类任务">分类任务</h3><p>一般来说，这个partitionfuntion是不能算的，除非是限制为一些可以积分的函数，得到闭式解，但那样表达力又太弱了。而在实际中，我们的<span class="math inline">\(f(x)\)</span>一般是用神经网络进行模拟的，所以很难求出这个积分（你也可以遍历所有的情况，但这对于训练或者推理都是无法接受的）。</p><p>有时候呢，除非是要算出具体的概率，我们不需要管这个partitionfunction，反正就是知道它是个常数。</p><p>比如我们想知道 <span class="math inline">\(p(a)\)</span> 和 <span class="math inline">\(p(b)\)</span>哪个概率大，就不用去知道绝对的值，只需要知道<strong>相对大小</strong>就可以啦。这就可以用在分类任务里了。</p><p><img src="/images/Energy%20Based%20Models/3.png"></p><p>比如对于图像识别的任务，我只需要知道一个物体是更有可能像猫还是更有可能像狗，而不一定要知道他们的具体概率。</p><p><img src="/images/Energy%20Based%20Models/4.png"></p><p>课程中还列举了一个Ising model 的例子，也很直观，不赘述了：</p><p><img src="/images/Energy%20Based%20Models/5.png"></p><h3 id="组合专家系统">组合专家系统</h3><p>通过EBMs，可以把多个<strong>专家模型</strong>混合起来，用乘法。在对模型采样的时候，就会具有多个生成模型的所有性质，比如又是女人又是年轻又是美貌，就不会生成一个年迈的男人。</p><p><img src="/images/Energy%20Based%20Models/6.png"></p><p><strong>受限玻尔兹曼机</strong>也是基于能量模型，能量形式如下:<br><span class="math display">\[f(\mathbf x;\theta)=exp(\mathbf x^T\mathbf{Wx}+\mathbf{b}^T\mathbf{x} +\mathbf{c}^T\mathbf{z})\]</span></p><p>其它就不赘述了。</p><p><img src="/images/Energy%20Based%20Models/7.png"></p><h2 id="训练">训练</h2><h3 id="损失函数训练目标">损失函数（训练目标）</h3><p>那么如何优化这个模型，直接想法肯定是<strong>极大似然估计</strong></p><p><span class="math display">\[L = \ log(\frac{exp({f_\theta(x_{train})})}{Z(\theta)}) = f_\theta(x_{train}) -log(Z(\theta))\]</span></p><p>这里有个小问题，直接最大化分子并不能解决问题，因为分母是分子的积分，如果只顾着最大化分子的话，可能分母也跟着变大，那最后这整个分数就可能不变甚至变小！但是积分我们又计算不出来怎么办？蒙特卡洛估计便可以派上用场了，我们对<span class="math inline">\(L\)</span> 求一下梯度：</p><p><span class="math display">\[\begin{align*}\nabla_{\theta} f_{\theta}(x_{\text{train}}) - \nabla_{\theta} \logZ(\theta) &amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) -\frac{\nabla_{\theta} Z(\theta)}{Z(\theta)} \\&amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) -\frac{1}{Z(\theta)} \int \nabla_{\theta} \exp \{ f_{\theta}(x) \} dx \\&amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) -\frac{1}{Z(\theta)} \int \exp \{ f_{\theta}(x) \} \nabla_{\theta}f_{\theta}(x) dx \\&amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) - \int \frac{\exp \{f_{\theta}(x) \}}{Z(\theta)} \nabla_{\theta} f_{\theta}(x) dx \\&amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) -\mathbb{E}_{x_{\text{sample}}} [\nabla_{\theta}f_{\theta}(x_{\text{sample}})] \\&amp;= \nabla_{\theta} f_{\theta}(x_{\text{train}}) - \nabla_{\theta}f_{\theta}(x_{\text{sample}})\end{align*}\]</span></p><p>其中 <span class="math inline">\(x_{sample} \simexp(f_\theta(x_{sample}))/Z_\theta\)</span></p><p>最后一步代表在训练过程中，我们只取一个样本作为期望的估计值。</p><p><img src="/images/Energy%20Based%20Models/8.png"></p><p>其实主观上也很好理解，其实就是对比了训练集和从模型中的采样，让训练集中数据的概率比随便采样出来的概率大。</p><p>我们对上面公式取个负，就是损失函数了。</p><h3 id="如何采样">如何采样</h3><p>那么问题来了，我们怎么从这个能量模型中采样呢？你看看上面能量模型的式子，你只知道x比y概率大还是概率小，但你不知道x或者y的准确概率。</p><p>这时候，MCMC<strong>马尔科夫链蒙特卡罗</strong>就出场啦。</p><p><img src="/images/Energy%20Based%20Models/9.png"></p><p>这是课程对于<strong>MCMC</strong>的叙述，没明白的可以复习一下，其实就是<strong>MH算法</strong>：</p><p><img src="/images/Energy%20Based%20Models/10.png"></p><p>课程中没强调这个noise是对称的，就是 <span class="math inline">\(x\)</span> 到 <span class="math inline">\(x&#39;\)</span> 的概率等于 <span class="math inline">\(x&#39;\)</span> 到 <span class="math inline">\(x\)</span> 的概率。这时候上图中的关于 <span class="math inline">\(q\)</span> 的分数就等于一了。那就是说，如果 <span class="math inline">\(f(x’)\)</span>的值大于当前值，那就无脑接受就好啦（2.1步）。如果没有大于，那就算一下比例咯（2.2步）。所以课程中的这个算法就是MH算法。</p><p>MH算法很美妙，但太慢啦。那怎么办呢？我们可以用<strong>郎之万Langevin动力学</strong>来帮助MH算法，让随机游走朝着概率更高的地方走。 这就是Metropolis-adjusted Langevin algorithm。</p><p><img src="/images/Energy%20Based%20Models/11.png"></p><p>最后总结一下，先用MH算法抽样，用这些抽样放到contrasive divergence算法里训练能量模型的参数，来极大似然</p><h2 id="score-matching">Score Matching</h2><p>上面我们用MH算法给出了一个训练和推理的方法，但缺点很明显，就是收敛的太慢了，随着维度的增加，收敛速度指数级别下降。虽然用了郎之万Langevin动力学来进行提速，但每次梯度一更新之后，分布就变了。所以对于contrasivedivergence的每一步来说，MCMC都要从头开始采样直到收敛。（MCMC采样不是一开始就能用的，要丢弃前n个样本，叫做burnin）</p><p>拿能否训练时候不用sampling呢？</p><h3 id="score-function">score function</h3><p>先看一下什么叫score function</p><p><img src="/images/Energy%20Based%20Models/12.png"></p><p>就是指向高概率方向的梯度。一个观察是，这个梯度和分母，就是partitionfunction无关。至于为什么叫做score fuction，那是因为我们一般把<strong><span class="math inline">\(f_\theta(x)\)</span></strong>对输入x的梯度称为<strong>score。</strong></p><h3 id="score-matching-1">score matching</h3><p>在之前的MCMC采样方法训练中，当我们有了一个准确的能量模型后，我们从数据分布里采样就转换成了根据训练好的能量模型的score,来进行MCMC采样。那么为什么不能换个思路，直接将能量模型建模成score，即用一个神经网络来拟合score!这个方法就叫score-matching!</p><p><img src="/images/Energy%20Based%20Models/13.png"></p><p>如上所示，我们的目标依旧是用score matching来减小这两个分布的区别。难点在于，对于真实分布Pdata怎么求导呢？先看看一维的情况：</p><p><span class="math display">\[\begin{align*}\frac{1}{2} \mathbb{E}_{x \sim p_{\text{data}}} \left[ (\nabla_x \logp_{\text{data}}(x) - \nabla_x \log p_{\theta}(x))^2 \right]  &amp;=\frac{1}{2} \int p_{\text{data}}(x) \left[ (\nabla_x \logp_{\text{data}}(x) - \nabla_x \log p_{\theta}(x))^2 \right] dx &amp;\\&amp;= \frac{1}{2} \int p_{\text{data}}(x) (\nabla_x \logp_{\text{data}}(x))^2 dx + \frac{1}{2} \int p_{\text{data}}(x) (\nabla_x\log p_{\theta}(x))^2 dx - \int p_{\text{data}}(x) \nabla_x \logp_{\text{data}}(x) \nabla_x \log p_{\theta}(x) dx &amp;\end{align*}\]</span></p><p>其中第一项是常数，我们不用管，第二项也只涉及到 <span class="math inline">\(p_\theta\)</span> (积分的 <span class="math inline">\(p_{data}\)</span>直接通过在训练集抽样即可)，第三项比较棘手，涉及到 <span class="math inline">\(\nabla_x \log p_{\text{data}}(x)\)</span>，这个我们没法直接求出。</p><p>但是我们可以通过分布积分来进行化简：</p><p><span class="math display">\[\begin{align*}-\int p_{\text{data}}(x) \nabla_x \log p_{\text{data}}(x) \nabla_x \logp_{\theta}(x) dx &amp;= - \int p_{\text{data}}(x)\frac{1}{p_{\text{data}}(x)} \nabla_x p_{\text{data}}(x) \nabla_x \logp_{\theta}(x) dx \\ &amp;= - p_{\text{data}}(x) \nabla_x \logp_{\theta}(x) \Big|_{x = -\infty}^{x = \infty} + \int p_{\text{data}}(x)\nabla_x^2 \log p_{\theta}(x) dx \\ &amp;= \int p_{\text{data}}(x)\nabla_x^2 \log p_{\theta}(x) dx\end{align*}\]</span></p><p>其中我们认为 <span class="math inline">\(p_{\text{data}}(x) \nabla_x\log p_{\theta}(x) \Big|_{x = -\infty}^{x = \infty}  = 0\)</span>，因为我们假定无穷远处的 <span class="math inline">\(p_{data}\)</span>为0。</p><p><img src="/images/Energy%20Based%20Models/14.png"></p><p>对于多维与一维类似，区别就是我们分部积分得到的结果是 <span class="math inline">\(log(p_\theta(x))\)</span>的<strong>Hessian</strong>的迹，最终我们得到的形式如下：</p><p><img src="/images/Energy%20Based%20Models/15.png"></p><p>我们通过分部积分把对 <span class="math inline">\(P_{data}\)</span>的梯度项给搞没了，就不用像之前那样费劲的去MCMC了。不过缺点是这个Hessian矩阵算起来很麻烦。</p><h2 id="noise-contrastive-estimation">Noise contrastive estimation</h2><p>把NCE用在Energy BasedModel其实思想也很简单，我们在GANs中提到，对于一个真实样本和模型样本进行分类的最佳判别器是，对给定<span class="math inline">\(x\)</span> 的判定为真实样本的概率为<span class="math inline">\(\frac{P_{data}(x)}{P_{data}(x) +P_n(x)}\)</span>。</p><p>所以NCE的想法就是我去用生成器组成一个判别器，这个生成器输出概率为<span class="math inline">\(P_{\theta^*}(x)\)</span>，而判别器的输出则是 <span class="math inline">\(\frac{P_{\theta^*}(x)}{P_{\theta^*}(x) +P_n(x)}\)</span> ，这样当判别器训练成为最佳判别器时， <span class="math inline">\(P_{\theta^*}(x)\)</span> 就等于 $P_{data}(x) $。</p><p>注意，这里的 <span class="math inline">\(P_n\)</span>的概率是我们给定一个特定噪声分布进行采样的概率，所以很好获得。也就是说在NCE中，非真实样本的概率分布是事先指定的，而不是模型学习得到的。</p><p>但是，依旧会到那个问题， <span class="math inline">\(P_{\theta^*}(x)= \frac{exp(f_{\theta^*}(x))}{Z_{\theta*}}\)</span>，我的分母怎么处理呢？此时我们可以把 <span class="math inline">\(Z\)</span>也作为一个参数进行训练。假如我们能够得到最佳判别器，由于 <span class="math inline">\(\frac{exp(f_{\theta^*}(x))}{Z^{*}} =P_{data}\)</span> ，所以 <span class="math inline">\(Z\)</span>也就肯定是最佳的分区函数了。</p><p><img src="/images/Energy%20Based%20Models/16.png"></p><p>把这个形式带入我们二分类的目标函数（与GANs相同，这里不赘述了）：</p><p><img src="/images/Energy%20Based%20Models/17.png"></p><p>当然，对于这个 <span class="math inline">\(p_n\)</span>，它对于训练效果有很显著的影响，毕竟区分图片和一堆噪声可不用很强的判别能力。所以后面也有对这个的改进工作，具体也就是类似GANs一样，再加一个生成器：</p><p><img src="/images/Energy%20Based%20Models/18.png"></p><p>当时，这样就会训练得到两个生成模型了，具体推理阶段都可以使用。</p><p>注意，能量模型作为生成模型的一种，建模的是 <span class="math inline">\(P(x)\)</span> ,主要功能是从 <span class="math inline">\(P(x)\)</span> 里面采样。上面说的scorematching是在训练的时候不用从中采样，加快训练的脚步，但是真正使用的时候还是得有MCMC。NCE因为显式的训练了partitionfunction <span class="math inline">\(Z\)</span>，也许可以不用MCMC（但笔者感觉也没有比较好的直接采样方法，个人觉得还是需要靠MCMC，如果读者有好的想法也可以指正我）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford
CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h2 id=&quot;引入&quot;&gt;引入&lt;/h2&gt;
&lt;p&gt;生成模型的核心目标是对目标样本的概率分布进行预测。而对于一个概率密度函数
&lt;span class=&quot;math i</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>蒙特卡洛采样方法</title>
    <link href="https://jia040223.github.io/2024/09/19/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95/"/>
    <id>https://jia040223.github.io/2024/09/19/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95/</id>
    <published>2024-09-19T12:04:35.000Z</published>
    <updated>2024-09-20T13:29:20.636Z</updated>
    
    <content type="html"><![CDATA[<p>最近在学习StanfordCS236课程，里面多次提到了蒙特卡洛采样，但本人之前并没有系统地对蒙特卡洛采样进行过整理学习，所以也就正好趁此机会学习一下蒙特卡洛采样，分享记录，也便于自己实时查看。</p><h1 id="蒙特卡洛估计">蒙特卡洛估计</h1><h2 id="蒙特卡洛估计的原理">蒙特卡洛估计的原理</h2><p><strong>蒙特卡洛估计(Monte CarloEstimator)</strong>的原理很简单，假设现在我们要求解一个一维的积分 <span class="math inline">\(\int_{a}^{b} g(x) dx\)</span> 。已知一个概率密度为<span class="math inline">\(f(x)\)</span> 的随机变量 $ X$，蒙特卡洛估计可以表示为：</p><p><span class="math display">\[G_N =\frac{1}{N}\sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}}\\\]</span></p><p>概率密度 <span class="math inline">\(f(x)\)</span> 需要满足</p><p><span class="math display">\[ \begin{cases}  f(x) &gt; 0, x \in (a,b),\\   f(x) = 0, x \notin (a, b).\end{cases}\\\]</span></p><p>现在来验证下, 这种方式是正确的：</p><p><span class="math display">\[\begin{align*} E[G_N] &amp; =E\left [\frac{1}{N}\sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}} \right]\\ &amp; =\frac{1}{N}\sum_{i=1}^{N}\int_{a}^{b}\frac{g(x)}{f(x)}f(x)dx\\ &amp;=\frac{1}{N}\sum_{i=1}^{N}\int_{a}^{b}g(x)dx\\ &amp;= \int_{a}^{b}g(x)dx\end{align*}\\\]</span></p><p>也就是说， <span class="math inline">\(G_N\)</span> 的期望与 <span class="math inline">\(\int_{a}^{b} g(x) dx\)</span> 是相同的，而 <span class="math inline">\(G_N\)</span> 的方差如下：</p><p><span class="math display">\[\begin{align*} D[G_N] &amp; =D\left [\frac{1}{N}\sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}} \right]\\ &amp; =\frac{1}{N^2}D\left [ \sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}} \right]\\&amp;= \frac{1}{N^2}\cdot N  \cdot D\left [ {\frac{g(X_i)}{f(X_i)}}\right]\\ &amp;= \frac{1}{N} D\left [ {\frac{g(X_i)}{f(X_i)}} \right]\end{align*}\\\]</span></p><p>从上面的式子，可以看出，要减少方差，有两种途径：</p><ul><li>增加采样次数 <span class="math inline">\(N\)</span></li><li>减少 <span class="math inline">\(D(\frac{g(X)}{f(X)})\)</span></li></ul><p>理论上，只要我们采样次数足够多，方差趋近于0，<span class="math inline">\(G_N\)</span> 也就依概率收敛于<span class="math inline">\(\int_{a}^{b} g(x) dx\)</span></p><h2 id="蒙特卡洛估计的优点">蒙特卡洛估计的优点</h2><p>我们在考虑一个<strong>积分算法/Estimator</strong>时，通常从两个角度考虑。</p><p>一个是计算的准确性，即随着采样次数增大时，结果是否趋近于我们期望的真实值。如果一个estimator的期望值和真实值相等，我们说它是<strong>无偏的/unbiased</strong>。如果一个estimator 的期望值和真实值不相等，则它是有偏的。大部分 estimator都是无偏的，在少数情况下，我们会使用一个有偏的但是计算收敛速度很快的estimator。</p><p>另外一个角度是计算结果的方差。随着采样次数增大时，计算结果的方差应该总是减少的。两个estimator的方差可以比较可以从两个角度来体现。即采样次数相同时的方差大小，以及随着采样次数增大，方差收敛的速度。我们总是期望使用一个方差较小且收敛较快的estimator，来减少计算的事件。</p><p>计算结果表明，蒙特卡洛估计误差收敛的速度为 <span class="math inline">\(O(\sqrt N)\)</span>(意味着4倍的采样会使误差减少一半)，蒙特卡洛估计不受维度影响，在高维情况下比其他估计方法收敛要快得多。</p><h1 id="蒙特卡洛估计的实践使用">蒙特卡洛估计的实践使用</h1><p>在实际使用中，直接使用蒙特卡洛方法要求我们能够从 $p(x) $中采样——对于简单分布（如均匀分布）这是容易做到的；对于稍微复杂一些但可写出PDF 或 CDF分布，可以利用变量替换定理来直接采样；而对于更复杂的分布，我们则更多选择拒绝采样和重要性采样来实现这一点。。</p><h2 id="变量替换定理">变量替换定理</h2><p>$ X$服从一个我们能直接进行采样的连续值（例如均匀分布），我们希望找到一个函数<span class="math inline">\(f(x)\)</span> ，让 <span class="math inline">\(Y=f(X)\)</span> 满足我们需要得到的分布 <span class="math inline">\(Y \sim P_y\)</span> ，则使用累积分布函数：</p><p><span class="math display">\[P_y(y)\triangleq P(Y\le y)=P(f(X)\ley)=P(X\in(f(x)\le y))\]</span></p><p>概率密度函数可以通过累积分布函数求导得到。当单调，因此可逆时，可得：</p><p><span class="math display">\[P_y(y)=P(f(X)\le y)=P(X\lef^{-1}(y))=P_x(f^{-1}(y))\]</span></p><p>求导可得：</p><p><span class="math display">\[p_y(y)\triangleq\frac{d}{dy}P_y(y)=\frac{d}{dy}P_x(f^{-1}(y))=\frac{dx}{dy}\frac{d}{dx}P_x(x)=\frac{dx}{dy}p_x(x)\]</span></p><p>其中 <span class="math inline">\(x=f^{-1}(y)\)</span>。由于符号并不重要，因此可得一般表达式：</p><p><span class="math display">\[p_y(y)=p_x(x)|\frac{dx}{dy}|\]</span></p><p>可将上述结果拓展为多变量分布。令 <span class="math inline">\(f\)</span> 为 <span class="math inline">\(R^n\)</span> 到 <span class="math inline">\(R^n\)</span> 的映射， <span class="math inline">\(\mathrm y=f(\mathrm x)\)</span> 。则雅可比矩阵<span class="math inline">\(J\)</span> 为：</p><p><span class="math display">\[J_{\mathrm x\rightarrow\mathrmy}\triangleq\frac{\partial(y_1,\ldots,y_n)}{\partial(x_1,\ldots,x_n)}\triangleq\begin{pmatrix} \frac{\partial y_1}{\partial x_1}&amp;\dots&amp;\frac{\partial y_1}{\partial x_n}\\\vdots&amp;\ddots&amp;\vdots\\ \frac{\partial y_n}{\partialx_1}&amp;\dots&amp;\frac{\partial y_n}{\partial x_n}\end{pmatrix}\]</span></p><p><span class="math inline">\(|det J|\)</span> 度量了单位立方体在应用<span class="math inline">\(f\)</span> 时的体积变化量。如果 <span class="math inline">\(f\)</span> 是一个可逆映射，可以使用反映射 <span class="math inline">\(\mathrm y\rightarrow\mathrm x\)</span>的雅可比矩阵定义变换变量的概率密度函数：</p><p><span class="math display">\[p_y(\mathrm y)=p_x(\mathrmx)|\det\left(\frac{\partial \mathrm x}{\partial\mathrmy}\right)|=p_x(\mathrm x)| \det J_{\mathrm y\rightarrow\mathrmx}|\]</span></p><p>这就是随机变量的变量替换定理，通过这个我们可以对一些相对简单的分布进行直接采样了。</p><p>例如设 <span class="math inline">\(x\)</span> 服从累积分布函数为<span class="math inline">\(F(x)=1-e^{-x}\)</span>(可验证是单调不减，且积分为1的函数)的分布，则可以通过逆变换的方法对<span class="math inline">\(F(x)\)</span>直接采样，<strong>产生服从F(X)分布的样本X。</strong><br>令 <span class="math inline">\(y=1-e^{-x}\)</span>，则$ e^{-x}=1-y $.两边求对数可得: <span class="math inline">\(x=-ln(1-y)\)</span> ,则<span class="math inline">\(F^{-1}(x)=-ln(1-x)\)</span> ，令 <span class="math inline">\(x_i\)</span> 为均匀分布样本，则 <span class="math inline">\(X_i=-ln(1-x_i)\)</span> 为服从累积分布函数为 $F(x)$ 分布的样本.</p><h2 id="拒绝接受采样">拒绝接受采样</h2><p>拒绝接受采样的目的仍然是<strong>得到服从某个概率分布的样本</strong>，不过这种方法是直接利用<strong>概率密度函数(PDF)</strong>得到样本。如下图所示，<span class="math inline">\(p(x)\)</span> 是我们希望采样的分布， <span class="math inline">\(q(x)\)</span>是我们<strong>提议的分布</strong>(proposal distribution)， <span class="math inline">\(q(x)\)</span> 分布比较简单，令 <span class="math inline">\(kq(x)&gt;p(x)\)</span> ，我们首先在 <span class="math inline">\(kq(x)\)</span>中按照直接采样的方法采样粒子，接下来以 <span class="math inline">\(\frac{p(x_i)}{kq(x_i)}\)</span>的概率接受这个点，最终得到符合 <span class="math inline">\(p(x)\)</span>的N个粒子。</p><p><img src="/images/蒙特卡洛采样方法/1.png"><br>可以证明，这样做得到的样本是服从<span class="math inline">\(p(x)\)</span>的，我们可以计算 <span class="math inline">\(x_0\)</span> 对应的样本被取到的概率为：</p><p><span class="math display">\[\frac{q(x_0)\dfrac{\tildep(x_0)}{kq(x_0)}}{\displaystyle\int_x q(x)\frac{\tildep(x)}{kq(x)}\mathrm dx}=\frac{\tilde p(x_0)}{\displaystyle\int_x \tildep(x)\mathrm dx}=p(x_0)\]</span></p><p>所以<strong>拒绝接受采样的基本步骤：</strong></p><ol type="1"><li>生成服从 <span class="math inline">\(q(x)\)</span> 的样本 <span class="math inline">\(x_i\)</span> .<br></li><li>生成服从均匀分布 <span class="math inline">\(U(0,1)\)</span> 的样本<span class="math inline">\(u_i\)</span> .<br></li><li>当 <span class="math inline">\(k\cdot q(x_i)\cdotu_i&lt;p(x_i)\)</span> ,也就是二维点落在蓝线以下，此时接受 <span class="math inline">\(X_k=x_i\)</span><br>这里乘以 <span class="math inline">\(u_i\)</span> ，是因为我们需要以<span class="math inline">\(\frac{p(x_i)}{kq(x_i)}\)</span>的概率接受这个点，因为如果 <span class="math inline">\(k\cdotq(x_i)\cdot u_i&lt;p(x_i)\)</span> ，则 <span class="math inline">\(u_i&lt;\frac{p(x_i)}{k\cdot q(x_i)}\)</span> ，而<span class="math inline">\(u_i\)</span> 服从均匀分布 <span class="math inline">\(U(0,1)\)</span><br></li><li>最终得到的 <span class="math inline">\(X_k\)</span> 为服从 <span class="math inline">\(p(x)\)</span> 的样本.</li></ol><p>我们可以计算一下样本采样的<strong>接受率</strong>：</p><p><span class="math display">\[p(\text{accept})=\int_x \frac{\tildep(x)}{kq(x)}q(x)\mathrm dx=\frac{1}{k}\int_x\tilde p(x)\mathrmdx\]</span></p><p>因此 <span class="math inline">\(k\)</span>越小，总接受率越大，算法效率越高。然而， <span class="math inline">\(k\)</span> 小也意味着 <span class="math inline">\(q(x)\)</span> 本身就要与 <span class="math inline">\(p(x)\)</span> 比较相似，对于复杂的 <span class="math inline">\(p(x)\)</span> 而言寻找到一个合适的 <span class="math inline">\(q(x)\)</span> 非常困难的。</p><h2 id="重要性采样">重要性采样</h2><p>重要性采样的目的：求一个函数 <span class="math inline">\(f(x)\)</span> 在概率密度函数为 $ p(x)$分布下的<strong>期望</strong>，即</p><p><span class="math display">\[\mathbb{E}[f(x)]=\intf(x)p(x)dx\]</span></p><p>当 <span class="math inline">\(p(x)\)</span>很复杂时，不解析，积分不好求时，可以通过重要性采样来计算。当 <span class="math inline">\(f(x)=x\)</span> ，则可以算 <span class="math inline">\(p(x)\)</span> 的期望。</p><h3 id="原理">原理</h3><p>首先, 当我们想要求一个函数 <span class="math inline">\(f(x)\)</span>在区间 <span class="math inline">\([a, b]\)</span> 上的积分 <span class="math inline">\(\int_{a}^{b} f(x) d x\)</span>时有可能会面临一个问题, 那就是积分曲线难以解析,无法直接求积分。这时候我们可以采用一种估计的方式, 即在区间 <span class="math inline">\([a, b]\)</span> 上进行采样: <span class="math inline">\(\left\{x_{1}, x_{2} \ldots, x_{n}\right\}\)</span>, 值为 <span class="math inline">\(\left\{f\left(x_{1}\right),f\left(x_{2}\right), \ldots, f\left(x_{n}\right)\right\}\)</span></p><p>如果采样是均匀的, 即如下图所示:</p><p><img src="/images/蒙特卡洛采样方法/2.png"></p><p>那么显然可以得到这样的估计: <span class="math inline">\(\int_{a}^{b}f(x) d x=\frac{b-a}{N} \sum_{i=1}^{N} f\left(x_{i}\right)\)</span> ,在这里 <span class="math inline">\(\frac{b-a}{N}\)</span>可以看作是上面小长方形的底部的 “宽”, 而 <span class="math inline">\(f\left(x_{i}\right)\)</span> 则是坚直的 “长”。</p><p>上述的估计方法随着取样数的增长而越发精确，那么有什么方法能够在一定的<strong>抽样数量基础</strong>上来增加准确度，减少方差呢？比如<span class="math inline">\(x\)</span> 样本数量取10000，那么显然在 <span class="math inline">\(f(x)\)</span> 比较大的地方，有更多的 <span class="math inline">\(x_i\)</span> ，近似的积分更精确。</p><p>并且原函数 <span class="math inline">\(f(x)\)</span>也许本身就是定义在一个分布之上的, 我们定义这个分布为 <span class="math inline">\(p(x)\)</span> , 我们无法直接从 $ p(x)$ 上进行采样,所以另辟蹊径重新找到一个更加简明的分布 <span class="math inline">\(q(x)\)</span> , 从它进行取样, 希望间接地求出 <span class="math inline">\(f(x)\)</span> 在分布 <span class="math inline">\(p(x)\)</span> 下的期望。</p><h3 id="若px归一化">若p(x)归一化</h3><p>搞清楚了这一点我们可以继续分析了。首先我们知道函数 <span class="math inline">\(f(x)\)</span> 在概率分布 <span class="math inline">\(p(x)\)</span> 下的期望为:</p><p><span class="math display">\[\mathbb{E}[f(x)]=\int_{x} p(x) f(x) d x\]</span></p><p>但是这个期望的值我们无法直接得到, 因此我们需要借助 <span class="math inline">\(q(x)\)</span> 来进行采样, <span class="math inline">\(q(x)\)</span>可以选取简单的分布，比如<strong>设q(x)为均匀分布</strong>，当我们在<span class="math inline">\(q(x)\)</span> 上采样得到 <span class="math inline">\(\left\{x_{1}, x_{2}, \ldots,x_{n}\right\}\)</span> （即 <span class="math inline">\(x_i\)</span>服从 <span class="math inline">\(q(x)\)</span>分布）后，那么我们可以估计 <span class="math inline">\(f\)</span> 在<span class="math inline">\({q(x)}\)</span> 下的期望为：</p><p><span class="math display">\[\mathbb{E}[f(x)]=\int_{x} q(x) f(x) d x\approx \frac{1}{N} \sum_{i=1}^{N} f\left(x_{i}\right) \]</span></p><p>上面这个式子就简单很多了，只要我们得到 <span class="math inline">\(x_i\)</span> 然后代入 <span class="math inline">\(f(x)\)</span> 然后求和就行了，而且均匀分布的样本<span class="math inline">\(x_i\)</span>很容易获得。接着我们来考虑原问题，对式(1)进行改写, 即： <span class="math inline">\(p(x) f(x)=q(x) \frac{p(x)}{q(x)} f(x)\)</span> ,所以我们可以得到:</p><p><span class="math display">\[\mathbb{E}[f(x)]=\int_{x} q(x)\frac{p(x)}{q(x)} f(x) d x\]</span></p><p>这个式子我们可以看作是函数 <span class="math inline">\(\frac{p(x)}{q(x)} f(x)\)</span> 定义在分布 <span class="math inline">\(q(x)\)</span> 上的期望, 当我们在 <span class="math inline">\(q(x)\)</span> 上采样 <span class="math inline">\(\left\{x_{1}, x_{2}, \ldots,x_{n}\right\}\)</span> (<strong>服从q(x)分布</strong>)，可以估计 <span class="math inline">\(f\)</span> 的期望:</p><p><span class="math display">\[\begin{aligned}\mathbb{E}[f(x)]&amp;=\frac{1}{N}\sum_{i=1}^{N} \frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}f\left(x_{i}\right)\\&amp;=\frac{1}{N} \sum_{i=1}^{N} w_if\left(x_{i}\right)\end{aligned}\]</span></p><p>在这里 <span class="math inline">\(w_i=\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\)</span>就是<strong>重要性权重</strong>。</p><h3 id="若px没有归一化">若p(x)没有归一化</h3><p>上面的讨论是假设 <span class="math inline">\(p(x)\)</span>已经完成归一化了，也就是 <span class="math inline">\(\intp(x)=1\)</span> ,假如 <span class="math inline">\(p(x)\)</span>没有归一化，那么我们可以在上面的推导中对 <span class="math inline">\(p(x)\)</span> 进行归一化：</p><p><span class="math display">\[\begin{aligned}\mathbb{E}[f(x)]&amp;=\int f(x)\frac{p(x)}{\int p(x) d x} d x\\&amp;=\frac{\int f(x) p(x) d x}{\intp(x) d x}\\&amp;=\frac{\int f(x) \frac{p(x)}{q(x)} q(x) d x}{\int\frac{p(x)}{q(x)} q(x) d x}.\end{aligned}\]</span></p><p>而分子分母可分别得到，下面两式约等于都利用 <span class="math inline">\(q(x)\)</span> 是均匀分布的假设：</p><p><span class="math display">\[\begin{aligned}\int f(x)\frac{p(x)}{q(x)} q(x) d x &amp;\approx \frac{1}{n} \sum_{i=1}^{n} W_{i}f\left(x_{i}\right), \\\int \frac{p(x)}{q(x)} q(x) d x &amp;\approx\frac{1}{n} \sum_{i=1}^{n} W_{i}.\end{aligned}\]</span></p><p>其中 <span class="math inline">\(W_i=\frac{p(x_i)}{q(x_i)}\)</span>，则最终可得 <span class="math inline">\(\mathbb{E}[f(x)]\)</span> :</p><p><span class="math display">\[\begin{aligned}\mathbb{E}[f(x)] \approx\sum_{i=1}^{n} w_{i} f\left(x_{i}\right),w_{i}=\frac{W_{i}}{\sum_{i=1}^{n} W_{i}}\end{aligned}\]</span></p><h3 id="多重重要性采样">多重重要性采样</h3><p>有的时候, 需要积分的方程中可能包含多个需要积分的部分,这时候就需要用到<strong>多重重要性采样(multiple importancesampling/MIS)</strong>.</p><p>比如现在要求解 <span class="math inline">\(\int_{}^{}g_1(x)g_2(x)\)</span> 这样的积分时, 两个部分分别对应两个概率密度 <span class="math inline">\(f_1(x), f_2(x)\)</span> ,MIS给出的新的蒙特卡洛估计为:</p><p><span class="math display">\[\frac{1}{n_1}\sum_{i=1}^{n_1}{\frac{g_1(X_1)g_2(X_1)\omega_1(X_1)}{f(X_1)}} +\frac{1}{n_2}\sum_{i=1}^{n_2}{\frac{g_1(X_2)g_2(X_2)\omega_2(X_2)}{f(X_2)}}\\\]</span></p><p><span class="math inline">\(n_1,n_2\)</span> 分别是两边的采样次数,$_1, _2 $ 分别是两个部分对应的权重.</p><p>一个常用的权重函数为:</p><p><span class="math display">\[\omega_k = \frac{(n_kf_k(x))^2}{\sum_{i}^{}{(n_1f_i(x))^2}}\\\]</span></p><p>在上面有两个部分的情况下得:</p><p><span class="math display">\[\omega_1 = \frac{(n_1f_1(x))^2}{(n_1f_1(x))^2 +(n_2f_2(x))^2  }\\ \omega_2 = \frac{(n_2f_2(x))^2}{(n_1f_1(x))^2 +(n_2f_2(x))^2  }\\\]</span><br>与拒绝采样一样，重要性采样的效果与提议分布 $q(x) $ 同 <span class="math inline">\(p(x)\)</span> 的接近程度紧密相关。当 <span class="math inline">\(p(x)\)</span> 比较复杂时，选择合适的 <span class="math inline">\(q(x)\)</span> 是非常困难的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在学习Stanford
CS236课程，里面多次提到了蒙特卡洛采样，但本人之前并没有系统地对蒙特卡洛采样进行过整理学习，所以也就正好趁此机会学习一下蒙特卡洛采样，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h1 id=&quot;蒙特卡洛估计&quot;&gt;蒙特卡洛估计&lt;/h1&gt;
&lt;h2</summary>
      
    
    
    
    <category term="机器学习" scheme="https://jia040223.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://jia040223.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="概率论与数理统计" scheme="https://jia040223.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>GANs</title>
    <link href="https://jia040223.github.io/2024/09/18/GANs/"/>
    <id>https://jia040223.github.io/2024/09/18/GANs/</id>
    <published>2024-09-18T14:10:33.000Z</published>
    <updated>2024-09-20T13:27:19.686Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习StanfordCS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h2 id="引入">引入</h2><p>前面我们学习了VAEs和NormalizingFlows，这两种模型都是基于最小化KL散度（对似然进行评估）来进行优化的。我们也可以看到，为了进行生成，我们往往会定义一个潜变量<span class="math inline">\(z\)</span>，所以对似然进行评估并不容易。VAEs是通过优化似然的下限ELBO来绕过这个问题，而NormalizingFlows是通过限制映射的形式来计算似然。</p><p>直接计算似然来进行评估，要么只能计算其下界，要么需要限制映射的形式。那有没有一种方法能够用间接方法代替这种直接比较，使生成分布变得越来越接近真实分布呢？GANs便是基于一种间接的评估方式进行设计的。</p><h2 id="基本思想">基本思想</h2><p>GANs的间接方法采用这两个分布的下游任务形式。然后，生成网络的训练是相对于该任务进行的，使生成分布变得越来越接近真实分布。GANs的下游任务是区分真实样本和生成样本的任务。或者我们可以说是“非区分”任务，因为我们希望区分尽可能失败。</p><p>因此，在 GANs架构中，我们有一个判别器，它接收真实和生成数据样本，并尽可能地对它们进行分类；还有一个生成器，它被训练成尽可能地欺骗判别器。即GANs由2个重要的部分构成：</p><ul><li>生成器(Generator)：通过机器生成数据，目的是“骗过”判别器。</li><li>判别器(Discriminator)：判断数据是真实的还是生成的，目的是找出生成器做的“假数据”。</li></ul><h2 id="训练过程">训练过程</h2><p>我们知道GANs的思想后，便能很直观的想到用分类问题的交叉熵作为判别器的损失函数。同时生成器的目的则是最大化这个交叉熵损失函数（混淆判别器），所以我们的训练目标是：</p><p><span class="math display">\[\mathop{\text{min}}\limits_{G}\mathop{\text{max}}\limits_{D}\ V(G,D) = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z\sim p_z(z)} [\log(1 - D(G(z)))]  \]</span></p><p>其中 <span class="math inline">\(G\)</span> 指的是生成器， <span class="math inline">\(D\)</span> 指的是判别器。</p><p>所以我们的训练目标是一个极大极小的优化问题，在实际中，我们只需要从数据集中进行采样，然后用生成器进行采样，然后对上面的目标函数进行近似计算，最后进行梯度上升或者梯度下降即可</p><p><img src="/images/GANs/1.png"></p><h2 id="与散度的关系">与散度的关系</h2><p>那么为什么这样的设计能够间接地去让生成器生成的样本与真实样本的分布相同呢？</p><p>其实本质上，GANs通过引入判别器来间接地计算了 <span class="math inline">\(\frac{P_\theta(x)}{P_{data}(x)}\)</span>，可以证明，对于一个生成器下的最佳判别器对给定 <span class="math inline">\(x\)</span> 的判定为真实样本的概率是<span class="math inline">\(\frac{P_{data}(x)}{P_{data}(x) +P_\theta(x)}\)</span>， 证明如下：</p><p><em>*Proof*</em>: 二分类交叉熵损失函数为：</p><p><span class="math display">\[\begin{align} \mathrm{BCE}(\mathcalP_1,\mathcal P_2)&amp;=-\mathbb E_{x\sim \mathcal P_1}[\logD(x)]-\mathbb E_{x\sim \mathcal P_2}[\log(1-D(x))]\\ &amp;=-\int \logD(x)\cdot p_1(x)\mathrm d x-\int\log(1-D(x))\cdot p_2(x)\mathrm d x\\&amp;=-\int \left[\log D(x)\cdot p_1(x)+\log(1-D(x))\cdotp_2(x)\right]\mathrm d x\\ \end{align} \\\]</span></p><p>易知 <span class="math inline">\(y=a\log x+b\log(1-x)\)</span> 在<span class="math inline">\(x=\frac{a}{a+b}\)</span>处取到唯一极大值（其中 <span class="math inline">\(0\leqa,b\leq1\)</span> ），所以欲使上式最小，只需：</p><p><span class="math inline">\(\forallx,\,D(x)=\frac{p_1(x)}{p_1(x)+p_2(x)} \\\)</span> 这样就证明完成了。</p><p>那么，再看我们的训练目标：</p><p><span class="math display">\[\min_G\max_D  V(G, D) \\  \begin{align}V(G, D)&amp;=\mathbb E_{x\sim\mathcal P_{data}}[\log D(x)]+\mathbbE_{z\sim \mathcal P_z}[\log(1-D(G(z)))]\\ &amp;=\mathbb E_{x\sim\mathcalP_{data}}[\log D(x)]+\mathbb E_{x\sim \mathcal P_{\theta}}[\log(1-D(x))]\end{align} \\\]</span></p><p>而最优判别器为：</p><p><span class="math inline">\(D^\ast(x)=\frac{p_{data}(x)}{p_{data}(x)+p_\theta(x)}\\\)</span><br>将最优判别器代入 <span class="math inline">\(G\)</span> 的优化目标：</p><p><span class="math display">\[\begin{align} V(G, D^\ast)&amp;=\mathbbE_{x\sim \mathcalP_{data}}\left[\log\frac{p_{data}(x)}{p_{data}(x)+p_\theta(x)}\right]+\mathbbE_{x\sim \mathcalP_\theta}\left[\log\frac{p_\theta(x)}{p_{data}(x)+p_\theta(x)}\right]\\&amp;=2\mathrm {JS}(\mathcal P_{data}\|\mathcal P_\theta)-2\log2\end{align} \\ \]</span></p><p>因此，生成器实际上在最小化 $ P_{data}$ 和 <span class="math inline">\(\mathcal P_\theta\)</span> 的 <span class="math inline">\(\mathrm{JS}\)</span> 散度，从而让生成数据的分布<span class="math inline">\(\mathcal P_\theta\)</span> 接近真实分布<span class="math inline">\(\mathcal P_{data}\)</span> 。</p><p><em><strong>注：</strong> <span class="math inline">\(JS\)</span>散度的定义如下：</em></p><p>*<span class="math display">\[\begin{align} \mathrm{JS}(\mathcalP_1\|\mathcal P_2)&amp;=\frac{1}{2}\left[\mathrm{KL}\left(\mathcalP_1\|\mathcal P_A\right)+\mathrm{KL}\left(\mathcal P_2\|\mathcalP_A\right)\right]\\ &amp;=\log 2+\frac{1}{2}\mathbb E_{x\sim\mathcalP_1}\left[\log\frac{p_1(x)}{p_1(x)+p_2(x)}\right]+\frac{1}{2}\mathbbE_{x\sim\mathcal P_2}\left[\log\frac{p_2(x)}{p_1(x)+p_2(x)}\right]\end{align} \\\]</span></p><p>其相比 <span class="math inline">\(KL\)</span>散度最大的特点便是其是对称的*。</p><p><img src="/images/GANs/2.png"><br>可以看出GANs是通过判别器来巧妙地规避了计算似然的问题，但正是因为在实践中我们很难得到真正的最佳判别器，所以实际上我们很多时候只是在优化<span class="math inline">\(JS\)</span>散度的一个下界，笔者认为这是GANs不得不直面的一个问题。</p><h2 id="fgan">fGAN</h2><h3 id="f-散度f-divergence">F-散度(F-divergence)</h3><p>在概率统计中，f散度是一个函数，这个函数用来衡量两个概率密度<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>的区别，也就是衡量这两个分布多么的相同或者不同。像<span class="math inline">\(KL\)</span> 散度和 <span class="math inline">\(JS\)</span> 散度都是它的一种特例</p><p>f散度定义如下：</p><p><span class="math display">\[{D_f}(\mathcal P_1\|\mathcal P_2)=\int f(\frac{p_2(x)}{p_1(x)})\cdot p_1(x)\mathrm d x=\mathbb E_{x\sim\mathcalP_1}\left[f(\frac{p_2(x)}{p_1(x)})\right] \\\]</span> <span class="math inline">\(f(·)\)</span> 就是不同的散度函数， <span class="math inline">\(D_f\)</span>就是在f散度函数下，两个分布的差异。规定</p><ul><li><span class="math inline">\(f\)</span>是凸函数(为了用琴生不等式)</li><li>$f ( 1 ) = 0 $ (如果两个分布一样，刚好公式=0)</li></ul><p><img src="/images/GANs/3.png"><br>这两个规定保证了 <span class="math inline">\(D_f\)</span>是非负的，而且当两个分布相同时，其值为0，一些常见散度的 <span class="math inline">\(f\)</span> 定义如下：</p><p><img src="/images/GANs/4.png"></p><h3 id="共轭函数fenchel-conjugate">共轭函数(Fenchel Conjugate)</h3><p>一个函数 <span class="math inline">\(f:\;\mathbb{R}^n\mapsto\mathbb{R}\)</span> 的Frenchel 共轭为：</p><p><span class="math display">\[\begin{align} f^*( t)=\sup_{x}\big(\langle t, x\rangle-f( x)) \end{align}\]</span></p><p>Fenchel 共轭有几何上的解释。当 $ x$ 固定时， <span class="math inline">\(\langle t, x\rangle-f( x)\)</span>是一个仿射函数，因此 Fenchel 共轭就是一组仿射函数的上确界。如果 <span class="math inline">\(f\)</span>可微，那么仿射函数取得上确界的位置正好是 <span class="math inline">\(f\)</span> 的切线，此处有 <span class="math inline">\(\nabla f( x)= t\)</span> 。</p><p>我们拿 $f ( x ) = x l o g x $ 来说，当 <span class="math inline">\(x=10,1, 0.1\)</span>时可以看到相应的函数直线，可以看到最大化y的点连起来是个凸函数，很类似$e^{t-1}$</p><p><img src="/images/GANs/5.png"><br>公式图像：</p><p><img src="/images/GANs/6.png"><br>用数学来推一下：</p><p>将 <span class="math inline">\(f ( x ) = x l o g x\)</span> 代入 $y (t ) = x t − f ( x ) $ ，得 $y ( x ) = x t − x l o g x $ ,对于每个给定的<span class="math inline">\(t\)</span>都可以求出最大值，求导为0即可。</p><p>求导后得： <span class="math inline">\(t − l o g x − 1 = 0\)</span>,即 <span class="math inline">\(x=e^{t-1}\)</span> ，代入$ f<sup><em>(t)$, 得 $ f^</em>(t)=te</sup>{t-1}-e<sup>{t-1}(t-1)=e</sup>{t-1}$</p><p>读者可以对这个 $ f^*(t)$ 再求一次共轭，可以发现其又变回原函数了。</p><p>事实上，可以证明，对于凸函数来说$ f^{**}(x) = f(x)$</p><p><img src="/images/GANs/7.png"></p><h3 id="应用于gan">应用于GAN</h3><p>那这个跟GAN有啥关系呢？</p><p>假如我们用一个 <span class="math inline">\(D_f\)</span>来评估生成模型，对于 <span class="math inline">\(p(x)\)</span> 和 <span class="math inline">\(q(x)\)</span> 之间的 f-divergence：</p><p><span class="math display">\[ \begin{aligned} D_f(P||Q) &amp;=\int_{x} q(x) f\left(\frac{p(x)}{q(x)}\right) dx \\           &amp;=\int_{x} q(x) \left( \max_{t \in \operatorname{dom}(f^*)}\left\{\frac{p(x)}{q(x)}t - f^*(t)\right\} \right) dx\end{aligned}   \]</span></p><p>记一个函数 D(x)，它输入是 <span class="math inline">\(x\)</span>，输出是 <span class="math inline">\(t\)</span> ，用该函数代替上式中的<span class="math inline">\(t\)</span> ，得到</p><p><span class="math display">\[ \begin{aligned} D_f(P||Q)&amp;\geq\int\limits_{x}q(x)(\frac{p(x)}{q(x)}D(x)-f^{*}(D(x)))dx\\ &amp;= \int\limits_{x}p(x)D(x)dx-\int \limits_{x}q(x)f^{*}(D(x))dx \end{aligned}\]</span></p><p>D(x)其实就是判别器，可以看出，它依然是在解一个求最大值问题，通过这种方法，去逼近f-divergence。</p><p><span class="math display">\[D_f(P||Q)\approx\max \limits_{D}\int\limits_{x}p(x)D(x)dx-\int \limits_{x}q(x)f^{*}(D(x))dx\]</span></p><p>p(x) 和 q(x) 本质上是一个概率，于是有</p><p><span class="math display">\[D_f(P||Q)\approx\max\limits_{D}\{E_{x\sim P}[D(x)]-E_{x\sim Q}[f^*(D(x))]\}\]</span></p><p>用 <span class="math inline">\(P_{data}\)</span> 和 <span class="math inline">\(P_\theta\)</span> 来指代 P 和 Q，有</p><p><span class="math display">\[D_f(P_{data}||P_\theta)\approx\max\limits_{D}\{E_{x\sim P_{data}}[D(x)]-E_{x\simP_\theta}[f^*(D(x))]\}\]</span></p><p>有没有发现这一套下来很熟悉？其实这还是我们之前训练生成器判别器的那一套流程。也就是</p><p><span class="math display">\[ \begin{aligned}G^*&amp;=\mathop{argmin}\limits_{G}D_f(P_{data}||P_\theta)\\&amp;=\mathop{argmin}\limits_{G}\max \limits_{D}\{E_{x\sim P_{data}}[D(x)]-E_{x\simP_\theta}[f^*(D(x))]\}\\&amp;=\mathop{argmin} \limits_{G}\max\limits_{D}V(G, D) \end{aligned} \]</span></p><p>只不过这次的损失函数更加 general 了。换不同的 <span class="math inline">\(f(x)\)</span>，就可以量不同的散度（divergence）。</p><p><img src="/images/GANs/8.png"></p><h2 id="wgan">WGAN</h2><h3 id="js散度-to-wassersteinearth-mover-em距离">JS散度 toWasserstein（Earth-Mover EM）距离</h3><h3 id="js散度的问题">JS散度的问题</h3><p>考虑两个分布"完全不相交"的时候，会发现 <span class="math inline">\(JS\)</span> 散度为常量，梯度为 <span class="math inline">\(0\)</span> 无法优化。</p><p>下面一个例子来说明:</p><p>假设两个二维空间上的概率分布，记为 <span class="math inline">\({P}_d(X_1, Z)\)</span> 和 <span class="math inline">\({P}_g(X_2, Z)\)</span> 。我们刻画 <span class="math inline">\(Z \sim U(0, 1)\)</span> 一个 <span class="math inline">\([0, 1]\)</span> 上的均匀分布，而分别令 $ X_1 = 0$和 <span class="math inline">\(X_2 = \theta\)</span>，因而，它们在二维空间上的概率分布空间就是两条平行线（垂直于 <span class="math inline">\(x\)</span> 的轴，而平行于 <span class="math inline">\(z\)</span> 的轴）。<br>当 <span class="math inline">\(\theta = 0.5\)</span>时，我们考量等价于JS散度的损失函数 <span class="math inline">\(V(G,D^*)\)</span>，由于两个分布概率大于0的空间范围是完全没有重叠的，因此，对于任意 <span class="math inline">\(p_d(x,y) \ne 0\)</span> 必然有 <span class="math inline">\(p_g(x, y) =0\)</span> 成立，反之亦然。</p><p>因而我们就有，对于任意 <span class="math inline">\(x \in\mathbb{R}^2\)</span> ，<br><span class="math display">\[V(G, D^*)= \int_x p_d(x) log\frac{p_{d}(x)}{p_{d}(x) + p_{g}(x)} + p_g(x)log\frac{p_{g}(x)}{p_{d}(x) + p_{g}(x)} dx   \\ = \int_x p_d(x) log (1) +p_g(x)log (1) dx = 0 \\ \]</span>此时，损失函数恒为常量，无法继续指导生成器 <span class="math inline">\(G(x)\)</span>的优化。即此时出现了梯度消失的问题。</p><h3 id="wasserstein距离">Wasserstein距离</h3><p>为了弥补JS散度的局限性，我们需要一种全新的”分布间距离“的度量来进行优化，即使用Wasserstein距离，也被称为“推土机距离”（Earth-Mover），它定义如下：<br><span class="math inline">\(W({P}_d, {P}_g) = inf_{\gamma \in \Pi({P}_d,{P}_g)} {E}[||x - y||] \\\)</span>这样数学形式的刻画可能会让人看得颇为一头雾水，我们逐步来分析解释它。</p><p>其中， <span class="math inline">\(\Pi({P}_d, {P}_g)\)</span>代表一个 <span class="math inline">\({P}_d, {P}_g\)</span>构成的联合分布的集合，且这个集合中的所有联合分布必须满足其边际分布分别为<span class="math inline">\({P}_d, {P}_g\)</span> 。 <span class="math inline">\(||x-y||\)</span> 是两个分布所在空间 <span class="math inline">\(\mathbb{R}^n\)</span> 中两点的欧式距离。</p><p>我们可以将 <span class="math inline">\(\Pi({P}_d, {P}_g)\)</span>中的元素理解为一种“概率的搬运方案”。 而 <span class="math inline">\(\gamma\)</span>是上述集合中的一个联合分布，可以使得任意两点的欧式距离期望最小，即将一个分布搬运为另外一个分布的最小开销。</p><p><img src="/images/GANs/9.png"><br>此时，我们再重新观察上面的场景，当概率分布式为两条平行线上的均匀分布时，显然，最佳方案就是直接与x轴平行地进行概率搬运，对应为：<span class="math inline">\(W(P_0, P_\theta) = |\theta|\)</span>。此时，即使两个分布完全没有重叠部分，我们仍然能通过优化Wasserstein距离来实现两个概率分布之间的距离优化。</p><p>可以给出证明的是，就像JS散度一样，Wasserstein距离收敛于0时，两个分布也完全一致。</p><p>固然，通过Wasserstein距离优化GAN的想法颇为"美好"，不过，找到"最优搬运方案"的优化问题却是难事，在实现层面上，我们难以直接计算Wasserstein距离。不过，基于对偶理论可以将Wasserstein距离变换为积分概率度量IPM框架下的形式，来方便我们进行优化。</p><p>IPM也是用于衡量两个分布之间的距离，它的想法是寻找某种限制下的函数空间<span class="math inline">\(\mathbb{F}\)</span> 中的一个函数 <span class="math inline">\(f(·)\)</span>，使得对任意位置两个分布的差异最大：</p><p><span class="math display">\[d_F(p, q) = sup_{f \in F} \mathbb{E}_{x\sim P}[f(x)] - \mathbb{E}_{x \sim Q}[f(x)] \\\]</span>对于Wasserstein距离而言，则变为：</p><p><span class="math display">\[W(p, q) = sup_{||f||_L \le 1}\mathbb{E}_{x \sim P}[f(x)] - \mathbb{E}_{x \sim Q}[f(x)] \\\]</span>因而，在函数 $ f(·)$ 满足Lipschitz约束的函数空间中，即 <span class="math inline">\(||f(x) - f(y)|| \le K||x - y||\)</span>，找到最佳的函数 <span class="math inline">\(f(·)\)</span>，该情况下上式的结果则为Wasserstein距离。</p><p>这个函数 <span class="math inline">\(f(·)\)</span>难以求解，但我们可以用神经网络来拟合它。需要注意的是，从此开始，GAN的<span class="math inline">\(D\)</span>就不再是先前我们认为的“真假判别器”了，它的意义变成了一个距离的度量。此时，GAN的生成器并不改变仍然生产图片，对生成器的训练则是减小与真实分布的Wasserstein距离，判别器<span class="math inline">\(D\)</span>负责给出真实图像和生产图像样本之间的Wasserstein距离，相应的，在固定生成器优化判别器时，化则变为了寻找函数空间<span class="math inline">\(\mathbb{F}\)</span> 中最佳的 <span class="math inline">\(f(·)\)</span> 。</p><p><img src="/images/GANs/10.png"><br>下面的图就可以体现传统GAN的判别器梯度和WGAN的判别器梯度的区别</p><p><img src="/images/GANs/11.png"><br>WGAN便有效解决了某些情况下传统GAN的梯度消失的问题</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford
CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h2 id=&quot;引入&quot;&gt;引入&lt;/h2&gt;
&lt;p&gt;前面我们学习了VAEs和Normalizing
Flows，这两种模型都是基于最小化KL散度（对似然进行评估）来</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Normalizing Flows</title>
    <link href="https://jia040223.github.io/2024/09/17/Normalizing%20Flows/"/>
    <id>https://jia040223.github.io/2024/09/17/Normalizing%20Flows/</id>
    <published>2024-09-17T10:18:14.000Z</published>
    <updated>2024-10-08T00:11:51.158Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习StanfordCS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h2 id="引入">引入</h2><p>生成模型模型的目的是让得到的数据分布 <span class="math inline">\(P_{\theta}\)</span> 与真实的数据分布 <span class="math inline">\(P_{data}\)</span>相同，也就是需要通过给定的样本来建模对应的分布，使得输入经过该模型后可以生成与给定样本类似的新样本。在这种意义下，评估的最佳方式便是使用<strong>极大似然估计</strong>，然而VAEs的做法导致计算似然十分复杂，所以我们只能选择计算似然的下界，也就是ELBO。</p><p>不妨思考一下，VAEs无法计算似然的原因是什么。不难发现，关键在于需要对所有的潜变量<span class="math inline">\(z\)</span>进行积分。所以假如我们有一个<strong>可逆映射</strong>，使得潜变量 <span class="math inline">\(z\)</span> 和数据 <span class="math inline">\(x\)</span>之间的是一一对应的，那我们便可以很轻松计算似然了。</p><p>Normalizing Flows正是这么做的。但可逆映射意味着潜变量 <span class="math inline">\(z\)</span> 的维度需要和数据 <span class="math inline">\(x\)</span>的<strong>维度一致</strong>，所以我们无法利用 <span class="math inline">\(z\)</span> 进行压缩。</p><h2 id="简介">简介</h2><p>正则化流（NormalizingFlow）是一种<strong>可逆生成模型</strong>，用于将一个原始分布通过学习的变换映射到另一个<strong>已知</strong>的概率分布。它可以<strong>将数据从原始分布转换为目标分布</strong>，从而实现数据的生成和采样。</p><p>在正则化流中，我们定义一个变换函数，它将输入样本从原始分布映射到目标分布。这个映射是一个<strong>可逆函数</strong>，确保转换是可逆的，也就是说，在给定目标分布样本的情况下，可以逆向计算出原始分布的样本。这个变换函数通常由一系列的可逆操作组成，每个操作都是可逆的，并且通过组合这些操作可以得到整个变换。常用的可逆操作包括仿射变换、尺度变换、平移变换等。</p><h2 id="原理">原理</h2><h3 id="变量替换">变量替换</h3><p>变量替换的形式如下： $ p_{X}(X)=p_{Z}(f(X))|det~J(f(X))|$</p><ul><li><span class="math inline">\(Z=f(X)\)</span> 是一个可逆的变换</li><li><span class="math inline">\(J(f(X))\)</span> 是 <span class="math inline">\(f(X)\)</span> 的雅可比行列式</li></ul><p>如何理解呢：即给出一个 <span class="math inline">\(X\)</span>，使用一个可逆变换 <span class="math inline">\(f(\cdot)\)</span> 将<span class="math inline">\(X\)</span> 变为 <span class="math inline">\(Z\)</span> ，那么 <span class="math inline">\(p(X)、p(Z)\)</span>这两个分布之间相差的就是这样一个雅可比行列式。</p><figure><img src="/images/Normalizing%20Flows/1.png" alt="1.png"><figcaption aria-hidden="true">1.png</figcaption></figure><h3 id="流的组合">流的组合</h3><p>基本原理：可导的可逆的函数在进行组合后依然是一个可导且可逆的函数</p><p>标准化方向： <span class="math inline">\(f=f_{1}\circf_{2}\circ....f_{N}\)</span></p><p>采样构造概率的方向： <span class="math inline">\(g=g_{N} \circg_{N-1} \circ .... \circ g_{1}\)</span></p><figure><img src="/images/Normalizing%20Flows/2.png" alt="2.png"><figcaption aria-hidden="true">2.png</figcaption></figure><p>这种流动的感觉就是标准化流这个名字的由来。</p><p>而由 <span class="math inline">\(p_{X}(X)=p_{Z}(f(X))|det~J(f(X))|\)</span>可知，上面组合出来的 <span class="math inline">\(f\)</span>的雅可比行列式刚好可以表示为每一个 <span class="math inline">\(f_{i}\)</span>的<strong>雅可比行列式</strong>相乘再求行列式。</p><p><span class="math inline">\(det~J(f)=det\prod_{i=1}^{N}J(f_{i})=\prod_{i=1}^{N}det~J(f_{i})\)</span></p><p>因为每一个样本都是独立同分布采样出来的，所以它的loglikelihood就是把他们的每一个loglikelihood加起来。由于做过变量代换，就可以把它变成<strong>我们知道的非常简单的分布</strong>加上剩下的<strong>log雅可比行列式</strong>的和。</p><figure><img src="/images/Normalizing%20Flows/3.png" alt="3.png"><figcaption aria-hidden="true">3.png</figcaption></figure><h3 id="计算">计算</h3><p>通过最大似然估计，我们便可以训练模型了。但问题在于，如何构建这种可逆映射和如何让雅可比行列式方便计算。因为对于一般的雅可比行列式的计算复杂度是<span class="math inline">\(O(n^3)\)</span>，但是我们可以构造<strong>半三角的雅可比行矩阵</strong>，这样行列式的计算复杂度只有<span class="math inline">\(O(n)\)</span> 了</p><h2 id="nice-non-linear-independent-components-estimation">NICE:Non-linear Independent Components Estimation</h2><p>NICE的目标是找到一个transformation <span class="math inline">\(z=f(x)\)</span> , 将数据映射到一个新的空间中;这个空间中的 <span class="math inline">\(z\)</span> 的各个分量 <span class="math inline">\(z_d\)</span> 之间都是<strong>独立的</strong>, 即<span class="math inline">\(p_\theta(z)=\prod_dp_{\theta_d}(z_d)\)</span> .在这种"各分量独立"的假设下,模型会自发地学习"most important factors of variation"; 否则, 比如 <span class="math inline">\(h_1\)</span> 和 <span class="math inline">\(h_2\)</span> 之间不独立,那么就浪费了一部分建模能力, 从而无法达到最好的建模效果.</p><p>通过 <span class="math inline">\(z\)</span> 的先验分布和 <span class="math inline">\(x=f^{-1}(z)\)</span> , 可以实现 <span class="math inline">\(x\)</span> 的生成(采样)。一般可以假定 <span class="math inline">\(z\)</span> 的分布满足标准高斯分布。</p><h3 id="映射构造additive-coupling-layer">映射构造(Additive couplinglayer)</h3><p>如何构造构造半三角的雅可比行矩阵呢？NICE给出的方法是：</p><p><span class="math inline">\(z_{1\sim d} = x_{1\sim d}\)</span></p><p><span class="math inline">\(z_{ {d\sim D} } = x_{ {d\sim D} } +u_{\theta}(x_{ {1\sim d} })\)</span></p><p>这个变换的雅克比矩阵为</p><p><span class="math display">\[\frac{\partial z}{\partial x}=\left[       \begin{array}{cc}      I_d&amp;  \bar{0}  \\      [\frac{\partial u_\theta}{\partial x_{1\sim d}}]  &amp;  I_{n-d}  \\   \end{array}    \right]   \]</span></p><p>这个映射的逆变换也很简单，为</p><p><span class="math inline">\(x_{1\sim d} = z_{1\sim d}\)</span></p><p><span class="math inline">\(x_{ {d\sim D} } = z_{ {d\sim D} } -u_{\theta}(z_{ {1\sim d} })\)</span></p><h3 id="combining-coupling-layers">Combining coupling layers</h3><p>事实上, 这个 <span class="math inline">\(f\)</span>是要用很多层叠在一起得到的, 即 <span class="math inline">\(f=f_L \circ... \circ f_2 \circ f_1\)</span> 。 在堆叠coupling layer的时候,注意到每个变换有一部分输入是不变的。这样才能让所有部分都能得到变换. 即,第一层 <span class="math inline">\(z_1=x_1\)</span> , 变 <span class="math inline">\(x_2\)</span> , 那么第二层就 <span class="math inline">\(z_2=x_2\)</span> , 变 <span class="math inline">\(z_1\)</span> .</p><p>另外, 堆叠后的雅克比行列式为</p><p><span class="math display">\[\left|\det \frac{\partial z}{\partial x} \right| = \left|\det\frac{\partial f_L(x)}{\partial f_{L-1}(x)}\right| \cdot \left|\det\frac{\partial f_{L-1}(x)}{\partial f_{L-2}(x)}\right| \cdot \ldots\cdot \left|\det \frac{\partial f_2(x)}{\partial f_1(x)}\right|\]</span></p><p>这些行列式的绝对值为1。</p><h3 id="allowing-scaling">Allowing scaling</h3><p>因为每个行列式的绝对值都是1, 因此 <span class="math inline">\(f\)</span> 是volume preserving（体积不变的）的.为了消除这个限制, 在 <span class="math inline">\(f_L\)</span>后又乘了一个diagonal scaling matrix <span class="math inline">\(S\)</span> , 即 <span class="math inline">\(z=S\cdot f_{1, ...,L}(x)\)</span> .这样既可以让一些重要特征又更大的变化范围,又可以让一些不重要的特征减小变化范围(降维). 所以最后目标函数为</p><p><span class="math inline">\(\log p_X(x)=\sum_{i=1}^D [\logp_{H_i}(f_i(x)) + \log |S_{ii}|]\)</span></p><h2 id="density-estimation-using-real-nvp">Density Estimation Using RealNVP</h2><p><strong>RealNVP</strong>将<strong>NICE</strong>中的每一层的映射改为如下:</p><p><span class="math inline">\(\begin{aligned} z_{1:d}&amp;=x_{1:d}\\z_{d+1:D} &amp;=x_{d+1:D} \odot exp(s(x_{1:d})) +t(x_{1:d})\end{aligned}\)</span></p><p>逆变换为</p><p><span class="math inline">\(\begin{aligned} x_{1:d}&amp;=z_{1:d}\\x_{d+1:D} &amp;=(z_{d+1:D}- t(x_{1:d})) \odot exp(-s(x_{1:d}))\end{aligned}\)</span></p><p>这个变换的雅克比矩阵为</p><p><span class="math display">\[  \frac{\partial z}{\partial x}=\left[       \begin{array}{cc}      I_d&amp;  \bar{0}  \\      \frac{\partial z_{d+1:D} }{\partial x_{1:d}}  &amp;  diag(exp(s(x_{1:d})))  \\   \end{array}    \right]   \]</span></p><p>其中 <span class="math inline">\(diag(exp(s(x_{1:d})))\)</span> 是将$ exp(s(x_{1:d}))$ 这个向量展开为对角矩阵.这个雅克比矩阵的log-determinant为 <span class="math display">\[\prod_{i=1}^d \log \exp(s(x_{1:d}))=\sum_{i=1}^ds(x_{1:d})\]</span> 其中没有任何 <span class="math inline">\(s\)</span>和 <span class="math inline">\(t\)</span> 行列式的计算,因此二者可以任意复杂且hidden layer采用不同于输入的维度.</p><p>这样我们便完成了一个更加复杂的构造，同时它的表现也自然比NICE更好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford
CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h2 id=&quot;引入&quot;&gt;引入&lt;/h2&gt;
&lt;p&gt;生成模型模型的目的是让得到的数据分布 &lt;span class=&quot;math inline&quot;&gt;&#92;(P_{&#92;theta}</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>VAEs</title>
    <link href="https://jia040223.github.io/2024/09/13/VAEs/"/>
    <id>https://jia040223.github.io/2024/09/13/VAEs/</id>
    <published>2024-09-13T11:31:24.000Z</published>
    <updated>2024-10-08T00:28:02.556Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记用于记录我学习Stanford CS236课程的学习笔记，分享记录，也便于自己实时查看。</p><h2 id="潜变量">潜变量</h2><p>对于生成模型，我们可以试图寻找一组潜变量z，这个潜变量可以有具体含义，例如对于人脸生成模型的眼睛，鼻子，嘴巴等。通过修改这些潜变量我们可以得到不同风格的生成对象。但是对于图片或者自然语言而言，人为指定这种潜变量极为困难。</p><p>所以我们可以并不人为指定潜变量的含义，例如无监督学习的GMM（高斯混合聚类）就并没有指定每个类别具体的含义。但高斯混合聚类人为指定了类别的数量，这对于生成模型也是很难实现定义的。</p><p>对于GMM来说，事实上是定义了一组离散的潜变量，在每个潜变量下的数据分布服从高斯分布，它可以给我们一些启示，虽然每个类别的概率只是定义为正态分布，但它组合之后可以形成非常复杂的概率分布。</p><p><img src="/images/VAEs/1.png" alt><br>所以不妨我们可以设定有无穷多个高斯聚类的组合，即设定潜变量 z 是一个连续的随机变量，而每个潜变量 z 的值对应于一个高斯分布，事实上这也正是VAEs做的</p><h2 id="核心思想">核心思想</h2><p>VAE 的目标是学习一个生成器，将随机向量 $z \in R^d$ 映射到 $x \in R^D$ , 使得 $x$ 的分布尽可能接近真实数据的分布。</p><p>这里的 $z$ 其实就是上面提到的潜变量，他是一个连续的随机变量，实践中一般定义为服从高斯分布。而对于每个z的值，我们假设x的分布是满足均值为 $\mu(z)$ ，协方差矩阵为 $\Sigma(z)$ （可以通过神经网络进行学习）的高斯分布。理论上这样的组合可以逼近任意的概率分布。</p><p><img src="/images/VAEs/2.png" alt><br>当然PPT中的 $z\sim N(0, I)$ 只是一个例子，也可以有更复杂的定义，但在实践中<strong>一般使用标准正态分布</strong>。</p><h2 id="生成和训练">生成和训练</h2><h3 id="损失函数">损失函数</h3><p>对于一个生成模型来说，<strong>生成和评估</strong>的难易很大程度上决定了它的实用性和价值。对于上面VAE的假设来说，生成是很简单。即假设我们已经知道了 $p(x|z)$ ，我们只需要先<strong>采样 $z$ ，再采样 $x$</strong> 就能得到数据。</p><p>但是评估并不容易，这意味着模型的训练可能是一个棘手的问题。对于评估，既然是衡量两个分布的相似度，我们能否直接用各种散度（如 KL 散度）作为损失函数呢？当然可以。在蒙特卡洛抽样（Monte Carlo Sampling）下，最小化KL散度就是<strong>最大似然估计</strong>。</p><p>那么我们的目标是 $θ_∗=argmax \sum_{i=1}^{n} logp_θ​(x_i) $ ，注意到</p><p>$\sum logP_\theta(x) =\sum  log(\sum q(z)P_\theta(x|z))$</p><p>对于等式右边的计算是非常复杂的，因为 $z$ 的取值理论上具有无穷多个</p><p><img src="/images/VAEs/3.png" alt><br>所以我们需要对这个公式进行简化，注意到</p><p>$$<br>\begin{align}<br>P_\theta(x) &amp;= \sum (q(z) \frac{p_\theta(z, x)}{q(z)}) \nonumber \<br>&amp;= E_{z \sim q(z)}\left(\frac{p_\theta(z,x)}{q(z)}\right)<br>\end{align}<br>$$</p><p>通过<strong>蒙特卡洛抽样</strong>（Monte Carlo Sampling），我们可以从 $q(z)$ 中采样若干数据点，然后进行平均即可估计 $P_\theta(x)$ 的值。但很可惜，我们无法通过蒙特卡洛抽样来估计 $log(P_\theta(x))$ , 因为</p><p>$log(E_{z \sim q(z)}(\frac{p_\theta(z,x)}{q(z)})) \ne E_{z \sim q(z)}(log(\frac{p_\theta(z,x)}{q(z)}))$</p><p><img src="/images/VAEs/4.png" alt><br>但幸运的是，对于对数函数是一个严格的<strong>凹函数</strong>，所以对于凹函数来说有</p><p>$log(px + (1-p)x^{‘}) \geq plogx +(1-p)logx^{’}$ ，进一步扩展便就是著名的琴生不等式：</p><p><img src="/images/VAEs/5.png" alt></p><p>琴生不等式</p><p>因此 $log(E_{z \sim q(z)}(\frac{p_\theta(z,x)}{q(z)})) \geq E_{z \sim q(z)}(log(\frac{p_\theta(z,x)}{q(z)}))$</p><p>所以我们可以通过这种方法来<strong>估计似然的下限</strong>，即上面不等号的右边，叫做<strong>ELBO（Evidence Lower Bound）</strong></p><p><img src="/images/VAEs/6.png" alt><br>至于这个界限有多紧，我们对 $logP(x)$ 进行一下推导，就能得到它们之间相差的便是 $D_{KL}(q(z)||p(z|x;\theta)$ ，也就是说当 $q(z)$ 与我们的后验分布越接近，这个界限越紧。</p><p><img src="/images/VAEs/7.png" alt><br>其实这里的推导就是<strong>EM算法里面的推导</strong>，最大化ELBO的过程就是对应于EM算法里面的M步（后续有机会可能也会写一写）。非常可惜的是，EM 算法无法直接应用于此，因为 E-step 要求我们能够表达出后验分布 $p_\theta(z|x)$ ，但没关系，如果我们能够最大化ELBO，也能保证似然的下限被最大化。</p><p>问题似乎解决了，但值得注意的是，ELBO 是关于函数 $q$ 的<strong>泛函</strong>，也就是说 $q$ 可以取任意函数，这并不好直接优化。为了解决这个问题，我们可以将 $q(z)$ 限制为以 $\phi$ 为参数的某<strong>可解分布族 $q_\phi(z|x)$</strong> ，这样优化变量就从函数 $q$ 变成了参数 $\phi$ 。不过，由于我们限制了 $q$ 的形式，所以即便能求出最优的参数 $\phi$ ，也大概率不是 $q$ 的最优解。显然，为了尽可能逼近最优解，我们应该让选取的分布族越复杂越好。</p><p><img src="/images/VAEs/8.png" alt><br><strong>那么这里有一个小问题</strong>——为什么 $q(z)$ 参数化后写作 $q_\phi(z|x)$ 而不是 $q_\phi(z)$ ?</p><p>首先， $q$ 本来就是我们人为引入的，它是否以 $x$ 为条件完全是我们的设计，且并不与之前的推导冲突；其次，ELBO与似然当 $q(z)=p_θ(z|x)$ 时是完全等价的，可见对于不同的 $x$ ，其 $q(z)$ 的最佳形式是不同的，所以这么设定有利于<strong>减少ELBO与似然的距离</strong>。</p><p><img src="/images/VAEs/9.png" alt><br>在VAE中 的 $p_θ(x|z)$ 和 $q_\phi(z|x)$ 都由神经网络表示，因此我们用<strong>梯度下降</strong>来最大化 ELBO 即可。即对ELBO取负数就是最终的损失函数。</p><p><img src="/images/VAEs/10.png" alt><br>注意到这样的形式中并没有 $p_θ(x|z)$ 一项，我们只需要稍微变化一下：</p><p>$$<br>\begin{align}<br>L(x;\theta, \phi) &amp;= \sum q_{\phi} (z|x)\left[\log(p_{\theta}(z,x;\theta)) - \log(q_{\phi}(z|x))\right] \<br>&amp;= \sum q_{\phi} (z|x)\left[\log(p_{\theta}(z,x;\theta)) - \log(p(z)) + \log(p(z)) - \log(q_{\phi}(z|x))\right] \<br>&amp;= \sum q_{\phi} (z|x)\left[\log(p_{\theta}(x|z)) - \log\left(\frac{q_{\phi}(z|x)}{p(z)}\right)\right] \<br>&amp;= E_{z \sim q_{\phi}(z|x)}\left[\log(p_{\theta}(x|z))\right] - D_{KL}(q_{\phi}(z|x) || p(z))<br>\end{align}<br>$$</p><p>这里就把我们的目标分成了两项：</p><ol><li>第一项是<strong>重构项</strong>，要求我们尽可能重构数据本身</li><li>第二项是<strong>正则项</strong>，要求我们的后验与先验接近</li></ol><p>所以可以看到，它与自动编码器最大的区别在于有第二项，这保证了隐藏变量 $z$ 的分布，从而我们<strong>可以从先验中对 $z$ 取样</strong>从而进行生成。换句话来说，VAEs是对潜变量进行了正则化的自动编码器，因为我们知道了潜变量 $z$ 的分布形式，所以它能够用于生成。</p><p>按照<strong>蒙特卡洛抽样</strong>（Monte Carlo Sampling），理论上求这个期望需要对每个样本多次采样进行计算，最后平均。但在具体实践中，往往采样一次进行计算就行。</p><h3 id="梯度计算细节：重参数化技巧">梯度计算细节：重参数化技巧</h3><p>有一个细节是现在 $z$ 是从</p><p>$q_\phi(z|x)∼N(μ_ϕ(x)，diag(\sigma^{2}_ϕ(x)))$</p><p>中采样的，但梯度无法经过采样传播到参数 $\phi$ 。但其实解决方法很简单，对于高斯函数，只需要先从 $N(0,I)$ 中采样 $\epsilon$ 再计算 $z=μ_ϕ(x)+\epsilon⋅σ_ϕ(x)$ 即可。</p><p>这种技巧也叫做<strong>重参数化技巧</strong>，其最开始应该是在强化学习中出现的，后面有时间也可以写一写。</p><p><img src="/images/VAEs/11.png" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记用于记录我学习Stanford CS236课程的学习笔记，分享记录，也便于自己实时查看。&lt;/p&gt;
&lt;h2 id=&quot;潜变量&quot;&gt;潜变量&lt;/h2&gt;
&lt;p&gt;对于生成模型，我们可以试图寻找一组潜变量z，这个潜变量可以有具体含义，例如对于人脸生成模型的眼睛，鼻子，嘴巴等。通过</summary>
      
    
    
    
    <category term="Stanford CS236深度生成模型" scheme="https://jia040223.github.io/categories/Stanford-CS236%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="生成模型" scheme="https://jia040223.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
</feed>
